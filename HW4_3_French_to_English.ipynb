{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "mount_file_id": "14CLN1pAxkKignjjzqqSpqFkzU0LiNIFd",
      "authorship_tag": "ABX9TyOSB0hZ/E2Y3eAmqNrffBhG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/myllanes/Introduction-to-Deep-Learning/blob/main/HW4_3_French_to_English.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Michael Yllanes\n",
        "# Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OqjxUDqSQoQ",
        "outputId": "8ece6b62-d73c-409f-d499-0cf6d12b2c47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNe7lBwqG__w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac9a716a-669f-486f-b664-9501178b3e5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.11/dist-packages (1.1.2)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.3.1)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.12.2)\n",
            "Epoch 0, Training Loss: 3.1027, Validation Loss: 2.9236\n",
            "Epoch 10, Training Loss: 2.2806, Validation Loss: 2.3457\n",
            "Epoch 20, Training Loss: 2.2473, Validation Loss: 2.0112\n",
            "Epoch 30, Training Loss: 2.1998, Validation Loss: 1.9105\n",
            "Epoch 40, Training Loss: 2.1563, Validation Loss: 2.2342\n",
            "Epoch 50, Training Loss: 2.0916, Validation Loss: 2.0487\n",
            "Epoch 60, Training Loss: 2.0175, Validation Loss: 2.1800\n",
            "Epoch 70, Training Loss: 2.1133, Validation Loss: 2.7490\n",
            "Epoch 80, Training Loss: 1.9154, Validation Loss: 2.8147\n",
            "Epoch 90, Training Loss: 1.8692, Validation Loss: 2.6164\n",
            "Epoch 100, Training Loss: 1.7382, Validation Loss: 2.8467\n",
            "Epoch 110, Training Loss: 1.7193, Validation Loss: 2.5161\n",
            "Epoch 120, Training Loss: 1.6060, Validation Loss: 2.8747\n",
            "Epoch 130, Training Loss: 1.4317, Validation Loss: 3.0369\n",
            "Epoch 140, Training Loss: 1.1653, Validation Loss: 3.2203\n",
            "Epoch 150, Training Loss: 0.7748, Validation Loss: 4.0242\n",
            "Epoch 160, Training Loss: 0.4900, Validation Loss: 4.4135\n",
            "Epoch 170, Training Loss: 0.2966, Validation Loss: 5.0985\n",
            "Epoch 180, Training Loss: 0.0723, Validation Loss: 6.1493\n",
            "Epoch 190, Training Loss: 0.0185, Validation Loss: 6.5531\n",
            "Input: Ils font un signe d'adieu, Target: They wave goodbye, Predicted: They wave goodbye\n",
            "Input: Elle porte des lunettes, Target: She wears glasses, Predicted: She wears glasses\n",
            "Input: Il dort profondément, Target: He sleeps deeply, Predicted: He sleeps deeply\n",
            "Input: Elle danse avec grâce, Target: She dances gracefully, Predicted: She dances gracefully\n",
            "Input: Nous apprenons quelque chose de nouveau chaque jour, Target: We learn something new every day, Predicted: We learn something new every day\n",
            "Evaluation Loss: 1.405215904406257, Accuracy: 0.7964601769911505\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "import random\n",
        "import ast  # For safely evaluating the file content\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Install python-docx for reading .docx files\n",
        "!pip install python-docx\n",
        "\n",
        "# .docx file in Google Drive\n",
        "file_path = '/content/drive/My Drive/Dataset_English_to_French.docx'\n",
        "\n",
        "# Load the .docx\n",
        "from docx import Document\n",
        "doc = Document(file_path)\n",
        "\n",
        "\n",
        "text = []\n",
        "for paragraph in doc.paragraphs:\n",
        "    text.append(paragraph.text)\n",
        "\n",
        "\n",
        "text = '\\n'.join(text)\n",
        "\n",
        "# Extract the list of tuples from the text\n",
        "start_index = text.find('[')  # Find the start\n",
        "end_index = text.rfind(']') + 1  # Find the end\n",
        "list_content = text[start_index:end_index]  # Extract the list content\n",
        "\n",
        "# evaluate the list content\n",
        "dataset = ast.literal_eval(list_content)\n",
        "\n",
        "# Swap the input and target pairs\n",
        "dataset = [(french, english) for english, french in dataset]\n",
        "\n",
        "# Special tokens for the start and end of sequences\n",
        "SOS_token = 0  # Start Of Sequence Token\n",
        "EOS_token = 1  # End Of Sequence Token\n",
        "\n",
        "# Mappings charaters\n",
        "all_chars = set(''.join([word for pair in dataset for word in pair]))\n",
        "char_to_index = {\"SOS\": SOS_token, \"EOS\": EOS_token, **{char: i+2 for i, char in enumerate(sorted(list(all_chars)))}}\n",
        "index_to_char = {i: char for char, i in char_to_index.items()}\n",
        "\n",
        "# Custom Dataset class for French to English\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, dataset, char_to_index):\n",
        "        self.dataset = dataset\n",
        "        self.char_to_index = char_to_index\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_word, target_word = self.dataset[idx]\n",
        "        input_tensor = torch.tensor([self.char_to_index[char] for char in input_word] + [EOS_token], dtype=torch.long)\n",
        "        target_tensor = torch.tensor([self.char_to_index[char] for char in target_word] + [EOS_token], dtype=torch.long)\n",
        "        return input_tensor, target_tensor\n",
        "\n",
        "# DataLoader check\n",
        "translation_dataset = TranslationDataset(dataset, char_to_index)\n",
        "dataloader = DataLoader(translation_dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "# Set device (GPU if available, else CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Split dataset into training and validation sets\n",
        "train_dataset, val_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create DataLoader for training and validation sets\n",
        "train_translation_dataset = TranslationDataset(train_dataset, char_to_index)\n",
        "val_translation_dataset = TranslationDataset(val_dataset, char_to_index)\n",
        "\n",
        "train_dataloader = DataLoader(train_translation_dataset, batch_size=1, shuffle=True)\n",
        "val_dataloader = DataLoader(val_translation_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "# Encoder model\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, en_out, hidden_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(input_size, en_out)\n",
        "        self.lstm = nn.LSTM(en_out, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output, hidden = self.lstm(embedded, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return (torch.zeros(1, 1, self.hidden_size, device=device),\n",
        "                torch.zeros(1, 1, self.hidden_size, device=device))\n",
        "\n",
        "# Decoder model\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output, hidden = self.lstm(embedded, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return (torch.zeros(1, 1, self.hidden_size, device=device),\n",
        "                torch.zeros(1, 1, self.hidden_size, device=device))\n",
        "\n",
        "# Model hyperparameters\n",
        "input_size = len(char_to_index)\n",
        "hidden_size = 256\n",
        "output_size = len(char_to_index)\n",
        "\n",
        "# Initialize encoder and decoder\n",
        "encoder = Encoder(input_size=input_size, en_out=64, hidden_size=hidden_size).to(device)\n",
        "decoder = Decoder(hidden_size=hidden_size, output_size=output_size).to(device)\n",
        "\n",
        "# Optimizers and loss function\n",
        "learning_rate = 0.01\n",
        "encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "# Training function\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=12):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    # Encoding each character\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(input_tensor[ei].unsqueeze(0), encoder_hidden)\n",
        "\n",
        "    # Decoder's first input is the SOS token\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    # Decoder starts with the encoder's last hidden state\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    # Decoding loop\n",
        "    for di in range(target_length):\n",
        "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "        topv, topi = decoder_output.topk(1)\n",
        "        decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        # Calculate loss\n",
        "        loss += criterion(decoder_output, target_tensor[di].unsqueeze(0))\n",
        "        if decoder_input.item() == EOS_token:\n",
        "            break\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "\n",
        "    # Update encoder and decoder parameters\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    # Return average loss\n",
        "    return loss.item() / target_length\n",
        "\n",
        "# Training loop\n",
        "n_epochs = 200\n",
        "for epoch in range(n_epochs):\n",
        "    # Training phase\n",
        "    encoder.train()\n",
        "    decoder.train()\n",
        "    total_train_loss = 0\n",
        "    for input_tensor, target_tensor in train_dataloader:\n",
        "        input_tensor = input_tensor[0].to(device)\n",
        "        target_tensor = target_tensor[0].to(device)\n",
        "        loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        total_train_loss += loss\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "\n",
        "    # Validation phase\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "    total_val_loss = 0\n",
        "    correct_predictions = 0  # Counter for correct predictions\n",
        "    with torch.no_grad():\n",
        "        for input_tensor, target_tensor in val_dataloader:\n",
        "            input_tensor = input_tensor[0].to(device)\n",
        "            target_tensor = target_tensor[0].to(device)\n",
        "            encoder_hidden = encoder.initHidden()\n",
        "            input_length = input_tensor.size(0)\n",
        "            target_length = target_tensor.size(0)\n",
        "            loss = 0\n",
        "\n",
        "            # Encoding step\n",
        "            for ei in range(input_length):\n",
        "                encoder_output, encoder_hidden = encoder(input_tensor[ei].unsqueeze(0), encoder_hidden)\n",
        "\n",
        "            # Decoding step\n",
        "            decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "            decoder_hidden = encoder_hidden\n",
        "\n",
        "            predicted_indices = []  # Store predicted indices for accuracy calculation\n",
        "            for di in range(target_length):\n",
        "                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "                topv, topi = decoder_output.topk(1)\n",
        "                predicted_indices.append(topi.item())\n",
        "                decoder_input = topi.squeeze().detach()\n",
        "\n",
        "                loss += criterion(decoder_output, target_tensor[di].unsqueeze(0))\n",
        "                if decoder_input.item() == EOS_token:\n",
        "                    break\n",
        "\n",
        "            # Calculate validation loss\n",
        "            total_val_loss += loss.item() / target_length\n",
        "\n",
        "            # Calculate accuracy\n",
        "            target_indices = target_tensor.tolist()\n",
        "            if predicted_indices == target_indices:\n",
        "                correct_predictions += 1\n",
        "\n",
        "    avg_val_loss = total_val_loss / len(val_dataloader)\n",
        "    val_accuracy = correct_predictions / len(val_dataloader)  # Validation accuracy\n",
        "\n",
        "    # Print training and validation\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch {epoch}, Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate_and_show_examples(encoder, decoder, dataloader, criterion, n_examples=5):\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (input_tensor, target_tensor) in enumerate(dataloader):\n",
        "            input_tensor = input_tensor[0].to(device)\n",
        "            target_tensor = target_tensor[0].to(device)\n",
        "\n",
        "            encoder_hidden = encoder.initHidden()\n",
        "\n",
        "            input_length = input_tensor.size(0)\n",
        "            target_length = target_tensor.size(0)\n",
        "\n",
        "            loss = 0\n",
        "\n",
        "            # Encoding step\n",
        "            for ei in range(input_length):\n",
        "                encoder_output, encoder_hidden = encoder(input_tensor[ei].unsqueeze(0), encoder_hidden)\n",
        "\n",
        "            # Decoding step\n",
        "            decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "            decoder_hidden = encoder_hidden\n",
        "\n",
        "            predicted_indices = []\n",
        "\n",
        "            for di in range(target_length):\n",
        "                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "                topv, topi = decoder_output.topk(1)\n",
        "                predicted_indices.append(topi.item())\n",
        "                decoder_input = topi.squeeze().detach()\n",
        "\n",
        "                loss += criterion(decoder_output, target_tensor[di].unsqueeze(0))\n",
        "                if decoder_input.item() == EOS_token:\n",
        "                    break\n",
        "\n",
        "            # Calculate and print loss and accuracy for the evaluation\n",
        "            total_loss += loss.item() / target_length\n",
        "            if predicted_indices == target_tensor.tolist():\n",
        "                correct_predictions += 1\n",
        "\n",
        "            # Print some examples\n",
        "            if i < n_examples:\n",
        "                predicted_string = ''.join([index_to_char[index] for index in predicted_indices if index not in (SOS_token, EOS_token)])\n",
        "                target_string = ''.join([index_to_char[index.item()] for index in target_tensor if index.item() not in (SOS_token, EOS_token)])\n",
        "                input_string = ''.join([index_to_char[index.item()] for index in input_tensor if index.item() not in (SOS_token, EOS_token)])\n",
        "\n",
        "                print(f'Input: {input_string}, Target: {target_string}, Predicted: {predicted_string}')\n",
        "\n",
        "        # Print overall evaluation results\n",
        "        average_loss = total_loss / len(dataloader)\n",
        "        accuracy = correct_predictions / len(dataloader)\n",
        "        print(f'Evaluation Loss: {average_loss}, Accuracy: {accuracy}')\n",
        "\n",
        "# Perform evaluation with examples\n",
        "evaluate_and_show_examples(encoder, decoder, dataloader, criterion)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "PRP9b40EA_iP"
      }
    }
  ]
}