{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "mount_file_id": "14CLN1pAxkKignjjzqqSpqFkzU0LiNIFd",
      "authorship_tag": "ABX9TyONFq4bm/0ChKWrVlhyA5LZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/myllanes/Introduction-to-Deep-Learning/blob/main/HW5_4_French_To_English.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Michael Yllanes\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OqjxUDqSQoQ",
        "outputId": "b004f1cb-493e-4c1e-c261-fba5bbec16d0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "kNe7lBwqG__w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5052bc5e-e3e3-46ce-b4b8-c22baf8b7d9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.11/dist-packages (1.1.2)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.3.1)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.13.0)\n",
            "Starting training (French â†’ English)...\n",
            "Epoch 1/600:\n",
            "  Training Loss: 3.4111\n",
            "  Validation Loss: 2.6986\n",
            "  Validation Accuracy: 0.2871\n",
            "  (Model saved)\n",
            "Epoch 2/600:\n",
            "  Training Loss: 2.5809\n",
            "  Validation Loss: 2.4985\n",
            "  Validation Accuracy: 0.3118\n",
            "  (Model saved)\n",
            "Epoch 3/600:\n",
            "  Training Loss: 2.3567\n",
            "  Validation Loss: 2.4153\n",
            "  Validation Accuracy: 0.3194\n",
            "  (Model saved)\n",
            "Epoch 4/600:\n",
            "  Training Loss: 2.2411\n",
            "  Validation Loss: 2.3684\n",
            "  Validation Accuracy: 0.3232\n",
            "  (Model saved)\n",
            "Epoch 5/600:\n",
            "  Training Loss: 2.1567\n",
            "  Validation Loss: 2.3509\n",
            "  Validation Accuracy: 0.3194\n",
            "  (Model saved)\n",
            "Epoch 6/600:\n",
            "  Training Loss: 2.1006\n",
            "  Validation Loss: 2.3306\n",
            "  Validation Accuracy: 0.3213\n",
            "  (Model saved)\n",
            "Epoch 7/600:\n",
            "  Training Loss: 2.0460\n",
            "  Validation Loss: 2.3464\n",
            "  Validation Accuracy: 0.3213\n",
            "Epoch 8/600:\n",
            "  Training Loss: 1.9876\n",
            "  Validation Loss: 2.3401\n",
            "  Validation Accuracy: 0.3289\n",
            "Epoch 9/600:\n",
            "  Training Loss: 1.9336\n",
            "  Validation Loss: 2.3550\n",
            "  Validation Accuracy: 0.3270\n",
            "Epoch 10/600:\n",
            "  Training Loss: 1.8772\n",
            "  Validation Loss: 2.3503\n",
            "  Validation Accuracy: 0.3327\n",
            "Epoch 11/600:\n",
            "  Training Loss: 1.8344\n",
            "  Validation Loss: 2.3915\n",
            "  Validation Accuracy: 0.3289\n",
            "Epoch 12/600:\n",
            "  Training Loss: 1.7759\n",
            "  Validation Loss: 2.4513\n",
            "  Validation Accuracy: 0.3327\n",
            "Epoch 13/600:\n",
            "  Training Loss: 1.7198\n",
            "  Validation Loss: 2.4549\n",
            "  Validation Accuracy: 0.3118\n",
            "Epoch 14/600:\n",
            "  Training Loss: 1.6722\n",
            "  Validation Loss: 2.4441\n",
            "  Validation Accuracy: 0.3137\n",
            "Epoch 15/600:\n",
            "  Training Loss: 1.6051\n",
            "  Validation Loss: 2.5193\n",
            "  Validation Accuracy: 0.3061\n",
            "Epoch 16/600:\n",
            "  Training Loss: 1.5417\n",
            "  Validation Loss: 2.5434\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 17/600:\n",
            "  Training Loss: 1.5364\n",
            "  Validation Loss: 2.5974\n",
            "  Validation Accuracy: 0.3061\n",
            "Epoch 18/600:\n",
            "  Training Loss: 1.5086\n",
            "  Validation Loss: 2.5546\n",
            "  Validation Accuracy: 0.3042\n",
            "Epoch 19/600:\n",
            "  Training Loss: 1.4255\n",
            "  Validation Loss: 2.6667\n",
            "  Validation Accuracy: 0.3080\n",
            "Epoch 20/600:\n",
            "  Training Loss: 1.3797\n",
            "  Validation Loss: 2.6542\n",
            "  Validation Accuracy: 0.2947\n",
            "Epoch 21/600:\n",
            "  Training Loss: 1.3209\n",
            "  Validation Loss: 2.7568\n",
            "  Validation Accuracy: 0.2757\n",
            "Epoch 22/600:\n",
            "  Training Loss: 1.2873\n",
            "  Validation Loss: 2.9071\n",
            "  Validation Accuracy: 0.2624\n",
            "Epoch 23/600:\n",
            "  Training Loss: 1.2706\n",
            "  Validation Loss: 2.7846\n",
            "  Validation Accuracy: 0.2738\n",
            "Epoch 24/600:\n",
            "  Training Loss: 1.2071\n",
            "  Validation Loss: 2.9305\n",
            "  Validation Accuracy: 0.2700\n",
            "Epoch 25/600:\n",
            "  Training Loss: 1.2114\n",
            "  Validation Loss: 2.9546\n",
            "  Validation Accuracy: 0.2662\n",
            "Epoch 26/600:\n",
            "  Training Loss: 1.2077\n",
            "  Validation Loss: 2.9711\n",
            "  Validation Accuracy: 0.2681\n",
            "Epoch 27/600:\n",
            "  Training Loss: 1.2018\n",
            "  Validation Loss: 3.0004\n",
            "  Validation Accuracy: 0.2757\n",
            "Epoch 28/600:\n",
            "  Training Loss: 1.1531\n",
            "  Validation Loss: 3.0739\n",
            "  Validation Accuracy: 0.2605\n",
            "Epoch 29/600:\n",
            "  Training Loss: 1.0836\n",
            "  Validation Loss: 3.1107\n",
            "  Validation Accuracy: 0.2700\n",
            "Epoch 30/600:\n",
            "  Training Loss: 1.0336\n",
            "  Validation Loss: 3.1816\n",
            "  Validation Accuracy: 0.2738\n",
            "Epoch 31/600:\n",
            "  Training Loss: 1.0254\n",
            "  Validation Loss: 3.2291\n",
            "  Validation Accuracy: 0.2681\n",
            "Epoch 32/600:\n",
            "  Training Loss: 0.9815\n",
            "  Validation Loss: 3.2467\n",
            "  Validation Accuracy: 0.2871\n",
            "Epoch 33/600:\n",
            "  Training Loss: 0.9829\n",
            "  Validation Loss: 3.3177\n",
            "  Validation Accuracy: 0.2662\n",
            "Epoch 34/600:\n",
            "  Training Loss: 0.9901\n",
            "  Validation Loss: 3.2972\n",
            "  Validation Accuracy: 0.2586\n",
            "Epoch 35/600:\n",
            "  Training Loss: 0.9887\n",
            "  Validation Loss: 3.3165\n",
            "  Validation Accuracy: 0.2586\n",
            "Epoch 36/600:\n",
            "  Training Loss: 0.9908\n",
            "  Validation Loss: 3.2770\n",
            "  Validation Accuracy: 0.2776\n",
            "Epoch 37/600:\n",
            "  Training Loss: 0.9952\n",
            "  Validation Loss: 3.2901\n",
            "  Validation Accuracy: 0.2757\n",
            "Epoch 38/600:\n",
            "  Training Loss: 0.9201\n",
            "  Validation Loss: 3.3922\n",
            "  Validation Accuracy: 0.2814\n",
            "Epoch 39/600:\n",
            "  Training Loss: 0.8858\n",
            "  Validation Loss: 3.4237\n",
            "  Validation Accuracy: 0.2795\n",
            "Epoch 40/600:\n",
            "  Training Loss: 0.8732\n",
            "  Validation Loss: 3.3967\n",
            "  Validation Accuracy: 0.2871\n",
            "Epoch 41/600:\n",
            "  Training Loss: 0.8275\n",
            "  Validation Loss: 3.4399\n",
            "  Validation Accuracy: 0.2757\n",
            "Epoch 42/600:\n",
            "  Training Loss: 0.7768\n",
            "  Validation Loss: 3.5608\n",
            "  Validation Accuracy: 0.2624\n",
            "Epoch 43/600:\n",
            "  Training Loss: 0.7794\n",
            "  Validation Loss: 3.5155\n",
            "  Validation Accuracy: 0.2795\n",
            "Epoch 44/600:\n",
            "  Training Loss: 0.7582\n",
            "  Validation Loss: 3.6214\n",
            "  Validation Accuracy: 0.2814\n",
            "Epoch 45/600:\n",
            "  Training Loss: 0.7698\n",
            "  Validation Loss: 3.5820\n",
            "  Validation Accuracy: 0.2871\n",
            "Epoch 46/600:\n",
            "  Training Loss: 0.7842\n",
            "  Validation Loss: 3.6112\n",
            "  Validation Accuracy: 0.2624\n",
            "Epoch 47/600:\n",
            "  Training Loss: 0.7294\n",
            "  Validation Loss: 3.5804\n",
            "  Validation Accuracy: 0.2738\n",
            "Epoch 48/600:\n",
            "  Training Loss: 0.7302\n",
            "  Validation Loss: 3.7019\n",
            "  Validation Accuracy: 0.2624\n",
            "Epoch 49/600:\n",
            "  Training Loss: 0.7121\n",
            "  Validation Loss: 3.6682\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 50/600:\n",
            "  Training Loss: 0.7094\n",
            "  Validation Loss: 3.6975\n",
            "  Validation Accuracy: 0.2719\n",
            "Epoch 51/600:\n",
            "  Training Loss: 0.6860\n",
            "  Validation Loss: 3.6980\n",
            "  Validation Accuracy: 0.2890\n",
            "Epoch 52/600:\n",
            "  Training Loss: 0.6591\n",
            "  Validation Loss: 3.6475\n",
            "  Validation Accuracy: 0.2985\n",
            "Epoch 53/600:\n",
            "  Training Loss: 0.6353\n",
            "  Validation Loss: 3.6502\n",
            "  Validation Accuracy: 0.2966\n",
            "Epoch 54/600:\n",
            "  Training Loss: 0.7097\n",
            "  Validation Loss: 3.6554\n",
            "  Validation Accuracy: 0.2928\n",
            "Epoch 55/600:\n",
            "  Training Loss: 0.6877\n",
            "  Validation Loss: 3.7131\n",
            "  Validation Accuracy: 0.2700\n",
            "Epoch 56/600:\n",
            "  Training Loss: 0.6849\n",
            "  Validation Loss: 3.6580\n",
            "  Validation Accuracy: 0.2928\n",
            "Epoch 57/600:\n",
            "  Training Loss: 0.6860\n",
            "  Validation Loss: 3.7503\n",
            "  Validation Accuracy: 0.2624\n",
            "Epoch 58/600:\n",
            "  Training Loss: 0.6517\n",
            "  Validation Loss: 3.7432\n",
            "  Validation Accuracy: 0.2776\n",
            "Epoch 59/600:\n",
            "  Training Loss: 0.6519\n",
            "  Validation Loss: 3.8009\n",
            "  Validation Accuracy: 0.2605\n",
            "Epoch 60/600:\n",
            "  Training Loss: 0.6274\n",
            "  Validation Loss: 3.7870\n",
            "  Validation Accuracy: 0.2643\n",
            "Epoch 61/600:\n",
            "  Training Loss: 0.5940\n",
            "  Validation Loss: 3.8137\n",
            "  Validation Accuracy: 0.2605\n",
            "Epoch 62/600:\n",
            "  Training Loss: 0.6010\n",
            "  Validation Loss: 3.8338\n",
            "  Validation Accuracy: 0.2871\n",
            "Epoch 63/600:\n",
            "  Training Loss: 0.5576\n",
            "  Validation Loss: 3.9026\n",
            "  Validation Accuracy: 0.2833\n",
            "Epoch 64/600:\n",
            "  Training Loss: 0.5765\n",
            "  Validation Loss: 3.9001\n",
            "  Validation Accuracy: 0.2814\n",
            "Epoch 65/600:\n",
            "  Training Loss: 0.5778\n",
            "  Validation Loss: 3.9322\n",
            "  Validation Accuracy: 0.2966\n",
            "Epoch 66/600:\n",
            "  Training Loss: 0.5988\n",
            "  Validation Loss: 3.9234\n",
            "  Validation Accuracy: 0.2757\n",
            "Epoch 67/600:\n",
            "  Training Loss: 0.5826\n",
            "  Validation Loss: 3.8794\n",
            "  Validation Accuracy: 0.2795\n",
            "Epoch 68/600:\n",
            "  Training Loss: 0.5801\n",
            "  Validation Loss: 3.9787\n",
            "  Validation Accuracy: 0.2795\n",
            "Epoch 69/600:\n",
            "  Training Loss: 0.5415\n",
            "  Validation Loss: 3.9276\n",
            "  Validation Accuracy: 0.2795\n",
            "Epoch 70/600:\n",
            "  Training Loss: 0.5353\n",
            "  Validation Loss: 3.9130\n",
            "  Validation Accuracy: 0.2662\n",
            "Epoch 71/600:\n",
            "  Training Loss: 0.5338\n",
            "  Validation Loss: 3.9727\n",
            "  Validation Accuracy: 0.2776\n",
            "Epoch 72/600:\n",
            "  Training Loss: 0.5444\n",
            "  Validation Loss: 3.8961\n",
            "  Validation Accuracy: 0.2833\n",
            "Epoch 73/600:\n",
            "  Training Loss: 0.5324\n",
            "  Validation Loss: 3.9570\n",
            "  Validation Accuracy: 0.2776\n",
            "Epoch 74/600:\n",
            "  Training Loss: 0.5155\n",
            "  Validation Loss: 3.9402\n",
            "  Validation Accuracy: 0.2795\n",
            "Epoch 75/600:\n",
            "  Training Loss: 0.5051\n",
            "  Validation Loss: 3.9439\n",
            "  Validation Accuracy: 0.2662\n",
            "Epoch 76/600:\n",
            "  Training Loss: 0.4985\n",
            "  Validation Loss: 3.9993\n",
            "  Validation Accuracy: 0.2700\n",
            "Epoch 77/600:\n",
            "  Training Loss: 0.5112\n",
            "  Validation Loss: 4.0568\n",
            "  Validation Accuracy: 0.2757\n",
            "Epoch 78/600:\n",
            "  Training Loss: 0.5203\n",
            "  Validation Loss: 4.0266\n",
            "  Validation Accuracy: 0.2833\n",
            "Epoch 79/600:\n",
            "  Training Loss: 0.5320\n",
            "  Validation Loss: 4.0334\n",
            "  Validation Accuracy: 0.2795\n",
            "Epoch 80/600:\n",
            "  Training Loss: 0.5236\n",
            "  Validation Loss: 4.1101\n",
            "  Validation Accuracy: 0.2757\n",
            "Epoch 81/600:\n",
            "  Training Loss: 0.5130\n",
            "  Validation Loss: 4.1036\n",
            "  Validation Accuracy: 0.2681\n",
            "Epoch 82/600:\n",
            "  Training Loss: 0.5031\n",
            "  Validation Loss: 4.0471\n",
            "  Validation Accuracy: 0.2814\n",
            "Epoch 83/600:\n",
            "  Training Loss: 0.4982\n",
            "  Validation Loss: 4.0280\n",
            "  Validation Accuracy: 0.2814\n",
            "Epoch 84/600:\n",
            "  Training Loss: 0.4829\n",
            "  Validation Loss: 4.1051\n",
            "  Validation Accuracy: 0.2681\n",
            "Epoch 85/600:\n",
            "  Training Loss: 0.4814\n",
            "  Validation Loss: 4.1171\n",
            "  Validation Accuracy: 0.2662\n",
            "Epoch 86/600:\n",
            "  Training Loss: 0.5019\n",
            "  Validation Loss: 4.1156\n",
            "  Validation Accuracy: 0.2738\n",
            "Epoch 87/600:\n",
            "  Training Loss: 0.4834\n",
            "  Validation Loss: 4.1106\n",
            "  Validation Accuracy: 0.2719\n",
            "Epoch 88/600:\n",
            "  Training Loss: 0.4663\n",
            "  Validation Loss: 4.0879\n",
            "  Validation Accuracy: 0.2510\n",
            "Epoch 89/600:\n",
            "  Training Loss: 0.4669\n",
            "  Validation Loss: 4.1365\n",
            "  Validation Accuracy: 0.2681\n",
            "Epoch 90/600:\n",
            "  Training Loss: 0.4601\n",
            "  Validation Loss: 4.1881\n",
            "  Validation Accuracy: 0.2757\n",
            "Epoch 91/600:\n",
            "  Training Loss: 0.4581\n",
            "  Validation Loss: 4.2170\n",
            "  Validation Accuracy: 0.2529\n",
            "Epoch 92/600:\n",
            "  Training Loss: 0.4742\n",
            "  Validation Loss: 4.1970\n",
            "  Validation Accuracy: 0.2624\n",
            "Epoch 93/600:\n",
            "  Training Loss: 0.4624\n",
            "  Validation Loss: 4.2064\n",
            "  Validation Accuracy: 0.2643\n",
            "Epoch 94/600:\n",
            "  Training Loss: 0.4546\n",
            "  Validation Loss: 4.2331\n",
            "  Validation Accuracy: 0.2452\n",
            "Epoch 95/600:\n",
            "  Training Loss: 0.4359\n",
            "  Validation Loss: 4.2466\n",
            "  Validation Accuracy: 0.2643\n",
            "Epoch 96/600:\n",
            "  Training Loss: 0.4390\n",
            "  Validation Loss: 4.2606\n",
            "  Validation Accuracy: 0.2719\n",
            "Epoch 97/600:\n",
            "  Training Loss: 0.4395\n",
            "  Validation Loss: 4.2858\n",
            "  Validation Accuracy: 0.2719\n",
            "Epoch 98/600:\n",
            "  Training Loss: 0.4404\n",
            "  Validation Loss: 4.2541\n",
            "  Validation Accuracy: 0.2605\n",
            "Epoch 99/600:\n",
            "  Training Loss: 0.4357\n",
            "  Validation Loss: 4.2479\n",
            "  Validation Accuracy: 0.2567\n",
            "Epoch 100/600:\n",
            "  Training Loss: 0.4390\n",
            "  Validation Loss: 4.2393\n",
            "  Validation Accuracy: 0.2624\n",
            "Epoch 101/600:\n",
            "  Training Loss: 0.4343\n",
            "  Validation Loss: 4.1821\n",
            "  Validation Accuracy: 0.2700\n",
            "Epoch 102/600:\n",
            "  Training Loss: 0.4495\n",
            "  Validation Loss: 4.2880\n",
            "  Validation Accuracy: 0.2662\n",
            "Epoch 103/600:\n",
            "  Training Loss: 0.4612\n",
            "  Validation Loss: 4.2283\n",
            "  Validation Accuracy: 0.2624\n",
            "Epoch 104/600:\n",
            "  Training Loss: 0.4377\n",
            "  Validation Loss: 4.1563\n",
            "  Validation Accuracy: 0.2567\n",
            "Epoch 105/600:\n",
            "  Training Loss: 0.4717\n",
            "  Validation Loss: 4.1846\n",
            "  Validation Accuracy: 0.2681\n",
            "Epoch 106/600:\n",
            "  Training Loss: 0.4542\n",
            "  Validation Loss: 4.1398\n",
            "  Validation Accuracy: 0.2871\n",
            "Epoch 107/600:\n",
            "  Training Loss: 0.4452\n",
            "  Validation Loss: 4.1646\n",
            "  Validation Accuracy: 0.2681\n",
            "Epoch 108/600:\n",
            "  Training Loss: 0.4475\n",
            "  Validation Loss: 4.1487\n",
            "  Validation Accuracy: 0.2757\n",
            "Epoch 109/600:\n",
            "  Training Loss: 0.4289\n",
            "  Validation Loss: 4.1346\n",
            "  Validation Accuracy: 0.2947\n",
            "Epoch 110/600:\n",
            "  Training Loss: 0.4255\n",
            "  Validation Loss: 4.1598\n",
            "  Validation Accuracy: 0.2700\n",
            "Epoch 111/600:\n",
            "  Training Loss: 0.4344\n",
            "  Validation Loss: 4.1784\n",
            "  Validation Accuracy: 0.2719\n",
            "Epoch 112/600:\n",
            "  Training Loss: 0.4273\n",
            "  Validation Loss: 4.2112\n",
            "  Validation Accuracy: 0.2757\n",
            "Epoch 113/600:\n",
            "  Training Loss: 0.4207\n",
            "  Validation Loss: 4.2364\n",
            "  Validation Accuracy: 0.2662\n",
            "Epoch 114/600:\n",
            "  Training Loss: 0.4130\n",
            "  Validation Loss: 4.2627\n",
            "  Validation Accuracy: 0.2624\n",
            "Epoch 115/600:\n",
            "  Training Loss: 0.4065\n",
            "  Validation Loss: 4.2434\n",
            "  Validation Accuracy: 0.2776\n",
            "Epoch 116/600:\n",
            "  Training Loss: 0.4133\n",
            "  Validation Loss: 4.2154\n",
            "  Validation Accuracy: 0.2757\n",
            "Epoch 117/600:\n",
            "  Training Loss: 0.4125\n",
            "  Validation Loss: 4.2429\n",
            "  Validation Accuracy: 0.2833\n",
            "Epoch 118/600:\n",
            "  Training Loss: 0.4173\n",
            "  Validation Loss: 4.2378\n",
            "  Validation Accuracy: 0.2795\n",
            "Epoch 119/600:\n",
            "  Training Loss: 0.4146\n",
            "  Validation Loss: 4.2162\n",
            "  Validation Accuracy: 0.2738\n",
            "Epoch 120/600:\n",
            "  Training Loss: 0.4229\n",
            "  Validation Loss: 4.2428\n",
            "  Validation Accuracy: 0.2719\n",
            "Epoch 121/600:\n",
            "  Training Loss: 0.4091\n",
            "  Validation Loss: 4.2544\n",
            "  Validation Accuracy: 0.2643\n",
            "Epoch 122/600:\n",
            "  Training Loss: 0.4110\n",
            "  Validation Loss: 4.2014\n",
            "  Validation Accuracy: 0.2738\n",
            "Epoch 123/600:\n",
            "  Training Loss: 0.4122\n",
            "  Validation Loss: 4.2062\n",
            "  Validation Accuracy: 0.2795\n",
            "Epoch 124/600:\n",
            "  Training Loss: 0.4200\n",
            "  Validation Loss: 4.1448\n",
            "  Validation Accuracy: 0.2700\n",
            "Epoch 125/600:\n",
            "  Training Loss: 0.4095\n",
            "  Validation Loss: 4.1622\n",
            "  Validation Accuracy: 0.2757\n",
            "Epoch 126/600:\n",
            "  Training Loss: 0.4140\n",
            "  Validation Loss: 4.1971\n",
            "  Validation Accuracy: 0.2795\n",
            "Epoch 127/600:\n",
            "  Training Loss: 0.3996\n",
            "  Validation Loss: 4.1234\n",
            "  Validation Accuracy: 0.2776\n",
            "Epoch 128/600:\n",
            "  Training Loss: 0.4036\n",
            "  Validation Loss: 4.2059\n",
            "  Validation Accuracy: 0.2814\n",
            "Epoch 129/600:\n",
            "  Training Loss: 0.4067\n",
            "  Validation Loss: 4.2822\n",
            "  Validation Accuracy: 0.2852\n",
            "Epoch 130/600:\n",
            "  Training Loss: 0.4054\n",
            "  Validation Loss: 4.2149\n",
            "  Validation Accuracy: 0.2814\n",
            "Epoch 131/600:\n",
            "  Training Loss: 0.4033\n",
            "  Validation Loss: 4.2129\n",
            "  Validation Accuracy: 0.2833\n",
            "Epoch 132/600:\n",
            "  Training Loss: 0.4132\n",
            "  Validation Loss: 4.1807\n",
            "  Validation Accuracy: 0.3004\n",
            "Epoch 133/600:\n",
            "  Training Loss: 0.3978\n",
            "  Validation Loss: 4.2214\n",
            "  Validation Accuracy: 0.2814\n",
            "Epoch 134/600:\n",
            "  Training Loss: 0.4097\n",
            "  Validation Loss: 4.2068\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 135/600:\n",
            "  Training Loss: 0.3996\n",
            "  Validation Loss: 4.2314\n",
            "  Validation Accuracy: 0.2852\n",
            "Epoch 136/600:\n",
            "  Training Loss: 0.4100\n",
            "  Validation Loss: 4.2221\n",
            "  Validation Accuracy: 0.2928\n",
            "Epoch 137/600:\n",
            "  Training Loss: 0.3925\n",
            "  Validation Loss: 4.2397\n",
            "  Validation Accuracy: 0.2947\n",
            "Epoch 138/600:\n",
            "  Training Loss: 0.4076\n",
            "  Validation Loss: 4.2385\n",
            "  Validation Accuracy: 0.2814\n",
            "Epoch 139/600:\n",
            "  Training Loss: 0.4026\n",
            "  Validation Loss: 4.2783\n",
            "  Validation Accuracy: 0.2833\n",
            "Epoch 140/600:\n",
            "  Training Loss: 0.4024\n",
            "  Validation Loss: 4.3206\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 141/600:\n",
            "  Training Loss: 0.3968\n",
            "  Validation Loss: 4.3246\n",
            "  Validation Accuracy: 0.2776\n",
            "Epoch 142/600:\n",
            "  Training Loss: 0.3892\n",
            "  Validation Loss: 4.2530\n",
            "  Validation Accuracy: 0.2662\n",
            "Epoch 143/600:\n",
            "  Training Loss: 0.4028\n",
            "  Validation Loss: 4.3331\n",
            "  Validation Accuracy: 0.2852\n",
            "Epoch 144/600:\n",
            "  Training Loss: 0.3952\n",
            "  Validation Loss: 4.2910\n",
            "  Validation Accuracy: 0.2947\n",
            "Epoch 145/600:\n",
            "  Training Loss: 0.4000\n",
            "  Validation Loss: 4.2132\n",
            "  Validation Accuracy: 0.2928\n",
            "Epoch 146/600:\n",
            "  Training Loss: 0.4013\n",
            "  Validation Loss: 4.2462\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 147/600:\n",
            "  Training Loss: 0.3968\n",
            "  Validation Loss: 4.2784\n",
            "  Validation Accuracy: 0.2928\n",
            "Epoch 148/600:\n",
            "  Training Loss: 0.3839\n",
            "  Validation Loss: 4.2096\n",
            "  Validation Accuracy: 0.2814\n",
            "Epoch 149/600:\n",
            "  Training Loss: 0.3935\n",
            "  Validation Loss: 4.2396\n",
            "  Validation Accuracy: 0.2738\n",
            "Epoch 150/600:\n",
            "  Training Loss: 0.3876\n",
            "  Validation Loss: 4.2752\n",
            "  Validation Accuracy: 0.2738\n",
            "Epoch 151/600:\n",
            "  Training Loss: 0.3915\n",
            "  Validation Loss: 4.3445\n",
            "  Validation Accuracy: 0.2567\n",
            "Epoch 152/600:\n",
            "  Training Loss: 0.4079\n",
            "  Validation Loss: 4.3122\n",
            "  Validation Accuracy: 0.2510\n",
            "Epoch 153/600:\n",
            "  Training Loss: 0.3974\n",
            "  Validation Loss: 4.3396\n",
            "  Validation Accuracy: 0.2719\n",
            "Epoch 154/600:\n",
            "  Training Loss: 0.3909\n",
            "  Validation Loss: 4.3024\n",
            "  Validation Accuracy: 0.2719\n",
            "Epoch 155/600:\n",
            "  Training Loss: 0.3842\n",
            "  Validation Loss: 4.2931\n",
            "  Validation Accuracy: 0.2738\n",
            "Epoch 156/600:\n",
            "  Training Loss: 0.3831\n",
            "  Validation Loss: 4.3281\n",
            "  Validation Accuracy: 0.2852\n",
            "Epoch 157/600:\n",
            "  Training Loss: 0.3769\n",
            "  Validation Loss: 4.2750\n",
            "  Validation Accuracy: 0.2852\n",
            "Epoch 158/600:\n",
            "  Training Loss: 0.3651\n",
            "  Validation Loss: 4.1888\n",
            "  Validation Accuracy: 0.2719\n",
            "Epoch 159/600:\n",
            "  Training Loss: 0.3664\n",
            "  Validation Loss: 4.2496\n",
            "  Validation Accuracy: 0.2795\n",
            "Epoch 160/600:\n",
            "  Training Loss: 0.3791\n",
            "  Validation Loss: 4.3116\n",
            "  Validation Accuracy: 0.2700\n",
            "Epoch 161/600:\n",
            "  Training Loss: 0.3845\n",
            "  Validation Loss: 4.3012\n",
            "  Validation Accuracy: 0.2624\n",
            "Epoch 162/600:\n",
            "  Training Loss: 0.4062\n",
            "  Validation Loss: 4.4250\n",
            "  Validation Accuracy: 0.2681\n",
            "Epoch 163/600:\n",
            "  Training Loss: 0.4162\n",
            "  Validation Loss: 4.3135\n",
            "  Validation Accuracy: 0.2681\n",
            "Epoch 164/600:\n",
            "  Training Loss: 0.4082\n",
            "  Validation Loss: 4.2469\n",
            "  Validation Accuracy: 0.2738\n",
            "Epoch 165/600:\n",
            "  Training Loss: 0.3977\n",
            "  Validation Loss: 4.1963\n",
            "  Validation Accuracy: 0.2776\n",
            "Epoch 166/600:\n",
            "  Training Loss: 0.3984\n",
            "  Validation Loss: 4.3579\n",
            "  Validation Accuracy: 0.2776\n",
            "Epoch 167/600:\n",
            "  Training Loss: 0.3842\n",
            "  Validation Loss: 4.2739\n",
            "  Validation Accuracy: 0.2776\n",
            "Epoch 168/600:\n",
            "  Training Loss: 0.3793\n",
            "  Validation Loss: 4.3200\n",
            "  Validation Accuracy: 0.2738\n",
            "Epoch 169/600:\n",
            "  Training Loss: 0.3723\n",
            "  Validation Loss: 4.3561\n",
            "  Validation Accuracy: 0.2814\n",
            "Epoch 170/600:\n",
            "  Training Loss: 0.3535\n",
            "  Validation Loss: 4.3031\n",
            "  Validation Accuracy: 0.2928\n",
            "Epoch 171/600:\n",
            "  Training Loss: 0.3741\n",
            "  Validation Loss: 4.3316\n",
            "  Validation Accuracy: 0.2719\n",
            "Epoch 172/600:\n",
            "  Training Loss: 0.3622\n",
            "  Validation Loss: 4.3212\n",
            "  Validation Accuracy: 0.2738\n",
            "Epoch 173/600:\n",
            "  Training Loss: 0.3507\n",
            "  Validation Loss: 4.2260\n",
            "  Validation Accuracy: 0.2966\n",
            "Epoch 174/600:\n",
            "  Training Loss: 0.3513\n",
            "  Validation Loss: 4.2902\n",
            "  Validation Accuracy: 0.3042\n",
            "Epoch 175/600:\n",
            "  Training Loss: 0.3581\n",
            "  Validation Loss: 4.2954\n",
            "  Validation Accuracy: 0.2947\n",
            "Epoch 176/600:\n",
            "  Training Loss: 0.3462\n",
            "  Validation Loss: 4.3734\n",
            "  Validation Accuracy: 0.3004\n",
            "Epoch 177/600:\n",
            "  Training Loss: 0.3737\n",
            "  Validation Loss: 4.3894\n",
            "  Validation Accuracy: 0.2928\n",
            "Epoch 178/600:\n",
            "  Training Loss: 0.3867\n",
            "  Validation Loss: 4.2779\n",
            "  Validation Accuracy: 0.2814\n",
            "Epoch 179/600:\n",
            "  Training Loss: 0.3943\n",
            "  Validation Loss: 4.2777\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 180/600:\n",
            "  Training Loss: 0.4788\n",
            "  Validation Loss: 4.3591\n",
            "  Validation Accuracy: 0.2852\n",
            "Epoch 181/600:\n",
            "  Training Loss: 0.5278\n",
            "  Validation Loss: 4.2597\n",
            "  Validation Accuracy: 0.2757\n",
            "Epoch 182/600:\n",
            "  Training Loss: 0.5120\n",
            "  Validation Loss: 4.2505\n",
            "  Validation Accuracy: 0.2681\n",
            "Epoch 183/600:\n",
            "  Training Loss: 0.5089\n",
            "  Validation Loss: 4.0965\n",
            "  Validation Accuracy: 0.2795\n",
            "Epoch 184/600:\n",
            "  Training Loss: 0.4722\n",
            "  Validation Loss: 4.0853\n",
            "  Validation Accuracy: 0.2833\n",
            "Epoch 185/600:\n",
            "  Training Loss: 0.4626\n",
            "  Validation Loss: 4.0888\n",
            "  Validation Accuracy: 0.2947\n",
            "Epoch 186/600:\n",
            "  Training Loss: 0.4329\n",
            "  Validation Loss: 4.1580\n",
            "  Validation Accuracy: 0.2814\n",
            "Epoch 187/600:\n",
            "  Training Loss: 0.4267\n",
            "  Validation Loss: 4.2442\n",
            "  Validation Accuracy: 0.2852\n",
            "Epoch 188/600:\n",
            "  Training Loss: 0.4024\n",
            "  Validation Loss: 4.2969\n",
            "  Validation Accuracy: 0.2928\n",
            "Epoch 189/600:\n",
            "  Training Loss: 0.3939\n",
            "  Validation Loss: 4.3396\n",
            "  Validation Accuracy: 0.2814\n",
            "Epoch 190/600:\n",
            "  Training Loss: 0.3886\n",
            "  Validation Loss: 4.2808\n",
            "  Validation Accuracy: 0.2795\n",
            "Epoch 191/600:\n",
            "  Training Loss: 0.3814\n",
            "  Validation Loss: 4.3346\n",
            "  Validation Accuracy: 0.2795\n",
            "Epoch 192/600:\n",
            "  Training Loss: 0.3780\n",
            "  Validation Loss: 4.3759\n",
            "  Validation Accuracy: 0.2795\n",
            "Epoch 193/600:\n",
            "  Training Loss: 0.3766\n",
            "  Validation Loss: 4.3175\n",
            "  Validation Accuracy: 0.2966\n",
            "Epoch 194/600:\n",
            "  Training Loss: 0.3870\n",
            "  Validation Loss: 4.3282\n",
            "  Validation Accuracy: 0.2814\n",
            "Epoch 195/600:\n",
            "  Training Loss: 0.3686\n",
            "  Validation Loss: 4.3467\n",
            "  Validation Accuracy: 0.2833\n",
            "Epoch 196/600:\n",
            "  Training Loss: 0.3582\n",
            "  Validation Loss: 4.3761\n",
            "  Validation Accuracy: 0.2814\n",
            "Epoch 197/600:\n",
            "  Training Loss: 0.3929\n",
            "  Validation Loss: 4.3840\n",
            "  Validation Accuracy: 0.2814\n",
            "Epoch 198/600:\n",
            "  Training Loss: 0.4317\n",
            "  Validation Loss: 4.3423\n",
            "  Validation Accuracy: 0.2814\n",
            "Epoch 199/600:\n",
            "  Training Loss: 0.4362\n",
            "  Validation Loss: 4.3466\n",
            "  Validation Accuracy: 0.2833\n",
            "Epoch 200/600:\n",
            "  Training Loss: 0.4553\n",
            "  Validation Loss: 4.2253\n",
            "  Validation Accuracy: 0.2833\n",
            "Epoch 201/600:\n",
            "  Training Loss: 0.4835\n",
            "  Validation Loss: 4.2067\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 202/600:\n",
            "  Training Loss: 0.4966\n",
            "  Validation Loss: 4.2156\n",
            "  Validation Accuracy: 0.2890\n",
            "Epoch 203/600:\n",
            "  Training Loss: 0.4484\n",
            "  Validation Loss: 4.2001\n",
            "  Validation Accuracy: 0.2947\n",
            "Epoch 204/600:\n",
            "  Training Loss: 0.4668\n",
            "  Validation Loss: 4.2780\n",
            "  Validation Accuracy: 0.2833\n",
            "Epoch 205/600:\n",
            "  Training Loss: 0.4958\n",
            "  Validation Loss: 4.2218\n",
            "  Validation Accuracy: 0.2966\n",
            "Epoch 206/600:\n",
            "  Training Loss: 0.4234\n",
            "  Validation Loss: 4.2556\n",
            "  Validation Accuracy: 0.2833\n",
            "Epoch 207/600:\n",
            "  Training Loss: 0.4141\n",
            "  Validation Loss: 4.1732\n",
            "  Validation Accuracy: 0.2928\n",
            "Epoch 208/600:\n",
            "  Training Loss: 0.4773\n",
            "  Validation Loss: 4.2323\n",
            "  Validation Accuracy: 0.3023\n",
            "Epoch 209/600:\n",
            "  Training Loss: 0.4325\n",
            "  Validation Loss: 4.1254\n",
            "  Validation Accuracy: 0.2966\n",
            "Epoch 210/600:\n",
            "  Training Loss: 0.4398\n",
            "  Validation Loss: 4.1891\n",
            "  Validation Accuracy: 0.2890\n",
            "Epoch 211/600:\n",
            "  Training Loss: 0.4205\n",
            "  Validation Loss: 4.2541\n",
            "  Validation Accuracy: 0.2871\n",
            "Epoch 212/600:\n",
            "  Training Loss: 0.4221\n",
            "  Validation Loss: 4.1929\n",
            "  Validation Accuracy: 0.2890\n",
            "Epoch 213/600:\n",
            "  Training Loss: 0.4315\n",
            "  Validation Loss: 4.2536\n",
            "  Validation Accuracy: 0.2795\n",
            "Epoch 214/600:\n",
            "  Training Loss: 0.4183\n",
            "  Validation Loss: 4.2067\n",
            "  Validation Accuracy: 0.2757\n",
            "Epoch 215/600:\n",
            "  Training Loss: 0.4112\n",
            "  Validation Loss: 4.3682\n",
            "  Validation Accuracy: 0.2833\n",
            "Epoch 216/600:\n",
            "  Training Loss: 0.4110\n",
            "  Validation Loss: 4.3184\n",
            "  Validation Accuracy: 0.2852\n",
            "Epoch 217/600:\n",
            "  Training Loss: 0.4083\n",
            "  Validation Loss: 4.4000\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 218/600:\n",
            "  Training Loss: 0.3939\n",
            "  Validation Loss: 4.2636\n",
            "  Validation Accuracy: 0.2681\n",
            "Epoch 219/600:\n",
            "  Training Loss: 0.4422\n",
            "  Validation Loss: 4.3759\n",
            "  Validation Accuracy: 0.2795\n",
            "Epoch 220/600:\n",
            "  Training Loss: 0.4293\n",
            "  Validation Loss: 4.3085\n",
            "  Validation Accuracy: 0.3042\n",
            "Epoch 221/600:\n",
            "  Training Loss: 0.4345\n",
            "  Validation Loss: 4.3299\n",
            "  Validation Accuracy: 0.2890\n",
            "Epoch 222/600:\n",
            "  Training Loss: 0.4698\n",
            "  Validation Loss: 4.1914\n",
            "  Validation Accuracy: 0.2947\n",
            "Epoch 223/600:\n",
            "  Training Loss: 0.5287\n",
            "  Validation Loss: 4.2110\n",
            "  Validation Accuracy: 0.2738\n",
            "Epoch 224/600:\n",
            "  Training Loss: 0.4855\n",
            "  Validation Loss: 4.1577\n",
            "  Validation Accuracy: 0.2852\n",
            "Epoch 225/600:\n",
            "  Training Loss: 0.4714\n",
            "  Validation Loss: 4.1607\n",
            "  Validation Accuracy: 0.2757\n",
            "Epoch 226/600:\n",
            "  Training Loss: 0.4489\n",
            "  Validation Loss: 4.0719\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 227/600:\n",
            "  Training Loss: 0.4099\n",
            "  Validation Loss: 4.0606\n",
            "  Validation Accuracy: 0.2833\n",
            "Epoch 228/600:\n",
            "  Training Loss: 0.4232\n",
            "  Validation Loss: 4.1153\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 229/600:\n",
            "  Training Loss: 0.4151\n",
            "  Validation Loss: 4.1956\n",
            "  Validation Accuracy: 0.2795\n",
            "Epoch 230/600:\n",
            "  Training Loss: 0.4095\n",
            "  Validation Loss: 4.2158\n",
            "  Validation Accuracy: 0.2947\n",
            "Epoch 231/600:\n",
            "  Training Loss: 0.4096\n",
            "  Validation Loss: 4.2354\n",
            "  Validation Accuracy: 0.2928\n",
            "Epoch 232/600:\n",
            "  Training Loss: 0.4016\n",
            "  Validation Loss: 4.1975\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 233/600:\n",
            "  Training Loss: 0.3888\n",
            "  Validation Loss: 4.2171\n",
            "  Validation Accuracy: 0.2776\n",
            "Epoch 234/600:\n",
            "  Training Loss: 0.3509\n",
            "  Validation Loss: 4.2748\n",
            "  Validation Accuracy: 0.2662\n",
            "Epoch 235/600:\n",
            "  Training Loss: 0.3336\n",
            "  Validation Loss: 4.3110\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 236/600:\n",
            "  Training Loss: 0.3535\n",
            "  Validation Loss: 4.3939\n",
            "  Validation Accuracy: 0.2814\n",
            "Epoch 237/600:\n",
            "  Training Loss: 0.3685\n",
            "  Validation Loss: 4.3611\n",
            "  Validation Accuracy: 0.2833\n",
            "Epoch 238/600:\n",
            "  Training Loss: 0.3604\n",
            "  Validation Loss: 4.3310\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 239/600:\n",
            "  Training Loss: 0.3879\n",
            "  Validation Loss: 4.2604\n",
            "  Validation Accuracy: 0.2833\n",
            "Epoch 240/600:\n",
            "  Training Loss: 0.4131\n",
            "  Validation Loss: 4.2800\n",
            "  Validation Accuracy: 0.2814\n",
            "Epoch 241/600:\n",
            "  Training Loss: 0.4016\n",
            "  Validation Loss: 4.1729\n",
            "  Validation Accuracy: 0.2871\n",
            "Epoch 242/600:\n",
            "  Training Loss: 0.3922\n",
            "  Validation Loss: 4.1939\n",
            "  Validation Accuracy: 0.2795\n",
            "Epoch 243/600:\n",
            "  Training Loss: 0.3888\n",
            "  Validation Loss: 4.1998\n",
            "  Validation Accuracy: 0.2738\n",
            "Epoch 244/600:\n",
            "  Training Loss: 0.4085\n",
            "  Validation Loss: 4.1839\n",
            "  Validation Accuracy: 0.2852\n",
            "Epoch 245/600:\n",
            "  Training Loss: 0.3909\n",
            "  Validation Loss: 4.2387\n",
            "  Validation Accuracy: 0.2719\n",
            "Epoch 246/600:\n",
            "  Training Loss: 0.4285\n",
            "  Validation Loss: 4.1932\n",
            "  Validation Accuracy: 0.3080\n",
            "Epoch 247/600:\n",
            "  Training Loss: 0.4880\n",
            "  Validation Loss: 4.2339\n",
            "  Validation Accuracy: 0.3004\n",
            "Epoch 248/600:\n",
            "  Training Loss: 0.4728\n",
            "  Validation Loss: 4.2616\n",
            "  Validation Accuracy: 0.2890\n",
            "Epoch 249/600:\n",
            "  Training Loss: 0.4274\n",
            "  Validation Loss: 4.2272\n",
            "  Validation Accuracy: 0.3042\n",
            "Epoch 250/600:\n",
            "  Training Loss: 0.4351\n",
            "  Validation Loss: 4.2265\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 251/600:\n",
            "  Training Loss: 0.4110\n",
            "  Validation Loss: 4.1783\n",
            "  Validation Accuracy: 0.2966\n",
            "Epoch 252/600:\n",
            "  Training Loss: 0.3973\n",
            "  Validation Loss: 4.1688\n",
            "  Validation Accuracy: 0.2966\n",
            "Epoch 253/600:\n",
            "  Training Loss: 0.4002\n",
            "  Validation Loss: 4.3050\n",
            "  Validation Accuracy: 0.2985\n",
            "Epoch 254/600:\n",
            "  Training Loss: 0.4161\n",
            "  Validation Loss: 4.2210\n",
            "  Validation Accuracy: 0.2928\n",
            "Epoch 255/600:\n",
            "  Training Loss: 0.3789\n",
            "  Validation Loss: 4.1929\n",
            "  Validation Accuracy: 0.3061\n",
            "Epoch 256/600:\n",
            "  Training Loss: 0.4207\n",
            "  Validation Loss: 4.3023\n",
            "  Validation Accuracy: 0.3042\n",
            "Epoch 257/600:\n",
            "  Training Loss: 0.3971\n",
            "  Validation Loss: 4.3301\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 258/600:\n",
            "  Training Loss: 0.4182\n",
            "  Validation Loss: 4.3204\n",
            "  Validation Accuracy: 0.2795\n",
            "Epoch 259/600:\n",
            "  Training Loss: 0.4258\n",
            "  Validation Loss: 4.4087\n",
            "  Validation Accuracy: 0.2776\n",
            "Epoch 260/600:\n",
            "  Training Loss: 0.3616\n",
            "  Validation Loss: 4.2989\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 261/600:\n",
            "  Training Loss: 0.3667\n",
            "  Validation Loss: 4.2827\n",
            "  Validation Accuracy: 0.2852\n",
            "Epoch 262/600:\n",
            "  Training Loss: 0.3272\n",
            "  Validation Loss: 4.2926\n",
            "  Validation Accuracy: 0.2871\n",
            "Epoch 263/600:\n",
            "  Training Loss: 0.3133\n",
            "  Validation Loss: 4.3885\n",
            "  Validation Accuracy: 0.2947\n",
            "Epoch 264/600:\n",
            "  Training Loss: 0.3091\n",
            "  Validation Loss: 4.3831\n",
            "  Validation Accuracy: 0.2966\n",
            "Epoch 265/600:\n",
            "  Training Loss: 0.2938\n",
            "  Validation Loss: 4.3693\n",
            "  Validation Accuracy: 0.2985\n",
            "Epoch 266/600:\n",
            "  Training Loss: 0.2681\n",
            "  Validation Loss: 4.4398\n",
            "  Validation Accuracy: 0.2890\n",
            "Epoch 267/600:\n",
            "  Training Loss: 0.2670\n",
            "  Validation Loss: 4.4928\n",
            "  Validation Accuracy: 0.2966\n",
            "Epoch 268/600:\n",
            "  Training Loss: 0.2589\n",
            "  Validation Loss: 4.5044\n",
            "  Validation Accuracy: 0.2947\n",
            "Epoch 269/600:\n",
            "  Training Loss: 0.2711\n",
            "  Validation Loss: 4.5270\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 270/600:\n",
            "  Training Loss: 0.3018\n",
            "  Validation Loss: 4.4899\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 271/600:\n",
            "  Training Loss: 0.2743\n",
            "  Validation Loss: 4.4804\n",
            "  Validation Accuracy: 0.2947\n",
            "Epoch 272/600:\n",
            "  Training Loss: 0.2702\n",
            "  Validation Loss: 4.4462\n",
            "  Validation Accuracy: 0.2966\n",
            "Epoch 273/600:\n",
            "  Training Loss: 0.2788\n",
            "  Validation Loss: 4.4631\n",
            "  Validation Accuracy: 0.2928\n",
            "Epoch 274/600:\n",
            "  Training Loss: 0.2708\n",
            "  Validation Loss: 4.5773\n",
            "  Validation Accuracy: 0.2985\n",
            "Epoch 275/600:\n",
            "  Training Loss: 0.2871\n",
            "  Validation Loss: 4.4895\n",
            "  Validation Accuracy: 0.2890\n",
            "Epoch 276/600:\n",
            "  Training Loss: 0.2955\n",
            "  Validation Loss: 4.4849\n",
            "  Validation Accuracy: 0.2795\n",
            "Epoch 277/600:\n",
            "  Training Loss: 0.2849\n",
            "  Validation Loss: 4.4585\n",
            "  Validation Accuracy: 0.2947\n",
            "Epoch 278/600:\n",
            "  Training Loss: 0.2847\n",
            "  Validation Loss: 4.4931\n",
            "  Validation Accuracy: 0.2795\n",
            "Epoch 279/600:\n",
            "  Training Loss: 0.2768\n",
            "  Validation Loss: 4.4608\n",
            "  Validation Accuracy: 0.2795\n",
            "Epoch 280/600:\n",
            "  Training Loss: 0.2684\n",
            "  Validation Loss: 4.4719\n",
            "  Validation Accuracy: 0.2852\n",
            "Epoch 281/600:\n",
            "  Training Loss: 0.2563\n",
            "  Validation Loss: 4.4338\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 282/600:\n",
            "  Training Loss: 0.2504\n",
            "  Validation Loss: 4.4676\n",
            "  Validation Accuracy: 0.2871\n",
            "Epoch 283/600:\n",
            "  Training Loss: 0.2737\n",
            "  Validation Loss: 4.5999\n",
            "  Validation Accuracy: 0.2871\n",
            "Epoch 284/600:\n",
            "  Training Loss: 0.2534\n",
            "  Validation Loss: 4.5579\n",
            "  Validation Accuracy: 0.2795\n",
            "Epoch 285/600:\n",
            "  Training Loss: 0.2634\n",
            "  Validation Loss: 4.5061\n",
            "  Validation Accuracy: 0.2947\n",
            "Epoch 286/600:\n",
            "  Training Loss: 0.2469\n",
            "  Validation Loss: 4.5473\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 287/600:\n",
            "  Training Loss: 0.2571\n",
            "  Validation Loss: 4.5403\n",
            "  Validation Accuracy: 0.2947\n",
            "Epoch 288/600:\n",
            "  Training Loss: 0.2545\n",
            "  Validation Loss: 4.5115\n",
            "  Validation Accuracy: 0.3099\n",
            "Epoch 289/600:\n",
            "  Training Loss: 0.2616\n",
            "  Validation Loss: 4.5444\n",
            "  Validation Accuracy: 0.3042\n",
            "Epoch 290/600:\n",
            "  Training Loss: 0.2577\n",
            "  Validation Loss: 4.5553\n",
            "  Validation Accuracy: 0.3042\n",
            "Epoch 291/600:\n",
            "  Training Loss: 0.2431\n",
            "  Validation Loss: 4.5205\n",
            "  Validation Accuracy: 0.2928\n",
            "Epoch 292/600:\n",
            "  Training Loss: 0.2608\n",
            "  Validation Loss: 4.5455\n",
            "  Validation Accuracy: 0.3061\n",
            "Epoch 293/600:\n",
            "  Training Loss: 0.2543\n",
            "  Validation Loss: 4.5094\n",
            "  Validation Accuracy: 0.2985\n",
            "Epoch 294/600:\n",
            "  Training Loss: 0.2515\n",
            "  Validation Loss: 4.5371\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 295/600:\n",
            "  Training Loss: 0.2483\n",
            "  Validation Loss: 4.5123\n",
            "  Validation Accuracy: 0.2871\n",
            "Epoch 296/600:\n",
            "  Training Loss: 0.2520\n",
            "  Validation Loss: 4.5150\n",
            "  Validation Accuracy: 0.2985\n",
            "Epoch 297/600:\n",
            "  Training Loss: 0.2555\n",
            "  Validation Loss: 4.5112\n",
            "  Validation Accuracy: 0.3004\n",
            "Epoch 298/600:\n",
            "  Training Loss: 0.2530\n",
            "  Validation Loss: 4.6000\n",
            "  Validation Accuracy: 0.2966\n",
            "Epoch 299/600:\n",
            "  Training Loss: 0.2447\n",
            "  Validation Loss: 4.6014\n",
            "  Validation Accuracy: 0.2833\n",
            "Epoch 300/600:\n",
            "  Training Loss: 0.2691\n",
            "  Validation Loss: 4.5952\n",
            "  Validation Accuracy: 0.2890\n",
            "Epoch 301/600:\n",
            "  Training Loss: 0.2832\n",
            "  Validation Loss: 4.6009\n",
            "  Validation Accuracy: 0.2814\n",
            "Epoch 302/600:\n",
            "  Training Loss: 0.2776\n",
            "  Validation Loss: 4.6724\n",
            "  Validation Accuracy: 0.2833\n",
            "Epoch 303/600:\n",
            "  Training Loss: 0.3017\n",
            "  Validation Loss: 4.6387\n",
            "  Validation Accuracy: 0.2814\n",
            "Epoch 304/600:\n",
            "  Training Loss: 0.3034\n",
            "  Validation Loss: 4.6082\n",
            "  Validation Accuracy: 0.2795\n",
            "Epoch 305/600:\n",
            "  Training Loss: 0.2928\n",
            "  Validation Loss: 4.6135\n",
            "  Validation Accuracy: 0.3042\n",
            "Epoch 306/600:\n",
            "  Training Loss: 0.2757\n",
            "  Validation Loss: 4.6534\n",
            "  Validation Accuracy: 0.2985\n",
            "Epoch 307/600:\n",
            "  Training Loss: 0.2596\n",
            "  Validation Loss: 4.5152\n",
            "  Validation Accuracy: 0.3061\n",
            "Epoch 308/600:\n",
            "  Training Loss: 0.2871\n",
            "  Validation Loss: 4.6651\n",
            "  Validation Accuracy: 0.3061\n",
            "Epoch 309/600:\n",
            "  Training Loss: 0.3459\n",
            "  Validation Loss: 4.6187\n",
            "  Validation Accuracy: 0.2833\n",
            "Epoch 310/600:\n",
            "  Training Loss: 0.3080\n",
            "  Validation Loss: 4.5325\n",
            "  Validation Accuracy: 0.2890\n",
            "Epoch 311/600:\n",
            "  Training Loss: 0.2991\n",
            "  Validation Loss: 4.5791\n",
            "  Validation Accuracy: 0.2852\n",
            "Epoch 312/600:\n",
            "  Training Loss: 0.2945\n",
            "  Validation Loss: 4.5532\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 313/600:\n",
            "  Training Loss: 0.3024\n",
            "  Validation Loss: 4.4777\n",
            "  Validation Accuracy: 0.2928\n",
            "Epoch 314/600:\n",
            "  Training Loss: 0.2651\n",
            "  Validation Loss: 4.4661\n",
            "  Validation Accuracy: 0.2890\n",
            "Epoch 315/600:\n",
            "  Training Loss: 0.2671\n",
            "  Validation Loss: 4.2718\n",
            "  Validation Accuracy: 0.3023\n",
            "Epoch 316/600:\n",
            "  Training Loss: 0.2648\n",
            "  Validation Loss: 4.4357\n",
            "  Validation Accuracy: 0.2719\n",
            "Epoch 317/600:\n",
            "  Training Loss: 0.2489\n",
            "  Validation Loss: 4.3332\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 318/600:\n",
            "  Training Loss: 0.2457\n",
            "  Validation Loss: 4.3183\n",
            "  Validation Accuracy: 0.3004\n",
            "Epoch 319/600:\n",
            "  Training Loss: 0.2291\n",
            "  Validation Loss: 4.4268\n",
            "  Validation Accuracy: 0.3080\n",
            "Epoch 320/600:\n",
            "  Training Loss: 0.2197\n",
            "  Validation Loss: 4.4055\n",
            "  Validation Accuracy: 0.2833\n",
            "Epoch 321/600:\n",
            "  Training Loss: 0.2255\n",
            "  Validation Loss: 4.4792\n",
            "  Validation Accuracy: 0.2833\n",
            "Epoch 322/600:\n",
            "  Training Loss: 0.2209\n",
            "  Validation Loss: 4.5125\n",
            "  Validation Accuracy: 0.2814\n",
            "Epoch 323/600:\n",
            "  Training Loss: 0.2258\n",
            "  Validation Loss: 4.5317\n",
            "  Validation Accuracy: 0.2947\n",
            "Epoch 324/600:\n",
            "  Training Loss: 0.2310\n",
            "  Validation Loss: 4.5262\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 325/600:\n",
            "  Training Loss: 0.2187\n",
            "  Validation Loss: 4.5518\n",
            "  Validation Accuracy: 0.2928\n",
            "Epoch 326/600:\n",
            "  Training Loss: 0.2093\n",
            "  Validation Loss: 4.5939\n",
            "  Validation Accuracy: 0.2776\n",
            "Epoch 327/600:\n",
            "  Training Loss: 0.2111\n",
            "  Validation Loss: 4.6827\n",
            "  Validation Accuracy: 0.2852\n",
            "Epoch 328/600:\n",
            "  Training Loss: 0.2082\n",
            "  Validation Loss: 4.7372\n",
            "  Validation Accuracy: 0.2966\n",
            "Epoch 329/600:\n",
            "  Training Loss: 0.2001\n",
            "  Validation Loss: 4.6877\n",
            "  Validation Accuracy: 0.2966\n",
            "Epoch 330/600:\n",
            "  Training Loss: 0.2043\n",
            "  Validation Loss: 4.6948\n",
            "  Validation Accuracy: 0.2871\n",
            "Epoch 331/600:\n",
            "  Training Loss: 0.1961\n",
            "  Validation Loss: 4.7346\n",
            "  Validation Accuracy: 0.2947\n",
            "Epoch 332/600:\n",
            "  Training Loss: 0.2102\n",
            "  Validation Loss: 4.7272\n",
            "  Validation Accuracy: 0.2814\n",
            "Epoch 333/600:\n",
            "  Training Loss: 0.2049\n",
            "  Validation Loss: 4.7099\n",
            "  Validation Accuracy: 0.2966\n",
            "Epoch 334/600:\n",
            "  Training Loss: 0.2121\n",
            "  Validation Loss: 4.6611\n",
            "  Validation Accuracy: 0.2814\n",
            "Epoch 335/600:\n",
            "  Training Loss: 0.2162\n",
            "  Validation Loss: 4.7225\n",
            "  Validation Accuracy: 0.2871\n",
            "Epoch 336/600:\n",
            "  Training Loss: 0.2011\n",
            "  Validation Loss: 4.7579\n",
            "  Validation Accuracy: 0.2928\n",
            "Epoch 337/600:\n",
            "  Training Loss: 0.2014\n",
            "  Validation Loss: 4.7261\n",
            "  Validation Accuracy: 0.2814\n",
            "Epoch 338/600:\n",
            "  Training Loss: 0.2062\n",
            "  Validation Loss: 4.7119\n",
            "  Validation Accuracy: 0.3023\n",
            "Epoch 339/600:\n",
            "  Training Loss: 0.2187\n",
            "  Validation Loss: 4.6768\n",
            "  Validation Accuracy: 0.2947\n",
            "Epoch 340/600:\n",
            "  Training Loss: 0.2224\n",
            "  Validation Loss: 4.6661\n",
            "  Validation Accuracy: 0.2890\n",
            "Epoch 341/600:\n",
            "  Training Loss: 0.2133\n",
            "  Validation Loss: 4.7345\n",
            "  Validation Accuracy: 0.2814\n",
            "Epoch 342/600:\n",
            "  Training Loss: 0.2157\n",
            "  Validation Loss: 4.7237\n",
            "  Validation Accuracy: 0.2662\n",
            "Epoch 343/600:\n",
            "  Training Loss: 0.2068\n",
            "  Validation Loss: 4.6876\n",
            "  Validation Accuracy: 0.2814\n",
            "Epoch 344/600:\n",
            "  Training Loss: 0.2096\n",
            "  Validation Loss: 4.7335\n",
            "  Validation Accuracy: 0.2852\n",
            "Epoch 345/600:\n",
            "  Training Loss: 0.2069\n",
            "  Validation Loss: 4.7321\n",
            "  Validation Accuracy: 0.2719\n",
            "Epoch 346/600:\n",
            "  Training Loss: 0.2023\n",
            "  Validation Loss: 4.6592\n",
            "  Validation Accuracy: 0.2757\n",
            "Epoch 347/600:\n",
            "  Training Loss: 0.2058\n",
            "  Validation Loss: 4.6419\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 348/600:\n",
            "  Training Loss: 0.2018\n",
            "  Validation Loss: 4.6252\n",
            "  Validation Accuracy: 0.2814\n",
            "Epoch 349/600:\n",
            "  Training Loss: 0.2041\n",
            "  Validation Loss: 4.6695\n",
            "  Validation Accuracy: 0.3004\n",
            "Epoch 350/600:\n",
            "  Training Loss: 0.1934\n",
            "  Validation Loss: 4.6806\n",
            "  Validation Accuracy: 0.2928\n",
            "Epoch 351/600:\n",
            "  Training Loss: 0.2060\n",
            "  Validation Loss: 4.6386\n",
            "  Validation Accuracy: 0.3023\n",
            "Epoch 352/600:\n",
            "  Training Loss: 0.2002\n",
            "  Validation Loss: 4.7089\n",
            "  Validation Accuracy: 0.3042\n",
            "Epoch 353/600:\n",
            "  Training Loss: 0.2403\n",
            "  Validation Loss: 4.6757\n",
            "  Validation Accuracy: 0.2681\n",
            "Epoch 354/600:\n",
            "  Training Loss: 0.2266\n",
            "  Validation Loss: 4.7481\n",
            "  Validation Accuracy: 0.2852\n",
            "Epoch 355/600:\n",
            "  Training Loss: 0.2267\n",
            "  Validation Loss: 4.6318\n",
            "  Validation Accuracy: 0.3080\n",
            "Epoch 356/600:\n",
            "  Training Loss: 0.2207\n",
            "  Validation Loss: 4.7335\n",
            "  Validation Accuracy: 0.2928\n",
            "Epoch 357/600:\n",
            "  Training Loss: 0.2224\n",
            "  Validation Loss: 4.6745\n",
            "  Validation Accuracy: 0.2852\n",
            "Epoch 358/600:\n",
            "  Training Loss: 0.2339\n",
            "  Validation Loss: 4.6616\n",
            "  Validation Accuracy: 0.2985\n",
            "Epoch 359/600:\n",
            "  Training Loss: 0.2272\n",
            "  Validation Loss: 4.6030\n",
            "  Validation Accuracy: 0.2871\n",
            "Epoch 360/600:\n",
            "  Training Loss: 0.2287\n",
            "  Validation Loss: 4.6022\n",
            "  Validation Accuracy: 0.2833\n",
            "Epoch 361/600:\n",
            "  Training Loss: 0.2019\n",
            "  Validation Loss: 4.5589\n",
            "  Validation Accuracy: 0.2738\n",
            "Epoch 362/600:\n",
            "  Training Loss: 0.2004\n",
            "  Validation Loss: 4.5474\n",
            "  Validation Accuracy: 0.2738\n",
            "Epoch 363/600:\n",
            "  Training Loss: 0.2090\n",
            "  Validation Loss: 4.6455\n",
            "  Validation Accuracy: 0.2738\n",
            "Epoch 364/600:\n",
            "  Training Loss: 0.1910\n",
            "  Validation Loss: 4.6338\n",
            "  Validation Accuracy: 0.2719\n",
            "Epoch 365/600:\n",
            "  Training Loss: 0.2107\n",
            "  Validation Loss: 4.7229\n",
            "  Validation Accuracy: 0.2852\n",
            "Epoch 366/600:\n",
            "  Training Loss: 0.2039\n",
            "  Validation Loss: 4.6059\n",
            "  Validation Accuracy: 0.2776\n",
            "Epoch 367/600:\n",
            "  Training Loss: 0.2162\n",
            "  Validation Loss: 4.7354\n",
            "  Validation Accuracy: 0.2814\n",
            "Epoch 368/600:\n",
            "  Training Loss: 0.2273\n",
            "  Validation Loss: 4.5075\n",
            "  Validation Accuracy: 0.2985\n",
            "Epoch 369/600:\n",
            "  Training Loss: 0.2646\n",
            "  Validation Loss: 4.8186\n",
            "  Validation Accuracy: 0.2795\n",
            "Epoch 370/600:\n",
            "  Training Loss: 0.3000\n",
            "  Validation Loss: 4.4846\n",
            "  Validation Accuracy: 0.3023\n",
            "Epoch 371/600:\n",
            "  Training Loss: 0.2582\n",
            "  Validation Loss: 4.6911\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 372/600:\n",
            "  Training Loss: 0.2824\n",
            "  Validation Loss: 4.5812\n",
            "  Validation Accuracy: 0.2795\n",
            "Epoch 373/600:\n",
            "  Training Loss: 0.2802\n",
            "  Validation Loss: 4.6367\n",
            "  Validation Accuracy: 0.2871\n",
            "Epoch 374/600:\n",
            "  Training Loss: 0.2467\n",
            "  Validation Loss: 4.5949\n",
            "  Validation Accuracy: 0.2719\n",
            "Epoch 375/600:\n",
            "  Training Loss: 0.2313\n",
            "  Validation Loss: 4.5532\n",
            "  Validation Accuracy: 0.2947\n",
            "Epoch 376/600:\n",
            "  Training Loss: 0.2169\n",
            "  Validation Loss: 4.5939\n",
            "  Validation Accuracy: 0.2814\n",
            "Epoch 377/600:\n",
            "  Training Loss: 0.2248\n",
            "  Validation Loss: 4.5206\n",
            "  Validation Accuracy: 0.2852\n",
            "Epoch 378/600:\n",
            "  Training Loss: 0.2104\n",
            "  Validation Loss: 4.6034\n",
            "  Validation Accuracy: 0.2928\n",
            "Epoch 379/600:\n",
            "  Training Loss: 0.2083\n",
            "  Validation Loss: 4.6638\n",
            "  Validation Accuracy: 0.2757\n",
            "Epoch 380/600:\n",
            "  Training Loss: 0.2077\n",
            "  Validation Loss: 4.6871\n",
            "  Validation Accuracy: 0.2966\n",
            "Epoch 381/600:\n",
            "  Training Loss: 0.1950\n",
            "  Validation Loss: 4.7044\n",
            "  Validation Accuracy: 0.3080\n",
            "Epoch 382/600:\n",
            "  Training Loss: 0.1934\n",
            "  Validation Loss: 4.7307\n",
            "  Validation Accuracy: 0.2966\n",
            "Epoch 383/600:\n",
            "  Training Loss: 0.1909\n",
            "  Validation Loss: 4.7478\n",
            "  Validation Accuracy: 0.2871\n",
            "Epoch 384/600:\n",
            "  Training Loss: 0.1886\n",
            "  Validation Loss: 4.7268\n",
            "  Validation Accuracy: 0.3023\n",
            "Epoch 385/600:\n",
            "  Training Loss: 0.1928\n",
            "  Validation Loss: 4.7156\n",
            "  Validation Accuracy: 0.2966\n",
            "Epoch 386/600:\n",
            "  Training Loss: 0.1946\n",
            "  Validation Loss: 4.7116\n",
            "  Validation Accuracy: 0.2947\n",
            "Epoch 387/600:\n",
            "  Training Loss: 0.1862\n",
            "  Validation Loss: 4.7833\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 388/600:\n",
            "  Training Loss: 0.1852\n",
            "  Validation Loss: 4.7617\n",
            "  Validation Accuracy: 0.2985\n",
            "Epoch 389/600:\n",
            "  Training Loss: 0.1892\n",
            "  Validation Loss: 4.7360\n",
            "  Validation Accuracy: 0.2890\n",
            "Epoch 390/600:\n",
            "  Training Loss: 0.1821\n",
            "  Validation Loss: 4.7143\n",
            "  Validation Accuracy: 0.2928\n",
            "Epoch 391/600:\n",
            "  Training Loss: 0.1927\n",
            "  Validation Loss: 4.7130\n",
            "  Validation Accuracy: 0.2966\n",
            "Epoch 392/600:\n",
            "  Training Loss: 0.1956\n",
            "  Validation Loss: 4.7568\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 393/600:\n",
            "  Training Loss: 0.1871\n",
            "  Validation Loss: 4.6547\n",
            "  Validation Accuracy: 0.2947\n",
            "Epoch 394/600:\n",
            "  Training Loss: 0.1928\n",
            "  Validation Loss: 4.6825\n",
            "  Validation Accuracy: 0.2852\n",
            "Epoch 395/600:\n",
            "  Training Loss: 0.1867\n",
            "  Validation Loss: 4.6770\n",
            "  Validation Accuracy: 0.2871\n",
            "Epoch 396/600:\n",
            "  Training Loss: 0.1839\n",
            "  Validation Loss: 4.6377\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 397/600:\n",
            "  Training Loss: 0.1892\n",
            "  Validation Loss: 4.6803\n",
            "  Validation Accuracy: 0.2947\n",
            "Epoch 398/600:\n",
            "  Training Loss: 0.1868\n",
            "  Validation Loss: 4.6778\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 399/600:\n",
            "  Training Loss: 0.1928\n",
            "  Validation Loss: 4.6908\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 400/600:\n",
            "  Training Loss: 0.1860\n",
            "  Validation Loss: 4.7174\n",
            "  Validation Accuracy: 0.2890\n",
            "Epoch 401/600:\n",
            "  Training Loss: 0.1847\n",
            "  Validation Loss: 4.7026\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 402/600:\n",
            "  Training Loss: 0.1822\n",
            "  Validation Loss: 4.8010\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 403/600:\n",
            "  Training Loss: 0.1826\n",
            "  Validation Loss: 4.7647\n",
            "  Validation Accuracy: 0.2852\n",
            "Epoch 404/600:\n",
            "  Training Loss: 0.1839\n",
            "  Validation Loss: 4.8129\n",
            "  Validation Accuracy: 0.2928\n",
            "Epoch 405/600:\n",
            "  Training Loss: 0.1967\n",
            "  Validation Loss: 4.8165\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 406/600:\n",
            "  Training Loss: 0.1889\n",
            "  Validation Loss: 4.7872\n",
            "  Validation Accuracy: 0.2795\n",
            "Epoch 407/600:\n",
            "  Training Loss: 0.1927\n",
            "  Validation Loss: 4.8790\n",
            "  Validation Accuracy: 0.2852\n",
            "Epoch 408/600:\n",
            "  Training Loss: 0.1957\n",
            "  Validation Loss: 4.7776\n",
            "  Validation Accuracy: 0.2776\n",
            "Epoch 409/600:\n",
            "  Training Loss: 0.2030\n",
            "  Validation Loss: 4.9153\n",
            "  Validation Accuracy: 0.2947\n",
            "Epoch 410/600:\n",
            "  Training Loss: 0.1993\n",
            "  Validation Loss: 4.8931\n",
            "  Validation Accuracy: 0.2814\n",
            "Epoch 411/600:\n",
            "  Training Loss: 0.1980\n",
            "  Validation Loss: 4.7472\n",
            "  Validation Accuracy: 0.2928\n",
            "Epoch 412/600:\n",
            "  Training Loss: 0.1989\n",
            "  Validation Loss: 4.8283\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 413/600:\n",
            "  Training Loss: 0.1981\n",
            "  Validation Loss: 4.8116\n",
            "  Validation Accuracy: 0.2871\n",
            "Epoch 414/600:\n",
            "  Training Loss: 0.2050\n",
            "  Validation Loss: 4.7997\n",
            "  Validation Accuracy: 0.2852\n",
            "Epoch 415/600:\n",
            "  Training Loss: 0.2007\n",
            "  Validation Loss: 4.8238\n",
            "  Validation Accuracy: 0.2814\n",
            "Epoch 416/600:\n",
            "  Training Loss: 0.2091\n",
            "  Validation Loss: 4.7082\n",
            "  Validation Accuracy: 0.2947\n",
            "Epoch 417/600:\n",
            "  Training Loss: 0.1961\n",
            "  Validation Loss: 4.7636\n",
            "  Validation Accuracy: 0.3080\n",
            "Epoch 418/600:\n",
            "  Training Loss: 0.1943\n",
            "  Validation Loss: 4.8324\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 419/600:\n",
            "  Training Loss: 0.2047\n",
            "  Validation Loss: 4.7755\n",
            "  Validation Accuracy: 0.2871\n",
            "Epoch 420/600:\n",
            "  Training Loss: 0.2038\n",
            "  Validation Loss: 4.7647\n",
            "  Validation Accuracy: 0.2871\n",
            "Epoch 421/600:\n",
            "  Training Loss: 0.2083\n",
            "  Validation Loss: 4.7931\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 422/600:\n",
            "  Training Loss: 0.1931\n",
            "  Validation Loss: 4.7510\n",
            "  Validation Accuracy: 0.2928\n",
            "Epoch 423/600:\n",
            "  Training Loss: 0.1876\n",
            "  Validation Loss: 4.7798\n",
            "  Validation Accuracy: 0.2985\n",
            "Epoch 424/600:\n",
            "  Training Loss: 0.2011\n",
            "  Validation Loss: 4.7527\n",
            "  Validation Accuracy: 0.2890\n",
            "Epoch 425/600:\n",
            "  Training Loss: 0.1860\n",
            "  Validation Loss: 4.7316\n",
            "  Validation Accuracy: 0.3004\n",
            "Epoch 426/600:\n",
            "  Training Loss: 0.1851\n",
            "  Validation Loss: 4.7844\n",
            "  Validation Accuracy: 0.2719\n",
            "Epoch 427/600:\n",
            "  Training Loss: 0.1853\n",
            "  Validation Loss: 4.7694\n",
            "  Validation Accuracy: 0.2833\n",
            "Epoch 428/600:\n",
            "  Training Loss: 0.1927\n",
            "  Validation Loss: 4.7798\n",
            "  Validation Accuracy: 0.2852\n",
            "Epoch 429/600:\n",
            "  Training Loss: 0.1860\n",
            "  Validation Loss: 4.8575\n",
            "  Validation Accuracy: 0.2700\n",
            "Epoch 430/600:\n",
            "  Training Loss: 0.1885\n",
            "  Validation Loss: 4.7850\n",
            "  Validation Accuracy: 0.2738\n",
            "Epoch 431/600:\n",
            "  Training Loss: 0.1830\n",
            "  Validation Loss: 4.8607\n",
            "  Validation Accuracy: 0.2890\n",
            "Epoch 432/600:\n",
            "  Training Loss: 0.1853\n",
            "  Validation Loss: 4.8597\n",
            "  Validation Accuracy: 0.2814\n",
            "Epoch 433/600:\n",
            "  Training Loss: 0.1756\n",
            "  Validation Loss: 4.8034\n",
            "  Validation Accuracy: 0.2966\n",
            "Epoch 434/600:\n",
            "  Training Loss: 0.1762\n",
            "  Validation Loss: 4.8639\n",
            "  Validation Accuracy: 0.2947\n",
            "Epoch 435/600:\n",
            "  Training Loss: 0.1732\n",
            "  Validation Loss: 4.8346\n",
            "  Validation Accuracy: 0.2814\n",
            "Epoch 436/600:\n",
            "  Training Loss: 0.1670\n",
            "  Validation Loss: 4.8314\n",
            "  Validation Accuracy: 0.2814\n",
            "Epoch 437/600:\n",
            "  Training Loss: 0.1809\n",
            "  Validation Loss: 4.8178\n",
            "  Validation Accuracy: 0.2890\n",
            "Epoch 438/600:\n",
            "  Training Loss: 0.1776\n",
            "  Validation Loss: 4.7921\n",
            "  Validation Accuracy: 0.2890\n",
            "Epoch 439/600:\n",
            "  Training Loss: 0.1810\n",
            "  Validation Loss: 4.7620\n",
            "  Validation Accuracy: 0.2985\n",
            "Epoch 440/600:\n",
            "  Training Loss: 0.1886\n",
            "  Validation Loss: 4.7599\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 441/600:\n",
            "  Training Loss: 0.1746\n",
            "  Validation Loss: 4.7767\n",
            "  Validation Accuracy: 0.2928\n",
            "Epoch 442/600:\n",
            "  Training Loss: 0.1813\n",
            "  Validation Loss: 4.7852\n",
            "  Validation Accuracy: 0.2833\n",
            "Epoch 443/600:\n",
            "  Training Loss: 0.1805\n",
            "  Validation Loss: 4.7528\n",
            "  Validation Accuracy: 0.2757\n",
            "Epoch 444/600:\n",
            "  Training Loss: 0.1817\n",
            "  Validation Loss: 4.8131\n",
            "  Validation Accuracy: 0.2795\n",
            "Epoch 445/600:\n",
            "  Training Loss: 0.1697\n",
            "  Validation Loss: 4.8251\n",
            "  Validation Accuracy: 0.2814\n",
            "Epoch 446/600:\n",
            "  Training Loss: 0.1817\n",
            "  Validation Loss: 4.8372\n",
            "  Validation Accuracy: 0.2757\n",
            "Epoch 447/600:\n",
            "  Training Loss: 0.1878\n",
            "  Validation Loss: 4.9062\n",
            "  Validation Accuracy: 0.2757\n",
            "Epoch 448/600:\n",
            "  Training Loss: 0.1788\n",
            "  Validation Loss: 4.8814\n",
            "  Validation Accuracy: 0.2947\n",
            "Epoch 449/600:\n",
            "  Training Loss: 0.1786\n",
            "  Validation Loss: 4.8140\n",
            "  Validation Accuracy: 0.2928\n",
            "Epoch 450/600:\n",
            "  Training Loss: 0.1769\n",
            "  Validation Loss: 4.8242\n",
            "  Validation Accuracy: 0.2814\n",
            "Epoch 451/600:\n",
            "  Training Loss: 0.1754\n",
            "  Validation Loss: 4.9264\n",
            "  Validation Accuracy: 0.2738\n",
            "Epoch 452/600:\n",
            "  Training Loss: 0.1887\n",
            "  Validation Loss: 4.8231\n",
            "  Validation Accuracy: 0.2871\n",
            "Epoch 453/600:\n",
            "  Training Loss: 0.1803\n",
            "  Validation Loss: 4.8642\n",
            "  Validation Accuracy: 0.2890\n",
            "Epoch 454/600:\n",
            "  Training Loss: 0.1974\n",
            "  Validation Loss: 4.7879\n",
            "  Validation Accuracy: 0.2928\n",
            "Epoch 455/600:\n",
            "  Training Loss: 0.1985\n",
            "  Validation Loss: 4.8431\n",
            "  Validation Accuracy: 0.2738\n",
            "Epoch 456/600:\n",
            "  Training Loss: 0.1935\n",
            "  Validation Loss: 4.7661\n",
            "  Validation Accuracy: 0.2890\n",
            "Epoch 457/600:\n",
            "  Training Loss: 0.1894\n",
            "  Validation Loss: 4.9516\n",
            "  Validation Accuracy: 0.2947\n",
            "Epoch 458/600:\n",
            "  Training Loss: 0.1959\n",
            "  Validation Loss: 4.8709\n",
            "  Validation Accuracy: 0.2833\n",
            "Epoch 459/600:\n",
            "  Training Loss: 0.2018\n",
            "  Validation Loss: 4.8807\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 460/600:\n",
            "  Training Loss: 0.2100\n",
            "  Validation Loss: 4.9439\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 461/600:\n",
            "  Training Loss: 0.2043\n",
            "  Validation Loss: 4.8244\n",
            "  Validation Accuracy: 0.2871\n",
            "Epoch 462/600:\n",
            "  Training Loss: 0.1977\n",
            "  Validation Loss: 4.8121\n",
            "  Validation Accuracy: 0.2890\n",
            "Epoch 463/600:\n",
            "  Training Loss: 0.1952\n",
            "  Validation Loss: 4.8710\n",
            "  Validation Accuracy: 0.2890\n",
            "Epoch 464/600:\n",
            "  Training Loss: 0.2077\n",
            "  Validation Loss: 4.8188\n",
            "  Validation Accuracy: 0.2890\n",
            "Epoch 465/600:\n",
            "  Training Loss: 0.2031\n",
            "  Validation Loss: 4.7248\n",
            "  Validation Accuracy: 0.2700\n",
            "Epoch 466/600:\n",
            "  Training Loss: 0.2085\n",
            "  Validation Loss: 4.8101\n",
            "  Validation Accuracy: 0.2871\n",
            "Epoch 467/600:\n",
            "  Training Loss: 0.1925\n",
            "  Validation Loss: 4.7868\n",
            "  Validation Accuracy: 0.2852\n",
            "Epoch 468/600:\n",
            "  Training Loss: 0.2009\n",
            "  Validation Loss: 4.7425\n",
            "  Validation Accuracy: 0.2871\n",
            "Epoch 469/600:\n",
            "  Training Loss: 0.1923\n",
            "  Validation Loss: 4.8002\n",
            "  Validation Accuracy: 0.3023\n",
            "Epoch 470/600:\n",
            "  Training Loss: 0.1748\n",
            "  Validation Loss: 4.7804\n",
            "  Validation Accuracy: 0.2890\n",
            "Epoch 471/600:\n",
            "  Training Loss: 0.2042\n",
            "  Validation Loss: 4.8193\n",
            "  Validation Accuracy: 0.3004\n",
            "Epoch 472/600:\n",
            "  Training Loss: 0.1924\n",
            "  Validation Loss: 4.8838\n",
            "  Validation Accuracy: 0.2871\n",
            "Epoch 473/600:\n",
            "  Training Loss: 0.2010\n",
            "  Validation Loss: 4.8212\n",
            "  Validation Accuracy: 0.2871\n",
            "Epoch 474/600:\n",
            "  Training Loss: 0.1803\n",
            "  Validation Loss: 4.8142\n",
            "  Validation Accuracy: 0.2890\n",
            "Epoch 475/600:\n",
            "  Training Loss: 0.2088\n",
            "  Validation Loss: 4.7613\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 476/600:\n",
            "  Training Loss: 0.1771\n",
            "  Validation Loss: 4.8248\n",
            "  Validation Accuracy: 0.2890\n",
            "Epoch 477/600:\n",
            "  Training Loss: 0.1747\n",
            "  Validation Loss: 4.8333\n",
            "  Validation Accuracy: 0.2871\n",
            "Epoch 478/600:\n",
            "  Training Loss: 0.1710\n",
            "  Validation Loss: 4.8037\n",
            "  Validation Accuracy: 0.2719\n",
            "Epoch 479/600:\n",
            "  Training Loss: 0.1632\n",
            "  Validation Loss: 4.9040\n",
            "  Validation Accuracy: 0.2814\n",
            "Epoch 480/600:\n",
            "  Training Loss: 0.1668\n",
            "  Validation Loss: 4.8688\n",
            "  Validation Accuracy: 0.2700\n",
            "Epoch 481/600:\n",
            "  Training Loss: 0.1674\n",
            "  Validation Loss: 4.8646\n",
            "  Validation Accuracy: 0.2643\n",
            "Epoch 482/600:\n",
            "  Training Loss: 0.1630\n",
            "  Validation Loss: 4.9314\n",
            "  Validation Accuracy: 0.2719\n",
            "Epoch 483/600:\n",
            "  Training Loss: 0.1595\n",
            "  Validation Loss: 4.8755\n",
            "  Validation Accuracy: 0.2700\n",
            "Epoch 484/600:\n",
            "  Training Loss: 0.1594\n",
            "  Validation Loss: 4.9054\n",
            "  Validation Accuracy: 0.2890\n",
            "Epoch 485/600:\n",
            "  Training Loss: 0.1606\n",
            "  Validation Loss: 4.7899\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 486/600:\n",
            "  Training Loss: 0.1703\n",
            "  Validation Loss: 4.8028\n",
            "  Validation Accuracy: 0.2985\n",
            "Epoch 487/600:\n",
            "  Training Loss: 0.1623\n",
            "  Validation Loss: 4.9307\n",
            "  Validation Accuracy: 0.2852\n",
            "Epoch 488/600:\n",
            "  Training Loss: 0.1716\n",
            "  Validation Loss: 4.8302\n",
            "  Validation Accuracy: 0.2700\n",
            "Epoch 489/600:\n",
            "  Training Loss: 0.1761\n",
            "  Validation Loss: 4.8458\n",
            "  Validation Accuracy: 0.2795\n",
            "Epoch 490/600:\n",
            "  Training Loss: 0.1827\n",
            "  Validation Loss: 4.8812\n",
            "  Validation Accuracy: 0.2833\n",
            "Epoch 491/600:\n",
            "  Training Loss: 0.1875\n",
            "  Validation Loss: 4.8081\n",
            "  Validation Accuracy: 0.2814\n",
            "Epoch 492/600:\n",
            "  Training Loss: 0.1748\n",
            "  Validation Loss: 4.8623\n",
            "  Validation Accuracy: 0.2833\n",
            "Epoch 493/600:\n",
            "  Training Loss: 0.1760\n",
            "  Validation Loss: 4.8682\n",
            "  Validation Accuracy: 0.2776\n",
            "Epoch 494/600:\n",
            "  Training Loss: 0.1629\n",
            "  Validation Loss: 4.7326\n",
            "  Validation Accuracy: 0.2871\n",
            "Epoch 495/600:\n",
            "  Training Loss: 0.1783\n",
            "  Validation Loss: 4.8766\n",
            "  Validation Accuracy: 0.2890\n",
            "Epoch 496/600:\n",
            "  Training Loss: 0.1824\n",
            "  Validation Loss: 4.8347\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 497/600:\n",
            "  Training Loss: 0.1651\n",
            "  Validation Loss: 4.7933\n",
            "  Validation Accuracy: 0.2928\n",
            "Epoch 498/600:\n",
            "  Training Loss: 0.1719\n",
            "  Validation Loss: 4.8250\n",
            "  Validation Accuracy: 0.2871\n",
            "Epoch 499/600:\n",
            "  Training Loss: 0.1695\n",
            "  Validation Loss: 4.8437\n",
            "  Validation Accuracy: 0.2871\n",
            "Epoch 500/600:\n",
            "  Training Loss: 0.1716\n",
            "  Validation Loss: 4.8420\n",
            "  Validation Accuracy: 0.2947\n",
            "Epoch 501/600:\n",
            "  Training Loss: 0.1584\n",
            "  Validation Loss: 4.8235\n",
            "  Validation Accuracy: 0.3004\n",
            "Epoch 502/600:\n",
            "  Training Loss: 0.1714\n",
            "  Validation Loss: 4.8426\n",
            "  Validation Accuracy: 0.2966\n",
            "Epoch 503/600:\n",
            "  Training Loss: 0.1751\n",
            "  Validation Loss: 4.8453\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 504/600:\n",
            "  Training Loss: 0.1735\n",
            "  Validation Loss: 4.9806\n",
            "  Validation Accuracy: 0.2871\n",
            "Epoch 505/600:\n",
            "  Training Loss: 0.1759\n",
            "  Validation Loss: 4.8001\n",
            "  Validation Accuracy: 0.2852\n",
            "Epoch 506/600:\n",
            "  Training Loss: 0.1936\n",
            "  Validation Loss: 4.8757\n",
            "  Validation Accuracy: 0.2985\n",
            "Epoch 507/600:\n",
            "  Training Loss: 0.2010\n",
            "  Validation Loss: 4.8756\n",
            "  Validation Accuracy: 0.2776\n",
            "Epoch 508/600:\n",
            "  Training Loss: 0.1753\n",
            "  Validation Loss: 4.8828\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 509/600:\n",
            "  Training Loss: 0.1790\n",
            "  Validation Loss: 4.8662\n",
            "  Validation Accuracy: 0.2852\n",
            "Epoch 510/600:\n",
            "  Training Loss: 0.1802\n",
            "  Validation Loss: 4.7372\n",
            "  Validation Accuracy: 0.2928\n",
            "Epoch 511/600:\n",
            "  Training Loss: 0.1757\n",
            "  Validation Loss: 4.8584\n",
            "  Validation Accuracy: 0.2738\n",
            "Epoch 512/600:\n",
            "  Training Loss: 0.1795\n",
            "  Validation Loss: 4.8779\n",
            "  Validation Accuracy: 0.2795\n",
            "Epoch 513/600:\n",
            "  Training Loss: 0.1654\n",
            "  Validation Loss: 4.8677\n",
            "  Validation Accuracy: 0.2947\n",
            "Epoch 514/600:\n",
            "  Training Loss: 0.1705\n",
            "  Validation Loss: 4.9156\n",
            "  Validation Accuracy: 0.2776\n",
            "Epoch 515/600:\n",
            "  Training Loss: 0.1606\n",
            "  Validation Loss: 4.8405\n",
            "  Validation Accuracy: 0.2776\n",
            "Epoch 516/600:\n",
            "  Training Loss: 0.1590\n",
            "  Validation Loss: 4.8727\n",
            "  Validation Accuracy: 0.2738\n",
            "Epoch 517/600:\n",
            "  Training Loss: 0.1653\n",
            "  Validation Loss: 4.8521\n",
            "  Validation Accuracy: 0.2795\n",
            "Epoch 518/600:\n",
            "  Training Loss: 0.1645\n",
            "  Validation Loss: 4.8454\n",
            "  Validation Accuracy: 0.2852\n",
            "Epoch 519/600:\n",
            "  Training Loss: 0.1744\n",
            "  Validation Loss: 4.8273\n",
            "  Validation Accuracy: 0.2871\n",
            "Epoch 520/600:\n",
            "  Training Loss: 0.1702\n",
            "  Validation Loss: 4.8519\n",
            "  Validation Accuracy: 0.2871\n",
            "Epoch 521/600:\n",
            "  Training Loss: 0.1629\n",
            "  Validation Loss: 4.7438\n",
            "  Validation Accuracy: 0.2947\n",
            "Epoch 522/600:\n",
            "  Training Loss: 0.1708\n",
            "  Validation Loss: 4.7452\n",
            "  Validation Accuracy: 0.2814\n",
            "Epoch 523/600:\n",
            "  Training Loss: 0.1724\n",
            "  Validation Loss: 4.8062\n",
            "  Validation Accuracy: 0.2814\n",
            "Epoch 524/600:\n",
            "  Training Loss: 0.1638\n",
            "  Validation Loss: 4.7305\n",
            "  Validation Accuracy: 0.2795\n",
            "Epoch 525/600:\n",
            "  Training Loss: 0.1644\n",
            "  Validation Loss: 4.8377\n",
            "  Validation Accuracy: 0.2814\n",
            "Epoch 526/600:\n",
            "  Training Loss: 0.1698\n",
            "  Validation Loss: 4.8132\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 527/600:\n",
            "  Training Loss: 0.1591\n",
            "  Validation Loss: 4.8091\n",
            "  Validation Accuracy: 0.2833\n",
            "Epoch 528/600:\n",
            "  Training Loss: 0.1714\n",
            "  Validation Loss: 4.9509\n",
            "  Validation Accuracy: 0.2833\n",
            "Epoch 529/600:\n",
            "  Training Loss: 0.1605\n",
            "  Validation Loss: 4.9240\n",
            "  Validation Accuracy: 0.2814\n",
            "Epoch 530/600:\n",
            "  Training Loss: 0.1658\n",
            "  Validation Loss: 4.8082\n",
            "  Validation Accuracy: 0.2890\n",
            "Epoch 531/600:\n",
            "  Training Loss: 0.1679\n",
            "  Validation Loss: 4.8035\n",
            "  Validation Accuracy: 0.2757\n",
            "Epoch 532/600:\n",
            "  Training Loss: 0.1586\n",
            "  Validation Loss: 4.9074\n",
            "  Validation Accuracy: 0.2757\n",
            "Epoch 533/600:\n",
            "  Training Loss: 0.1883\n",
            "  Validation Loss: 4.8776\n",
            "  Validation Accuracy: 0.2776\n",
            "Epoch 534/600:\n",
            "  Training Loss: 0.1990\n",
            "  Validation Loss: 4.9295\n",
            "  Validation Accuracy: 0.2776\n",
            "Epoch 535/600:\n",
            "  Training Loss: 0.2037\n",
            "  Validation Loss: 4.8911\n",
            "  Validation Accuracy: 0.2795\n",
            "Epoch 536/600:\n",
            "  Training Loss: 0.2062\n",
            "  Validation Loss: 4.8719\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 537/600:\n",
            "  Training Loss: 0.1964\n",
            "  Validation Loss: 4.7847\n",
            "  Validation Accuracy: 0.2871\n",
            "Epoch 538/600:\n",
            "  Training Loss: 0.2095\n",
            "  Validation Loss: 4.8570\n",
            "  Validation Accuracy: 0.2757\n",
            "Epoch 539/600:\n",
            "  Training Loss: 0.1756\n",
            "  Validation Loss: 4.8504\n",
            "  Validation Accuracy: 0.2947\n",
            "Epoch 540/600:\n",
            "  Training Loss: 0.1965\n",
            "  Validation Loss: 4.7753\n",
            "  Validation Accuracy: 0.2852\n",
            "Epoch 541/600:\n",
            "  Training Loss: 0.1758\n",
            "  Validation Loss: 4.8421\n",
            "  Validation Accuracy: 0.2700\n",
            "Epoch 542/600:\n",
            "  Training Loss: 0.1776\n",
            "  Validation Loss: 4.8636\n",
            "  Validation Accuracy: 0.2833\n",
            "Epoch 543/600:\n",
            "  Training Loss: 0.1798\n",
            "  Validation Loss: 4.7617\n",
            "  Validation Accuracy: 0.2757\n",
            "Epoch 544/600:\n",
            "  Training Loss: 0.1794\n",
            "  Validation Loss: 4.7097\n",
            "  Validation Accuracy: 0.2662\n",
            "Epoch 545/600:\n",
            "  Training Loss: 0.1908\n",
            "  Validation Loss: 4.7645\n",
            "  Validation Accuracy: 0.2662\n",
            "Epoch 546/600:\n",
            "  Training Loss: 0.1686\n",
            "  Validation Loss: 4.8284\n",
            "  Validation Accuracy: 0.2605\n",
            "Epoch 547/600:\n",
            "  Training Loss: 0.1749\n",
            "  Validation Loss: 4.7497\n",
            "  Validation Accuracy: 0.2776\n",
            "Epoch 548/600:\n",
            "  Training Loss: 0.1632\n",
            "  Validation Loss: 4.7719\n",
            "  Validation Accuracy: 0.2833\n",
            "Epoch 549/600:\n",
            "  Training Loss: 0.1744\n",
            "  Validation Loss: 4.7965\n",
            "  Validation Accuracy: 0.2738\n",
            "Epoch 550/600:\n",
            "  Training Loss: 0.1799\n",
            "  Validation Loss: 4.8122\n",
            "  Validation Accuracy: 0.2643\n",
            "Epoch 551/600:\n",
            "  Training Loss: 0.1744\n",
            "  Validation Loss: 4.7825\n",
            "  Validation Accuracy: 0.2700\n",
            "Epoch 552/600:\n",
            "  Training Loss: 0.1686\n",
            "  Validation Loss: 4.7936\n",
            "  Validation Accuracy: 0.2833\n",
            "Epoch 553/600:\n",
            "  Training Loss: 0.1767\n",
            "  Validation Loss: 4.7668\n",
            "  Validation Accuracy: 0.2776\n",
            "Epoch 554/600:\n",
            "  Training Loss: 0.1700\n",
            "  Validation Loss: 4.8154\n",
            "  Validation Accuracy: 0.2662\n",
            "Epoch 555/600:\n",
            "  Training Loss: 0.1733\n",
            "  Validation Loss: 4.8346\n",
            "  Validation Accuracy: 0.2624\n",
            "Epoch 556/600:\n",
            "  Training Loss: 0.1776\n",
            "  Validation Loss: 4.8052\n",
            "  Validation Accuracy: 0.2795\n",
            "Epoch 557/600:\n",
            "  Training Loss: 0.1837\n",
            "  Validation Loss: 4.8463\n",
            "  Validation Accuracy: 0.2890\n",
            "Epoch 558/600:\n",
            "  Training Loss: 0.1672\n",
            "  Validation Loss: 4.8643\n",
            "  Validation Accuracy: 0.2757\n",
            "Epoch 559/600:\n",
            "  Training Loss: 0.1647\n",
            "  Validation Loss: 4.9152\n",
            "  Validation Accuracy: 0.2795\n",
            "Epoch 560/600:\n",
            "  Training Loss: 0.1706\n",
            "  Validation Loss: 4.9173\n",
            "  Validation Accuracy: 0.2757\n",
            "Epoch 561/600:\n",
            "  Training Loss: 0.1682\n",
            "  Validation Loss: 4.9329\n",
            "  Validation Accuracy: 0.2700\n",
            "Epoch 562/600:\n",
            "  Training Loss: 0.1688\n",
            "  Validation Loss: 4.9027\n",
            "  Validation Accuracy: 0.2624\n",
            "Epoch 563/600:\n",
            "  Training Loss: 0.1690\n",
            "  Validation Loss: 4.8197\n",
            "  Validation Accuracy: 0.2852\n",
            "Epoch 564/600:\n",
            "  Training Loss: 0.1578\n",
            "  Validation Loss: 4.8819\n",
            "  Validation Accuracy: 0.2871\n",
            "Epoch 565/600:\n",
            "  Training Loss: 0.1652\n",
            "  Validation Loss: 4.8926\n",
            "  Validation Accuracy: 0.2700\n",
            "Epoch 566/600:\n",
            "  Training Loss: 0.1627\n",
            "  Validation Loss: 4.9538\n",
            "  Validation Accuracy: 0.2681\n",
            "Epoch 567/600:\n",
            "  Training Loss: 0.1668\n",
            "  Validation Loss: 4.9055\n",
            "  Validation Accuracy: 0.2795\n",
            "Epoch 568/600:\n",
            "  Training Loss: 0.1654\n",
            "  Validation Loss: 4.8790\n",
            "  Validation Accuracy: 0.2833\n",
            "Epoch 569/600:\n",
            "  Training Loss: 0.1596\n",
            "  Validation Loss: 4.8536\n",
            "  Validation Accuracy: 0.2890\n",
            "Epoch 570/600:\n",
            "  Training Loss: 0.1669\n",
            "  Validation Loss: 4.7822\n",
            "  Validation Accuracy: 0.2928\n",
            "Epoch 571/600:\n",
            "  Training Loss: 0.1685\n",
            "  Validation Loss: 4.7939\n",
            "  Validation Accuracy: 0.2871\n",
            "Epoch 572/600:\n",
            "  Training Loss: 0.1692\n",
            "  Validation Loss: 4.8474\n",
            "  Validation Accuracy: 0.2833\n",
            "Epoch 573/600:\n",
            "  Training Loss: 0.1697\n",
            "  Validation Loss: 4.8820\n",
            "  Validation Accuracy: 0.2871\n",
            "Epoch 574/600:\n",
            "  Training Loss: 0.1902\n",
            "  Validation Loss: 4.8169\n",
            "  Validation Accuracy: 0.2928\n",
            "Epoch 575/600:\n",
            "  Training Loss: 0.1841\n",
            "  Validation Loss: 4.8663\n",
            "  Validation Accuracy: 0.2890\n",
            "Epoch 576/600:\n",
            "  Training Loss: 0.1702\n",
            "  Validation Loss: 4.9177\n",
            "  Validation Accuracy: 0.2947\n",
            "Epoch 577/600:\n",
            "  Training Loss: 0.1932\n",
            "  Validation Loss: 4.8102\n",
            "  Validation Accuracy: 0.2985\n",
            "Epoch 578/600:\n",
            "  Training Loss: 0.1845\n",
            "  Validation Loss: 4.8639\n",
            "  Validation Accuracy: 0.2833\n",
            "Epoch 579/600:\n",
            "  Training Loss: 0.1818\n",
            "  Validation Loss: 4.8660\n",
            "  Validation Accuracy: 0.2700\n",
            "Epoch 580/600:\n",
            "  Training Loss: 0.1840\n",
            "  Validation Loss: 4.8025\n",
            "  Validation Accuracy: 0.2928\n",
            "Epoch 581/600:\n",
            "  Training Loss: 0.1744\n",
            "  Validation Loss: 4.8496\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 582/600:\n",
            "  Training Loss: 0.1817\n",
            "  Validation Loss: 4.8808\n",
            "  Validation Accuracy: 0.2928\n",
            "Epoch 583/600:\n",
            "  Training Loss: 0.1894\n",
            "  Validation Loss: 4.8091\n",
            "  Validation Accuracy: 0.3080\n",
            "Epoch 584/600:\n",
            "  Training Loss: 0.1712\n",
            "  Validation Loss: 4.7613\n",
            "  Validation Accuracy: 0.3004\n",
            "Epoch 585/600:\n",
            "  Training Loss: 0.1640\n",
            "  Validation Loss: 4.7059\n",
            "  Validation Accuracy: 0.2909\n",
            "Epoch 586/600:\n",
            "  Training Loss: 0.1816\n",
            "  Validation Loss: 4.7047\n",
            "  Validation Accuracy: 0.2966\n",
            "Epoch 587/600:\n",
            "  Training Loss: 0.1697\n",
            "  Validation Loss: 4.7552\n",
            "  Validation Accuracy: 0.3099\n",
            "Epoch 588/600:\n",
            "  Training Loss: 0.1638\n",
            "  Validation Loss: 4.7238\n",
            "  Validation Accuracy: 0.3118\n",
            "Epoch 589/600:\n",
            "  Training Loss: 0.1645\n",
            "  Validation Loss: 4.6793\n",
            "  Validation Accuracy: 0.3023\n",
            "Epoch 590/600:\n",
            "  Training Loss: 0.1584\n",
            "  Validation Loss: 4.6953\n",
            "  Validation Accuracy: 0.3004\n",
            "Epoch 591/600:\n",
            "  Training Loss: 0.1572\n",
            "  Validation Loss: 4.7162\n",
            "  Validation Accuracy: 0.2890\n",
            "Epoch 592/600:\n",
            "  Training Loss: 0.1463\n",
            "  Validation Loss: 4.7979\n",
            "  Validation Accuracy: 0.2947\n",
            "Epoch 593/600:\n",
            "  Training Loss: 0.1497\n",
            "  Validation Loss: 4.9631\n",
            "  Validation Accuracy: 0.2795\n",
            "Epoch 594/600:\n",
            "  Training Loss: 0.1592\n",
            "  Validation Loss: 4.9871\n",
            "  Validation Accuracy: 0.2852\n",
            "Epoch 595/600:\n",
            "  Training Loss: 0.1562\n",
            "  Validation Loss: 4.9816\n",
            "  Validation Accuracy: 0.2833\n",
            "Epoch 596/600:\n",
            "  Training Loss: 0.1624\n",
            "  Validation Loss: 4.9854\n",
            "  Validation Accuracy: 0.2928\n",
            "Epoch 597/600:\n",
            "  Training Loss: 0.1690\n",
            "  Validation Loss: 4.9217\n",
            "  Validation Accuracy: 0.2985\n",
            "Epoch 598/600:\n",
            "  Training Loss: 0.1873\n",
            "  Validation Loss: 4.9105\n",
            "  Validation Accuracy: 0.3137\n",
            "Epoch 599/600:\n",
            "  Training Loss: 0.1881\n",
            "  Validation Loss: 4.7336\n",
            "  Validation Accuracy: 0.2985\n",
            "Epoch 600/600:\n",
            "  Training Loss: 0.2020\n",
            "  Validation Loss: 4.8178\n",
            "  Validation Accuracy: 0.2890\n",
            "\n",
            "Showing 5 translation examples (French â†’ English):\n",
            "\n",
            "Example 1: French Input: Nous rendons visite Ã  nos grands-parents, English Target: We visit our grandparents, English Prediction: e weete t sat ayt  yatt  nn   aa  tttttnnn    nnnn\n",
            "\n",
            "Example 2: French Input: Nous sommes amis, English Target: We are friends, English Prediction: e btk i knsscooosnnnooooorrooooooooooooooossssorro\n",
            "\n",
            "Example 3: French Input: Nous voyageons en train, English Target: We travel by train, English Prediction: e canve  lr giiycdglooooonnnnooooooooooonnnggggllll\n",
            "\n",
            "Example 4: French Input: Elle nage dans l'ocÃ©an, English Target: She swims in the ocean, English Prediction: he tiane sngshesoohscgnoonnnneeeeeeeeooonneessannne\n",
            "\n",
            "Example 5: French Input: Il aime lire des livres, English Target: He enjoys reading books, English Prediction: e w doo  tastacgahrddsoooooooooooooooooooooommmrem\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "import random\n",
        "import ast\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Install python-docx for reading .docx files\n",
        "!pip install python-docx\n",
        "\n",
        "# Path to the .docx file in Google Drive\n",
        "file_path = '/content/drive/My Drive/Dataset_English_to_French.docx'\n",
        "\n",
        "# Load the .docx file\n",
        "from docx import Document\n",
        "doc = Document(file_path)\n",
        "\n",
        "# Extract text\n",
        "text = []\n",
        "for paragraph in doc.paragraphs:\n",
        "    text.append(paragraph.text)\n",
        "\n",
        "# Combine into single string\n",
        "text = '\\n'.join(text)\n",
        "\n",
        "# Extract the list from the text\n",
        "start_index = text.find('[')  # Find the start of the list\n",
        "end_index = text.rfind(']') + 1  # Find the end of the list\n",
        "list_content = text[start_index:end_index]  # Extract the list content\n",
        "\n",
        "# Safely evaluate the list content\n",
        "dataset = ast.literal_eval(list_content)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Special tokens\n",
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "PAD_token = 2  # padding token\n",
        "\n",
        "# Create character mappings\n",
        "all_chars = set(''.join([word for pair in dataset for word in pair]))\n",
        "char_to_index = {\"SOS\": SOS_token, \"EOS\": EOS_token, \"PAD\": PAD_token,\n",
        "                **{char: i+3 for i, char in enumerate(sorted(list(all_chars)))}}\n",
        "index_to_char = {i: char for char, i in char_to_index.items()}\n",
        "vocab_size = len(char_to_index)\n",
        "\n",
        "# Find maximum sequence length in the dataset\n",
        "max_length = max(len(word) for pair in dataset for word in pair) + 1  # +1 for EOS token\n",
        "\n",
        "# Dataset class with proper padding\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, dataset, char_to_index, max_length):\n",
        "        self.dataset = dataset\n",
        "        self.char_to_index = char_to_index\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Swap input (French) and target (English)\n",
        "        target_word, input_word = self.dataset[idx]  # Reverse the order\n",
        "\n",
        "        # Convert to indices and add EOS\n",
        "        input_indices = [self.char_to_index[char] for char in input_word] + [EOS_token]\n",
        "        target_indices = [self.char_to_index[char] for char in target_word] + [EOS_token]\n",
        "\n",
        "        # Pad sequences to max_length\n",
        "        input_padded = input_indices + [PAD_token] * (self.max_length - len(input_indices))\n",
        "        target_padded = target_indices + [PAD_token] * (self.max_length - len(target_indices))\n",
        "\n",
        "        return (\n",
        "            torch.tensor(input_padded[:self.max_length], dtype=torch.long),\n",
        "            torch.tensor(target_padded[:self.max_length], dtype=torch.long)\n",
        "        )\n",
        "\n",
        "# Custom collate function to handle padding\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = zip(*batch)\n",
        "    src_batch = torch.stack(src_batch)\n",
        "    tgt_batch = torch.stack(tgt_batch)\n",
        "    return src_batch, tgt_batch\n",
        "\n",
        "# Positional Encoding\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]\n",
        "\n",
        "# Transformer Model\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model=256, nhead=2, num_layers=1, dropout=0.01): # Number of Heads and Layers\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model, padding_idx=PAD_token)\n",
        "        self.pos_encoder = PositionalEncoding(d_model)\n",
        "\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            num_encoder_layers=num_layers,\n",
        "            num_decoder_layers=num_layers,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, src, tgt, src_mask=None, tgt_mask=None):\n",
        "        # Create source and target masks\n",
        "        src_key_padding_mask = (src == PAD_token)\n",
        "        tgt_key_padding_mask = (tgt == PAD_token)\n",
        "\n",
        "        # Embedding and positional encoding\n",
        "        src = self.embedding(src) * math.sqrt(self.d_model)\n",
        "        src = self.pos_encoder(src)\n",
        "\n",
        "        tgt = self.embedding(tgt) * math.sqrt(self.d_model)\n",
        "        tgt = self.pos_encoder(tgt)\n",
        "\n",
        "        # Create attention masks\n",
        "        if tgt_mask is None:\n",
        "            tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt.size(1)).to(device)\n",
        "\n",
        "        # Transformer\n",
        "        output = self.transformer(\n",
        "            src, tgt,\n",
        "            tgt_mask=tgt_mask,\n",
        "            src_key_padding_mask=src_key_padding_mask,\n",
        "            tgt_key_padding_mask=tgt_key_padding_mask\n",
        "        )\n",
        "        output = self.fc_out(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "def calculate_accuracy(model, dataloader):\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src, tgt in dataloader:\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "            tgt_input = tgt[:, :-1]\n",
        "            tgt_output = tgt[:, 1:]\n",
        "\n",
        "            output = model(src, tgt_input)\n",
        "            preds = output.argmax(dim=-1)\n",
        "\n",
        "            # Mask for non-padding tokens\n",
        "            mask = (tgt_output != PAD_token)\n",
        "            total += mask.sum().item()\n",
        "            correct += (preds == tgt_output)[mask].sum().item()\n",
        "\n",
        "    return correct / total if total > 0 else 0\n",
        "\n",
        "def evaluate(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_batches = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src, tgt in dataloader:\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "            tgt_input = tgt[:, :-1]\n",
        "            tgt_output = tgt[:, 1:]\n",
        "\n",
        "            output = model(src, tgt_input)\n",
        "            loss = criterion(output.reshape(-1, output.size(-1)), tgt_output.reshape(-1))\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_batches += 1\n",
        "\n",
        "    return total_loss / total_batches if total_batches > 0 else 0\n",
        "\n",
        "# Train\n",
        "def train_model(model, train_dataloader, val_dataloader, n_epochs, learning_rate=0.001):\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=PAD_token)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        train_batches = 0\n",
        "\n",
        "        for src, tgt in train_dataloader:\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "\n",
        "            # Prepare input and output\n",
        "            tgt_input = tgt[:, :-1]\n",
        "            tgt_output = tgt[:, 1:]\n",
        "\n",
        "            # Forward pass\n",
        "            optimizer.zero_grad()\n",
        "            output = model(src, tgt_input)\n",
        "\n",
        "            # Calculate loss (ignoring padding tokens)\n",
        "            loss = criterion(output.reshape(-1, output.size(-1)), tgt_output.reshape(-1))\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            train_batches += 1\n",
        "\n",
        "        # Calculate metrics\n",
        "        avg_train_loss = train_loss / train_batches\n",
        "        avg_val_loss = evaluate(model, val_dataloader, criterion)\n",
        "        val_accuracy = calculate_accuracy(model, val_dataloader)\n",
        "\n",
        "        # Print progress\n",
        "        print(f'Epoch {epoch+1}/{n_epochs}:')\n",
        "        print(f'  Training Loss: {avg_train_loss:.4f}')\n",
        "        print(f'  Validation Loss: {avg_val_loss:.4f}')\n",
        "        print(f'  Validation Accuracy: {val_accuracy:.4f}')\n",
        "\n",
        "        # Save best model\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "            print('  (Model saved)')\n",
        "\n",
        "\n",
        "#Examples\n",
        "def show_examples(model, dataloader, index_to_char, n_examples):\n",
        "    model.eval()\n",
        "    example_count = 0\n",
        "\n",
        "    print(f\"\\nShowing {n_examples} translation examples (French â†’ English):\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src, tgt in dataloader:\n",
        "            if example_count >= n_examples:\n",
        "                break\n",
        "\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "            tgt_input = tgt[:, :-1]\n",
        "            output = model(src, tgt_input)\n",
        "            preds = output.argmax(dim=-1)\n",
        "\n",
        "            def indices_to_str(indices):\n",
        "                return ''.join([index_to_char.get(idx.item(), '?')\n",
        "                              for idx in indices\n",
        "                              if idx not in (SOS_token, EOS_token, PAD_token)])\n",
        "\n",
        "            for i in range(src.size(0)):\n",
        "                if example_count >= n_examples:\n",
        "                    break\n",
        "\n",
        "                print(f\"\\nExample {example_count + 1}: French Input: {indices_to_str(src[i])}, English Target: {indices_to_str(tgt[i])}, English Prediction: {indices_to_str(preds[i])}\")\n",
        "\n",
        "                example_count += 1\n",
        "\n",
        "# Split dataset (now French â†’ English)\n",
        "train_data, val_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create dataloaders (input=French, target=English)\n",
        "train_dataset = TranslationDataset(train_data, char_to_index, max_length)\n",
        "val_dataset = TranslationDataset(val_data, char_to_index, max_length)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "# Initialize model (same architecture)\n",
        "model = TransformerModel(vocab_size).to(device)\n",
        "\n",
        "# Train the model (French â†’ English)\n",
        "print(\"Starting training (French â†’ English)...\")\n",
        "train_model(model, train_dataloader, val_dataloader, n_epochs=600) # Number of Epochs\n",
        "\n",
        "# Show examples (French â†’ English)\n",
        "show_examples(model, val_dataloader, index_to_char, n_examples=5) # NUmber of examples"
      ]
    }
  ]
}