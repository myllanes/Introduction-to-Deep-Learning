{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyOcv+ElFNNPPfRrzH9H6tEe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/myllanes/Introduction-to-Deep-Learning/blob/main/HW6_1_RES_18.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vknqjf3TBAF5",
        "outputId": "82bfbd2f-ad29-4d54-f6ab-4b80899a5e03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "Starting training...\n",
            "\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 391/391 [00:17<00:00, 21.94it/s]\n",
            "Evaluating: 100%|██████████| 79/79 [00:01<00:00, 75.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time: 18.87s\n",
            "Train Loss: 3.5005 | Train Acc: 23.20%\n",
            "Val Loss: 2.5645 | Val Acc: 45.18%\n",
            "\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 391/391 [00:17<00:00, 21.84it/s]\n",
            "Evaluating: 100%|██████████| 79/79 [00:01<00:00, 75.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time: 18.96s\n",
            "Train Loss: 2.5964 | Train Acc: 44.65%\n",
            "Val Loss: 2.1821 | Val Acc: 56.73%\n",
            "\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 391/391 [00:18<00:00, 21.68it/s]\n",
            "Evaluating: 100%|██████████| 79/79 [00:01<00:00, 75.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time: 19.09s\n",
            "Train Loss: 2.2820 | Train Acc: 53.51%\n",
            "Val Loss: 2.0465 | Val Acc: 60.62%\n",
            "\n",
            "Epoch 4/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 391/391 [00:17<00:00, 21.84it/s]\n",
            "Evaluating: 100%|██████████| 79/79 [00:01<00:00, 75.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time: 18.96s\n",
            "Train Loss: 2.0972 | Train Acc: 59.21%\n",
            "Val Loss: 1.9244 | Val Acc: 64.36%\n",
            "\n",
            "Epoch 5/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 391/391 [00:17<00:00, 22.03it/s]\n",
            "Evaluating: 100%|██████████| 79/79 [00:01<00:00, 76.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time: 18.78s\n",
            "Train Loss: 1.9527 | Train Acc: 63.86%\n",
            "Val Loss: 1.8626 | Val Acc: 66.71%\n",
            "\n",
            "Epoch 6/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 391/391 [00:17<00:00, 22.07it/s]\n",
            "Evaluating: 100%|██████████| 79/79 [00:01<00:00, 77.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time: 18.75s\n",
            "Train Loss: 1.8446 | Train Acc: 67.20%\n",
            "Val Loss: 1.8111 | Val Acc: 68.18%\n",
            "\n",
            "Epoch 7/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 391/391 [00:17<00:00, 22.03it/s]\n",
            "Evaluating: 100%|██████████| 79/79 [00:01<00:00, 76.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time: 18.79s\n",
            "Train Loss: 1.7622 | Train Acc: 69.97%\n",
            "Val Loss: 1.7685 | Val Acc: 69.28%\n",
            "\n",
            "Epoch 8/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 391/391 [00:17<00:00, 21.94it/s]\n",
            "Evaluating: 100%|██████████| 79/79 [00:01<00:00, 74.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time: 18.89s\n",
            "Train Loss: 1.6968 | Train Acc: 72.39%\n",
            "Val Loss: 1.7407 | Val Acc: 70.47%\n",
            "\n",
            "Epoch 9/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 391/391 [00:17<00:00, 21.87it/s]\n",
            "Evaluating: 100%|██████████| 79/79 [00:01<00:00, 76.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time: 18.92s\n",
            "Train Loss: 1.6501 | Train Acc: 73.79%\n",
            "Val Loss: 1.7290 | Val Acc: 70.78%\n",
            "\n",
            "Epoch 10/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 391/391 [00:17<00:00, 21.90it/s]\n",
            "Evaluating: 100%|██████████| 79/79 [00:01<00:00, 74.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time: 18.92s\n",
            "Train Loss: 1.6318 | Train Acc: 74.48%\n",
            "Val Loss: 1.7241 | Val Acc: 70.97%\n",
            "Total Training Time: 188.92 seconds\n",
            "Average Time per Epoch: 18.89 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Michael Yllanes\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Hyperparameters\n",
        "num_classes = 100     # 100 classes for CIFAR-100\n",
        "batch_size = 64      # batch size\n",
        "num_epochs = 30       # Training epochs\n",
        "learning_rate = 0.001\n",
        "weight_decay = 1e-4   # Weight decay\n",
        "\n",
        "# Enhanced data for CIFAR-100\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))  # CIFAR-100 stats\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))\n",
        "])\n",
        "\n",
        "# CIFAR-100 dataset\n",
        "train_dataset = torchvision.datasets.CIFAR100(\n",
        "    root='./data', train=True, download=True, transform=train_transform)\n",
        "test_dataset = torchvision.datasets.CIFAR100(\n",
        "    root='./data', train=False, download=True, transform=test_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                         shuffle=True, num_workers=4, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size,\n",
        "                         shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "class ResNet18_CIFAR100(nn.Module):\n",
        "    \"\"\"Modified ResNet-18 for CIFAR-100 classification\"\"\"\n",
        "    def __init__(self, pretrained=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # ResNet-18\n",
        "        if pretrained:\n",
        "            self.resnet = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "        else:\n",
        "            self.resnet = resnet18(weights=None)\n",
        "\n",
        "        # onvolution\n",
        "        self.resnet.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.resnet.maxpool = nn.Identity()\n",
        "\n",
        "\n",
        "        in_features = self.resnet.fc.in_features\n",
        "        self.resnet.fc = nn.Sequential(\n",
        "            nn.Dropout(0.3),  # dropout for regularization\n",
        "            nn.Linear(in_features, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet(x)\n",
        "\n",
        "# Initialize model\n",
        "model = ResNet18_CIFAR100(pretrained=True).to(device)\n",
        "\n",
        "# Loss function with label smoothing\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "\n",
        "# Optimizer with weight decay\n",
        "optimizer = torch.optim.AdamW(\n",
        "    [\n",
        "        {'params': [p for n, p in model.named_parameters()\n",
        "                   if 'fc' not in n and p.requires_grad], 'lr': learning_rate/10},\n",
        "        {'params': model.resnet.fc.parameters(), 'lr': learning_rate}\n",
        "    ],\n",
        "    weight_decay=weight_decay\n",
        ")\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "\n",
        "def train_epoch(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss, total_correct, total_samples = 0, 0, 0\n",
        "\n",
        "    for images, labels in tqdm(loader, desc=\"Training\"):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Metrics\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_samples += labels.size(0)\n",
        "        total_correct += (predicted == labels).sum().item()\n",
        "        total_loss += loss.item() * labels.size(0)\n",
        "\n",
        "    avg_loss = total_loss / total_samples\n",
        "    accuracy = 100 * total_correct / total_samples\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "def evaluate(model, loader, criterion):\n",
        "    model.eval()\n",
        "    total_loss, total_correct, total_samples = 0, 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(loader, desc=\"Evaluating\"):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_samples += labels.size(0)\n",
        "            total_correct += (predicted == labels).sum().item()\n",
        "            total_loss += loss.item() * labels.size(0)\n",
        "\n",
        "    avg_loss = total_loss / total_samples\n",
        "    accuracy = 100 * total_correct / total_samples\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "# Training loop with validation and timing\n",
        "best_acc = 0.0\n",
        "total_training_time = 0.0\n",
        "\n",
        "print(\"\\nStarting training...\")\n",
        "overall_start_time = time.time()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_start_time = time.time()\n",
        "\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion)\n",
        "    val_loss, val_acc = evaluate(model, test_loader, criterion)\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    # Calculate epoch time\n",
        "    epoch_time = time.time() - epoch_start_time\n",
        "    total_training_time += epoch_time\n",
        "\n",
        "    # Print metrics\n",
        "    print(f\"Time: {epoch_time:.2f}s\")\n",
        "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
        "    print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "# Calculate total training time\n",
        "total_time = time.time() - overall_start_time\n",
        "\n",
        "\n",
        "# Print final results and timing information\n",
        "print(f\"Total Training Time: {total_time:.2f} seconds\")\n",
        "print(f\"Average Time per Epoch: {total_time/num_epochs:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo\n",
        "from torchinfo import summary\n",
        "import time\n",
        "\n",
        "# Using torchinfo\n",
        "# Model summary\n",
        "summary(model, input_size=(batch_size, 3, 32, 32),\n",
        "       verbose=1, col_names=[\"input_size\", \"output_size\", \"num_params\", \"mult_adds\"])\n",
        "\n",
        "# Timing\n",
        "starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
        "repetitions = 100\n",
        "timings = []\n",
        "\n",
        "for _ in range(10):\n",
        "    _ = model(torch.randn(batch_size, 3, 32, 32).to(device))\n",
        "\n",
        "# Measurement\n",
        "with torch.no_grad():\n",
        "    for _ in range(repetitions):\n",
        "        inputs = torch.randn(batch_size, 3, 32, 32).to(device)\n",
        "        starter.record()\n",
        "        _ = model(inputs)\n",
        "        ender.record()\n",
        "        torch.cuda.synchronize()\n",
        "        timings.append(starter.elapsed_time(ender))\n",
        "\n",
        "avg_time = sum(timings) / repetitions\n",
        "print(f\"Average forward pass time: {avg_time:.2f}ms\")\n",
        "print(f\"Throughput: {1000/(avg_time)*batch_size:.0f} samples/sec\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t771xzJUpawu",
        "outputId": "494a6429-23ba-409f-e7bf-d85db7778ce4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n",
            "=================================================================================================================================================\n",
            "Layer (type:depth-idx)                        Input Shape               Output Shape              Param #                   Mult-Adds\n",
            "=================================================================================================================================================\n",
            "ResNet18_CIFAR100                             [64, 3, 32, 32]           [64, 100]                 --                        --\n",
            "├─ResNet: 1-1                                 [64, 3, 32, 32]           [64, 100]                 --                        --\n",
            "│    └─Conv2d: 2-1                            [64, 3, 32, 32]           [64, 64, 32, 32]          1,728                     113,246,208\n",
            "│    └─BatchNorm2d: 2-2                       [64, 64, 32, 32]          [64, 64, 32, 32]          128                       8,192\n",
            "│    └─ReLU: 2-3                              [64, 64, 32, 32]          [64, 64, 32, 32]          --                        --\n",
            "│    └─Identity: 2-4                          [64, 64, 32, 32]          [64, 64, 32, 32]          --                        --\n",
            "│    └─Sequential: 2-5                        [64, 64, 32, 32]          [64, 64, 32, 32]          --                        --\n",
            "│    │    └─BasicBlock: 3-1                   [64, 64, 32, 32]          [64, 64, 32, 32]          73,984                    4,831,854,592\n",
            "│    │    └─BasicBlock: 3-2                   [64, 64, 32, 32]          [64, 64, 32, 32]          73,984                    4,831,854,592\n",
            "│    └─Sequential: 2-6                        [64, 64, 32, 32]          [64, 128, 16, 16]         --                        --\n",
            "│    │    └─BasicBlock: 3-3                   [64, 64, 32, 32]          [64, 128, 16, 16]         230,144                   3,758,145,536\n",
            "│    │    └─BasicBlock: 3-4                   [64, 128, 16, 16]         [64, 128, 16, 16]         295,424                   4,831,870,976\n",
            "│    └─Sequential: 2-7                        [64, 128, 16, 16]         [64, 256, 8, 8]           --                        --\n",
            "│    │    └─BasicBlock: 3-5                   [64, 128, 16, 16]         [64, 256, 8, 8]           919,040                   3,758,194,688\n",
            "│    │    └─BasicBlock: 3-6                   [64, 256, 8, 8]           [64, 256, 8, 8]           1,180,672                 4,831,903,744\n",
            "│    └─Sequential: 2-8                        [64, 256, 8, 8]           [64, 512, 4, 4]           --                        --\n",
            "│    │    └─BasicBlock: 3-7                   [64, 256, 8, 8]           [64, 512, 4, 4]           3,673,088                 3,758,292,992\n",
            "│    │    └─BasicBlock: 3-8                   [64, 512, 4, 4]           [64, 512, 4, 4]           4,720,640                 4,831,969,280\n",
            "│    └─AdaptiveAvgPool2d: 2-9                 [64, 512, 4, 4]           [64, 512, 1, 1]           --                        --\n",
            "│    └─Sequential: 2-10                       [64, 512]                 [64, 100]                 --                        --\n",
            "│    │    └─Dropout: 3-9                      [64, 512]                 [64, 512]                 --                        --\n",
            "│    │    └─Linear: 3-10                      [64, 512]                 [64, 100]                 51,300                    3,283,200\n",
            "=================================================================================================================================================\n",
            "Total params: 11,220,132\n",
            "Trainable params: 11,220,132\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 35.55\n",
            "=================================================================================================================================================\n",
            "Input size (MB): 0.79\n",
            "Forward/backward pass size (MB): 629.20\n",
            "Params size (MB): 44.88\n",
            "Estimated Total Size (MB): 674.86\n",
            "=================================================================================================================================================\n",
            "Average forward pass time: 4.62ms\n",
            "Throughput: 13847 samples/sec\n"
          ]
        }
      ]
    }
  ]
}