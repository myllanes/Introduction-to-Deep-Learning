{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "mount_file_id": "14CLN1pAxkKignjjzqqSpqFkzU0LiNIFd",
      "authorship_tag": "ABX9TyPc3c5dkRZdsMQS8kYcZApE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/myllanes/Introduction-to-Deep-Learning/blob/main/HW5_3_English_To_French.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Michael Yllanes\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OqjxUDqSQoQ",
        "outputId": "c8ddd836-2668-45c0-f5dc-b91379036cb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNe7lBwqG__w"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "import random\n",
        "import ast\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Install python-docx for reading .docx files\n",
        "!pip install python-docx\n",
        "\n",
        "# Path to the .docx file in Google Drive\n",
        "file_path = '/content/drive/My Drive/Dataset_English_to_French.docx'\n",
        "\n",
        "# Load the .docx file\n",
        "from docx import Document\n",
        "doc = Document(file_path)\n",
        "\n",
        "# Extract text\n",
        "text = []\n",
        "for paragraph in doc.paragraphs:\n",
        "    text.append(paragraph.text)\n",
        "\n",
        "# Combine into single string\n",
        "text = '\\n'.join(text)\n",
        "\n",
        "# Extract the list from the text\n",
        "start_index = text.find('[')  # Find the start of the list\n",
        "end_index = text.rfind(']') + 1  # Find the end of the list\n",
        "list_content = text[start_index:end_index]  # Extract the list content\n",
        "\n",
        "# Safely evaluate the list content\n",
        "dataset = ast.literal_eval(list_content)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Special tokens\n",
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "PAD_token = 2  # Padding token\n",
        "\n",
        "# Create character mappings\n",
        "all_chars = set(''.join([word for pair in dataset for word in pair]))\n",
        "char_to_index = {\"SOS\": SOS_token, \"EOS\": EOS_token, \"PAD\": PAD_token,\n",
        "                **{char: i+3 for i, char in enumerate(sorted(list(all_chars)))}}\n",
        "index_to_char = {i: char for char, i in char_to_index.items()}\n",
        "vocab_size = len(char_to_index)\n",
        "\n",
        "# Find maximum sequence length in the dataset\n",
        "max_length = max(len(word) for pair in dataset for word in pair) + 1  # +1 for EOS token\n",
        "\n",
        "# Dataset class with proper padding\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, dataset, char_to_index, max_length):\n",
        "        self.dataset = dataset\n",
        "        self.char_to_index = char_to_index\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_word, target_word = self.dataset[idx]\n",
        "\n",
        "        # Convert to indices and add EOS\n",
        "        input_indices = [self.char_to_index[char] for char in input_word] + [EOS_token]\n",
        "        target_indices = [self.char_to_index[char] for char in target_word] + [EOS_token]\n",
        "\n",
        "        # Pad sequences to max_length\n",
        "        input_padded = input_indices + [PAD_token] * (self.max_length - len(input_indices))\n",
        "        target_padded = target_indices + [PAD_token] * (self.max_length - len(target_indices))\n",
        "\n",
        "        return (\n",
        "            torch.tensor(input_padded[:self.max_length], dtype=torch.long),\n",
        "            torch.tensor(target_padded[:self.max_length], dtype=torch.long)\n",
        "        )\n",
        "\n",
        "# collate function\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = zip(*batch)\n",
        "    src_batch = torch.stack(src_batch)\n",
        "    tgt_batch = torch.stack(tgt_batch)\n",
        "    return src_batch, tgt_batch\n",
        "\n",
        "# Positional Encoding\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]\n",
        "\n",
        "# Transformer Model\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model=256, nhead=2, num_layers=3, dropout=0.01): # Number of Heads and Layers\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model, padding_idx=PAD_token)\n",
        "        self.pos_encoder = PositionalEncoding(d_model)\n",
        "\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            num_encoder_layers=num_layers,\n",
        "            num_decoder_layers=num_layers,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, src, tgt, src_mask=None, tgt_mask=None):\n",
        "        # Create source and target masks\n",
        "        src_key_padding_mask = (src == PAD_token)\n",
        "        tgt_key_padding_mask = (tgt == PAD_token)\n",
        "\n",
        "        # Embedding and positional encoding\n",
        "        src = self.embedding(src) * math.sqrt(self.d_model)\n",
        "        src = self.pos_encoder(src)\n",
        "\n",
        "        tgt = self.embedding(tgt) * math.sqrt(self.d_model)\n",
        "        tgt = self.pos_encoder(tgt)\n",
        "\n",
        "        # Create attention masks\n",
        "        if tgt_mask is None:\n",
        "            tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt.size(1)).to(device)\n",
        "\n",
        "        # Transformer\n",
        "        output = self.transformer(\n",
        "            src, tgt,\n",
        "            tgt_mask=tgt_mask,\n",
        "            src_key_padding_mask=src_key_padding_mask,\n",
        "            tgt_key_padding_mask=tgt_key_padding_mask\n",
        "        )\n",
        "        output = self.fc_out(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "def calculate_accuracy(model, dataloader):\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src, tgt in dataloader:\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "            tgt_input = tgt[:, :-1]\n",
        "            tgt_output = tgt[:, 1:]\n",
        "\n",
        "            output = model(src, tgt_input)\n",
        "            preds = output.argmax(dim=-1)\n",
        "\n",
        "            # Mask for non-padding tokens\n",
        "            mask = (tgt_output != PAD_token)\n",
        "            total += mask.sum().item()\n",
        "            correct += (preds == tgt_output)[mask].sum().item()\n",
        "\n",
        "    return correct / total if total > 0 else 0\n",
        "\n",
        "def evaluate(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_batches = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src, tgt in dataloader:\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "            tgt_input = tgt[:, :-1]\n",
        "            tgt_output = tgt[:, 1:]\n",
        "\n",
        "            output = model(src, tgt_input)\n",
        "            loss = criterion(output.reshape(-1, output.size(-1)), tgt_output.reshape(-1))\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_batches += 1\n",
        "\n",
        "    return total_loss / total_batches if total_batches > 0 else 0\n",
        "\n",
        "def train_model(model, train_dataloader, val_dataloader, n_epochs, learning_rate=0.001):\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=PAD_token)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        train_batches = 0\n",
        "\n",
        "        for src, tgt in train_dataloader:\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "\n",
        "            # Prepare input and output\n",
        "            tgt_input = tgt[:, :-1]\n",
        "            tgt_output = tgt[:, 1:]\n",
        "\n",
        "            # Forward pass\n",
        "            optimizer.zero_grad()\n",
        "            output = model(src, tgt_input)\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = criterion(output.reshape(-1, output.size(-1)), tgt_output.reshape(-1))\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            train_batches += 1\n",
        "\n",
        "        # Calculate metrics\n",
        "        avg_train_loss = train_loss / train_batches\n",
        "        avg_val_loss = evaluate(model, val_dataloader, criterion)\n",
        "        val_accuracy = calculate_accuracy(model, val_dataloader)\n",
        "\n",
        "        # Print progress\n",
        "        print(f'Epoch {epoch+1}/{n_epochs}:')\n",
        "        print(f'  Training Loss: {avg_train_loss:.4f}')\n",
        "        print(f'  Validation Loss: {avg_val_loss:.4f}')\n",
        "        print(f'  Validation Accuracy: {val_accuracy:.4f}')\n",
        "\n",
        "        # Save best model\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "            print('  (Model saved)')\n",
        "\n",
        "\n",
        "\n",
        "def show_examples(model, dataloader, index_to_char, n_examples):\n",
        "    model.eval()\n",
        "    example_count = 0\n",
        "\n",
        "    print(f\"\\nShowing {n_examples} translation examples:\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src, tgt in dataloader:\n",
        "            if example_count >= n_examples:\n",
        "                break\n",
        "\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "            tgt_input = tgt[:, :-1]\n",
        "            output = model(src, tgt_input)\n",
        "            preds = output.argmax(dim=-1)\n",
        "\n",
        "            # Convert indices to characters\n",
        "            def indices_to_str(indices):\n",
        "                return ''.join([index_to_char.get(idx.item(), '?')\n",
        "                              for idx in indices\n",
        "                              if idx not in (SOS_token, EOS_token, PAD_token)])\n",
        "\n",
        "            # Print all examples\n",
        "            for i in range(src.size(0)):\n",
        "                if example_count >= n_examples:\n",
        "                    break\n",
        "\n",
        "                print(f\"\\nExample {example_count + 1}: Input: {indices_to_str(src[i])}, Target: {indices_to_str(tgt[i])}, Prediction: {indices_to_str(preds[i])}\")\n",
        "\n",
        "                example_count += 1\n",
        "\n",
        "# Split dataset\n",
        "train_data, val_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create dataloaders with custom collate function\n",
        "train_dataset = TranslationDataset(train_data, char_to_index, max_length)\n",
        "val_dataset = TranslationDataset(val_data, char_to_index, max_length)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "# Initialize model\n",
        "model = TransformerModel(vocab_size).to(device)\n",
        "\n",
        "# Train the model\n",
        "print(\"Starting training...\")\n",
        "train_model(model, train_dataloader, val_dataloader, n_epochs=400) # Epochss\n",
        "\n",
        "# Show examples after training\n",
        "show_examples(model, val_dataloader, index_to_char, n_examples=5) # Examples"
      ]
    }
  ]
}