{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "mount_file_id": "14CLN1pAxkKignjjzqqSpqFkzU0LiNIFd",
      "authorship_tag": "ABX9TyNE25na+8FRjOm08RKmPnCx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/myllanes/Introduction-to-Deep-Learning/blob/main/HW5_3_English_To_French.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Michael Yllanes\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OqjxUDqSQoQ",
        "outputId": "c8ddd836-2668-45c0-f5dc-b91379036cb0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "kNe7lBwqG__w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b83a7505-2500-4019-ed8f-71529628d3e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.11/dist-packages (1.1.2)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.3.1)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.13.0)\n",
            "Starting training...\n",
            "Epoch 1/400:\n",
            "  Training Loss: 3.7223\n",
            "  Validation Loss: 3.3551\n",
            "  Validation Accuracy: 0.1146\n",
            "  (Model saved)\n",
            "Epoch 2/400:\n",
            "  Training Loss: 3.1380\n",
            "  Validation Loss: 3.0501\n",
            "  Validation Accuracy: 0.1429\n",
            "  (Model saved)\n",
            "Epoch 3/400:\n",
            "  Training Loss: 2.9928\n",
            "  Validation Loss: 3.0444\n",
            "  Validation Accuracy: 0.1146\n",
            "  (Model saved)\n",
            "Epoch 4/400:\n",
            "  Training Loss: 2.9552\n",
            "  Validation Loss: 3.0449\n",
            "  Validation Accuracy: 0.1229\n",
            "Epoch 5/400:\n",
            "  Training Loss: 2.9397\n",
            "  Validation Loss: 3.0346\n",
            "  Validation Accuracy: 0.1429\n",
            "  (Model saved)\n",
            "Epoch 6/400:\n",
            "  Training Loss: 2.9241\n",
            "  Validation Loss: 3.0152\n",
            "  Validation Accuracy: 0.1512\n",
            "  (Model saved)\n",
            "Epoch 7/400:\n",
            "  Training Loss: 2.9116\n",
            "  Validation Loss: 2.9876\n",
            "  Validation Accuracy: 0.1728\n",
            "  (Model saved)\n",
            "Epoch 8/400:\n",
            "  Training Loss: 2.8693\n",
            "  Validation Loss: 2.8888\n",
            "  Validation Accuracy: 0.2209\n",
            "  (Model saved)\n",
            "Epoch 9/400:\n",
            "  Training Loss: 2.7553\n",
            "  Validation Loss: 2.8072\n",
            "  Validation Accuracy: 0.2824\n",
            "  (Model saved)\n",
            "Epoch 10/400:\n",
            "  Training Loss: 2.6059\n",
            "  Validation Loss: 2.6537\n",
            "  Validation Accuracy: 0.3173\n",
            "  (Model saved)\n",
            "Epoch 11/400:\n",
            "  Training Loss: 2.4859\n",
            "  Validation Loss: 2.5414\n",
            "  Validation Accuracy: 0.3223\n",
            "  (Model saved)\n",
            "Epoch 12/400:\n",
            "  Training Loss: 2.3230\n",
            "  Validation Loss: 2.4669\n",
            "  Validation Accuracy: 0.3289\n",
            "  (Model saved)\n",
            "Epoch 13/400:\n",
            "  Training Loss: 2.1944\n",
            "  Validation Loss: 2.4635\n",
            "  Validation Accuracy: 0.3056\n",
            "  (Model saved)\n",
            "Epoch 14/400:\n",
            "  Training Loss: 2.1351\n",
            "  Validation Loss: 2.5309\n",
            "  Validation Accuracy: 0.2807\n",
            "Epoch 15/400:\n",
            "  Training Loss: 2.1163\n",
            "  Validation Loss: 2.4501\n",
            "  Validation Accuracy: 0.3056\n",
            "  (Model saved)\n",
            "Epoch 16/400:\n",
            "  Training Loss: 2.0233\n",
            "  Validation Loss: 2.3557\n",
            "  Validation Accuracy: 0.3173\n",
            "  (Model saved)\n",
            "Epoch 17/400:\n",
            "  Training Loss: 1.9462\n",
            "  Validation Loss: 2.3564\n",
            "  Validation Accuracy: 0.3073\n",
            "Epoch 18/400:\n",
            "  Training Loss: 1.8965\n",
            "  Validation Loss: 2.3274\n",
            "  Validation Accuracy: 0.3389\n",
            "  (Model saved)\n",
            "Epoch 19/400:\n",
            "  Training Loss: 1.8468\n",
            "  Validation Loss: 2.3285\n",
            "  Validation Accuracy: 0.3007\n",
            "Epoch 20/400:\n",
            "  Training Loss: 1.7798\n",
            "  Validation Loss: 2.3663\n",
            "  Validation Accuracy: 0.3223\n",
            "Epoch 21/400:\n",
            "  Training Loss: 1.7419\n",
            "  Validation Loss: 2.3725\n",
            "  Validation Accuracy: 0.3223\n",
            "Epoch 22/400:\n",
            "  Training Loss: 1.7011\n",
            "  Validation Loss: 2.3657\n",
            "  Validation Accuracy: 0.3272\n",
            "Epoch 23/400:\n",
            "  Training Loss: 1.6757\n",
            "  Validation Loss: 2.3778\n",
            "  Validation Accuracy: 0.3339\n",
            "Epoch 24/400:\n",
            "  Training Loss: 1.6265\n",
            "  Validation Loss: 2.4053\n",
            "  Validation Accuracy: 0.3156\n",
            "Epoch 25/400:\n",
            "  Training Loss: 1.5514\n",
            "  Validation Loss: 2.4159\n",
            "  Validation Accuracy: 0.3106\n",
            "Epoch 26/400:\n",
            "  Training Loss: 1.5033\n",
            "  Validation Loss: 2.3886\n",
            "  Validation Accuracy: 0.3189\n",
            "Epoch 27/400:\n",
            "  Training Loss: 1.4846\n",
            "  Validation Loss: 2.4442\n",
            "  Validation Accuracy: 0.3322\n",
            "Epoch 28/400:\n",
            "  Training Loss: 1.4276\n",
            "  Validation Loss: 2.4623\n",
            "  Validation Accuracy: 0.3173\n",
            "Epoch 29/400:\n",
            "  Training Loss: 1.3442\n",
            "  Validation Loss: 2.4850\n",
            "  Validation Accuracy: 0.3422\n",
            "Epoch 30/400:\n",
            "  Training Loss: 1.2896\n",
            "  Validation Loss: 2.4678\n",
            "  Validation Accuracy: 0.3522\n",
            "Epoch 31/400:\n",
            "  Training Loss: 1.2477\n",
            "  Validation Loss: 2.5254\n",
            "  Validation Accuracy: 0.3289\n",
            "Epoch 32/400:\n",
            "  Training Loss: 1.1805\n",
            "  Validation Loss: 2.5287\n",
            "  Validation Accuracy: 0.3272\n",
            "Epoch 33/400:\n",
            "  Training Loss: 1.1190\n",
            "  Validation Loss: 2.6402\n",
            "  Validation Accuracy: 0.3123\n",
            "Epoch 34/400:\n",
            "  Training Loss: 1.0453\n",
            "  Validation Loss: 2.6524\n",
            "  Validation Accuracy: 0.3355\n",
            "Epoch 35/400:\n",
            "  Training Loss: 1.0106\n",
            "  Validation Loss: 2.6608\n",
            "  Validation Accuracy: 0.3206\n",
            "Epoch 36/400:\n",
            "  Training Loss: 0.9785\n",
            "  Validation Loss: 2.7862\n",
            "  Validation Accuracy: 0.3140\n",
            "Epoch 37/400:\n",
            "  Training Loss: 0.9056\n",
            "  Validation Loss: 2.6965\n",
            "  Validation Accuracy: 0.3422\n",
            "Epoch 38/400:\n",
            "  Training Loss: 0.8650\n",
            "  Validation Loss: 2.8158\n",
            "  Validation Accuracy: 0.3455\n",
            "Epoch 39/400:\n",
            "  Training Loss: 0.8046\n",
            "  Validation Loss: 2.8152\n",
            "  Validation Accuracy: 0.3389\n",
            "Epoch 40/400:\n",
            "  Training Loss: 0.8095\n",
            "  Validation Loss: 2.9872\n",
            "  Validation Accuracy: 0.3422\n",
            "Epoch 41/400:\n",
            "  Training Loss: 0.7666\n",
            "  Validation Loss: 2.8740\n",
            "  Validation Accuracy: 0.3555\n",
            "Epoch 42/400:\n",
            "  Training Loss: 0.8168\n",
            "  Validation Loss: 3.0659\n",
            "  Validation Accuracy: 0.3123\n",
            "Epoch 43/400:\n",
            "  Training Loss: 0.7570\n",
            "  Validation Loss: 3.0129\n",
            "  Validation Accuracy: 0.3173\n",
            "Epoch 44/400:\n",
            "  Training Loss: 0.6948\n",
            "  Validation Loss: 3.0677\n",
            "  Validation Accuracy: 0.3156\n",
            "Epoch 45/400:\n",
            "  Training Loss: 0.6344\n",
            "  Validation Loss: 3.1192\n",
            "  Validation Accuracy: 0.3306\n",
            "Epoch 46/400:\n",
            "  Training Loss: 0.6324\n",
            "  Validation Loss: 3.1051\n",
            "  Validation Accuracy: 0.3355\n",
            "Epoch 47/400:\n",
            "  Training Loss: 0.5974\n",
            "  Validation Loss: 3.1073\n",
            "  Validation Accuracy: 0.3306\n",
            "Epoch 48/400:\n",
            "  Training Loss: 0.5810\n",
            "  Validation Loss: 3.1724\n",
            "  Validation Accuracy: 0.3439\n",
            "Epoch 49/400:\n",
            "  Training Loss: 0.5709\n",
            "  Validation Loss: 3.3075\n",
            "  Validation Accuracy: 0.3223\n",
            "Epoch 50/400:\n",
            "  Training Loss: 0.5377\n",
            "  Validation Loss: 3.2475\n",
            "  Validation Accuracy: 0.3389\n",
            "Epoch 51/400:\n",
            "  Training Loss: 0.5292\n",
            "  Validation Loss: 3.3089\n",
            "  Validation Accuracy: 0.3405\n",
            "Epoch 52/400:\n",
            "  Training Loss: 0.5136\n",
            "  Validation Loss: 3.3684\n",
            "  Validation Accuracy: 0.3289\n",
            "Epoch 53/400:\n",
            "  Training Loss: 0.5206\n",
            "  Validation Loss: 3.3475\n",
            "  Validation Accuracy: 0.3538\n",
            "Epoch 54/400:\n",
            "  Training Loss: 0.5601\n",
            "  Validation Loss: 3.4595\n",
            "  Validation Accuracy: 0.3206\n",
            "Epoch 55/400:\n",
            "  Training Loss: 0.5133\n",
            "  Validation Loss: 3.4646\n",
            "  Validation Accuracy: 0.3389\n",
            "Epoch 56/400:\n",
            "  Training Loss: 0.5993\n",
            "  Validation Loss: 3.3845\n",
            "  Validation Accuracy: 0.3322\n",
            "Epoch 57/400:\n",
            "  Training Loss: 0.5696\n",
            "  Validation Loss: 3.5459\n",
            "  Validation Accuracy: 0.3322\n",
            "Epoch 58/400:\n",
            "  Training Loss: 0.5987\n",
            "  Validation Loss: 3.5037\n",
            "  Validation Accuracy: 0.3173\n",
            "Epoch 59/400:\n",
            "  Training Loss: 0.6352\n",
            "  Validation Loss: 3.3825\n",
            "  Validation Accuracy: 0.3339\n",
            "Epoch 60/400:\n",
            "  Training Loss: 0.5604\n",
            "  Validation Loss: 3.5030\n",
            "  Validation Accuracy: 0.3322\n",
            "Epoch 61/400:\n",
            "  Training Loss: 0.5224\n",
            "  Validation Loss: 3.3849\n",
            "  Validation Accuracy: 0.3488\n",
            "Epoch 62/400:\n",
            "  Training Loss: 0.5243\n",
            "  Validation Loss: 3.3929\n",
            "  Validation Accuracy: 0.3239\n",
            "Epoch 63/400:\n",
            "  Training Loss: 0.4841\n",
            "  Validation Loss: 3.4584\n",
            "  Validation Accuracy: 0.3455\n",
            "Epoch 64/400:\n",
            "  Training Loss: 0.4729\n",
            "  Validation Loss: 3.5890\n",
            "  Validation Accuracy: 0.3289\n",
            "Epoch 65/400:\n",
            "  Training Loss: 0.4790\n",
            "  Validation Loss: 3.5731\n",
            "  Validation Accuracy: 0.3256\n",
            "Epoch 66/400:\n",
            "  Training Loss: 0.4336\n",
            "  Validation Loss: 3.5742\n",
            "  Validation Accuracy: 0.3355\n",
            "Epoch 67/400:\n",
            "  Training Loss: 0.4294\n",
            "  Validation Loss: 3.6177\n",
            "  Validation Accuracy: 0.3223\n",
            "Epoch 68/400:\n",
            "  Training Loss: 0.4123\n",
            "  Validation Loss: 3.5788\n",
            "  Validation Accuracy: 0.3389\n",
            "Epoch 69/400:\n",
            "  Training Loss: 0.3957\n",
            "  Validation Loss: 3.7079\n",
            "  Validation Accuracy: 0.3339\n",
            "Epoch 70/400:\n",
            "  Training Loss: 0.3677\n",
            "  Validation Loss: 3.6198\n",
            "  Validation Accuracy: 0.3505\n",
            "Epoch 71/400:\n",
            "  Training Loss: 0.3603\n",
            "  Validation Loss: 3.6926\n",
            "  Validation Accuracy: 0.3322\n",
            "Epoch 72/400:\n",
            "  Training Loss: 0.3438\n",
            "  Validation Loss: 3.7616\n",
            "  Validation Accuracy: 0.3422\n",
            "Epoch 73/400:\n",
            "  Training Loss: 0.3292\n",
            "  Validation Loss: 3.7586\n",
            "  Validation Accuracy: 0.3422\n",
            "Epoch 74/400:\n",
            "  Training Loss: 0.3201\n",
            "  Validation Loss: 3.8085\n",
            "  Validation Accuracy: 0.3256\n",
            "Epoch 75/400:\n",
            "  Training Loss: 0.3123\n",
            "  Validation Loss: 3.8287\n",
            "  Validation Accuracy: 0.3189\n",
            "Epoch 76/400:\n",
            "  Training Loss: 0.3016\n",
            "  Validation Loss: 3.8028\n",
            "  Validation Accuracy: 0.3272\n",
            "Epoch 77/400:\n",
            "  Training Loss: 0.2989\n",
            "  Validation Loss: 3.7832\n",
            "  Validation Accuracy: 0.3289\n",
            "Epoch 78/400:\n",
            "  Training Loss: 0.2881\n",
            "  Validation Loss: 3.8433\n",
            "  Validation Accuracy: 0.3355\n",
            "Epoch 79/400:\n",
            "  Training Loss: 0.2730\n",
            "  Validation Loss: 3.8546\n",
            "  Validation Accuracy: 0.3372\n",
            "Epoch 80/400:\n",
            "  Training Loss: 0.2767\n",
            "  Validation Loss: 3.8907\n",
            "  Validation Accuracy: 0.3306\n",
            "Epoch 81/400:\n",
            "  Training Loss: 0.2742\n",
            "  Validation Loss: 3.8916\n",
            "  Validation Accuracy: 0.3322\n",
            "Epoch 82/400:\n",
            "  Training Loss: 0.2732\n",
            "  Validation Loss: 3.9042\n",
            "  Validation Accuracy: 0.3239\n",
            "Epoch 83/400:\n",
            "  Training Loss: 0.2718\n",
            "  Validation Loss: 3.9071\n",
            "  Validation Accuracy: 0.3372\n",
            "Epoch 84/400:\n",
            "  Training Loss: 0.2584\n",
            "  Validation Loss: 3.9269\n",
            "  Validation Accuracy: 0.3422\n",
            "Epoch 85/400:\n",
            "  Training Loss: 0.2711\n",
            "  Validation Loss: 3.9896\n",
            "  Validation Accuracy: 0.3223\n",
            "Epoch 86/400:\n",
            "  Training Loss: 0.2686\n",
            "  Validation Loss: 3.9374\n",
            "  Validation Accuracy: 0.3389\n",
            "Epoch 87/400:\n",
            "  Training Loss: 0.2613\n",
            "  Validation Loss: 3.9315\n",
            "  Validation Accuracy: 0.3339\n",
            "Epoch 88/400:\n",
            "  Training Loss: 0.2594\n",
            "  Validation Loss: 3.9513\n",
            "  Validation Accuracy: 0.3272\n",
            "Epoch 89/400:\n",
            "  Training Loss: 0.2614\n",
            "  Validation Loss: 4.0052\n",
            "  Validation Accuracy: 0.3239\n",
            "Epoch 90/400:\n",
            "  Training Loss: 0.2511\n",
            "  Validation Loss: 4.0449\n",
            "  Validation Accuracy: 0.3239\n",
            "Epoch 91/400:\n",
            "  Training Loss: 0.2419\n",
            "  Validation Loss: 4.0442\n",
            "  Validation Accuracy: 0.3289\n",
            "Epoch 92/400:\n",
            "  Training Loss: 0.2556\n",
            "  Validation Loss: 4.0198\n",
            "  Validation Accuracy: 0.3189\n",
            "Epoch 93/400:\n",
            "  Training Loss: 0.2404\n",
            "  Validation Loss: 4.0143\n",
            "  Validation Accuracy: 0.3322\n",
            "Epoch 94/400:\n",
            "  Training Loss: 0.2543\n",
            "  Validation Loss: 4.0200\n",
            "  Validation Accuracy: 0.3372\n",
            "Epoch 95/400:\n",
            "  Training Loss: 0.2613\n",
            "  Validation Loss: 4.0119\n",
            "  Validation Accuracy: 0.3355\n",
            "Epoch 96/400:\n",
            "  Training Loss: 0.2456\n",
            "  Validation Loss: 4.0697\n",
            "  Validation Accuracy: 0.3289\n",
            "Epoch 97/400:\n",
            "  Training Loss: 0.2427\n",
            "  Validation Loss: 4.0800\n",
            "  Validation Accuracy: 0.3272\n",
            "Epoch 98/400:\n",
            "  Training Loss: 0.2450\n",
            "  Validation Loss: 4.0656\n",
            "  Validation Accuracy: 0.3339\n",
            "Epoch 99/400:\n",
            "  Training Loss: 0.2571\n",
            "  Validation Loss: 4.0051\n",
            "  Validation Accuracy: 0.3472\n",
            "Epoch 100/400:\n",
            "  Training Loss: 0.2531\n",
            "  Validation Loss: 4.0092\n",
            "  Validation Accuracy: 0.3488\n",
            "Epoch 101/400:\n",
            "  Training Loss: 0.2367\n",
            "  Validation Loss: 4.0925\n",
            "  Validation Accuracy: 0.3488\n",
            "Epoch 102/400:\n",
            "  Training Loss: 0.2495\n",
            "  Validation Loss: 4.0469\n",
            "  Validation Accuracy: 0.3272\n",
            "Epoch 103/400:\n",
            "  Training Loss: 0.2343\n",
            "  Validation Loss: 4.0786\n",
            "  Validation Accuracy: 0.3339\n",
            "Epoch 104/400:\n",
            "  Training Loss: 0.2343\n",
            "  Validation Loss: 4.1502\n",
            "  Validation Accuracy: 0.3389\n",
            "Epoch 105/400:\n",
            "  Training Loss: 0.2504\n",
            "  Validation Loss: 4.1708\n",
            "  Validation Accuracy: 0.3256\n",
            "Epoch 106/400:\n",
            "  Training Loss: 0.2324\n",
            "  Validation Loss: 4.1721\n",
            "  Validation Accuracy: 0.3239\n",
            "Epoch 107/400:\n",
            "  Training Loss: 0.2295\n",
            "  Validation Loss: 4.1513\n",
            "  Validation Accuracy: 0.3272\n",
            "Epoch 108/400:\n",
            "  Training Loss: 0.2445\n",
            "  Validation Loss: 4.1640\n",
            "  Validation Accuracy: 0.3306\n",
            "Epoch 109/400:\n",
            "  Training Loss: 0.2304\n",
            "  Validation Loss: 4.1746\n",
            "  Validation Accuracy: 0.3339\n",
            "Epoch 110/400:\n",
            "  Training Loss: 0.2260\n",
            "  Validation Loss: 4.1833\n",
            "  Validation Accuracy: 0.3355\n",
            "Epoch 111/400:\n",
            "  Training Loss: 0.2175\n",
            "  Validation Loss: 4.2461\n",
            "  Validation Accuracy: 0.3422\n",
            "Epoch 112/400:\n",
            "  Training Loss: 0.2178\n",
            "  Validation Loss: 4.3060\n",
            "  Validation Accuracy: 0.3405\n",
            "Epoch 113/400:\n",
            "  Training Loss: 0.2225\n",
            "  Validation Loss: 4.3228\n",
            "  Validation Accuracy: 0.3372\n",
            "Epoch 114/400:\n",
            "  Training Loss: 0.2118\n",
            "  Validation Loss: 4.2450\n",
            "  Validation Accuracy: 0.3372\n",
            "Epoch 115/400:\n",
            "  Training Loss: 0.2162\n",
            "  Validation Loss: 4.1906\n",
            "  Validation Accuracy: 0.3372\n",
            "Epoch 116/400:\n",
            "  Training Loss: 0.2106\n",
            "  Validation Loss: 4.1914\n",
            "  Validation Accuracy: 0.3372\n",
            "Epoch 117/400:\n",
            "  Training Loss: 0.2191\n",
            "  Validation Loss: 4.2705\n",
            "  Validation Accuracy: 0.3355\n",
            "Epoch 118/400:\n",
            "  Training Loss: 0.2088\n",
            "  Validation Loss: 4.3333\n",
            "  Validation Accuracy: 0.3223\n",
            "Epoch 119/400:\n",
            "  Training Loss: 0.2285\n",
            "  Validation Loss: 4.3292\n",
            "  Validation Accuracy: 0.3372\n",
            "Epoch 120/400:\n",
            "  Training Loss: 0.2287\n",
            "  Validation Loss: 4.3207\n",
            "  Validation Accuracy: 0.3389\n",
            "Epoch 121/400:\n",
            "  Training Loss: 0.2201\n",
            "  Validation Loss: 4.3419\n",
            "  Validation Accuracy: 0.3256\n",
            "Epoch 122/400:\n",
            "  Training Loss: 0.2184\n",
            "  Validation Loss: 4.3657\n",
            "  Validation Accuracy: 0.3306\n",
            "Epoch 123/400:\n",
            "  Training Loss: 0.2207\n",
            "  Validation Loss: 4.3343\n",
            "  Validation Accuracy: 0.3256\n",
            "Epoch 124/400:\n",
            "  Training Loss: 0.2111\n",
            "  Validation Loss: 4.2326\n",
            "  Validation Accuracy: 0.3372\n",
            "Epoch 125/400:\n",
            "  Training Loss: 0.2058\n",
            "  Validation Loss: 4.2882\n",
            "  Validation Accuracy: 0.3405\n",
            "Epoch 126/400:\n",
            "  Training Loss: 0.2234\n",
            "  Validation Loss: 4.3158\n",
            "  Validation Accuracy: 0.3239\n",
            "Epoch 127/400:\n",
            "  Training Loss: 0.2584\n",
            "  Validation Loss: 4.3390\n",
            "  Validation Accuracy: 0.3289\n",
            "Epoch 128/400:\n",
            "  Training Loss: 0.2467\n",
            "  Validation Loss: 4.3075\n",
            "  Validation Accuracy: 0.3289\n",
            "Epoch 129/400:\n",
            "  Training Loss: 0.2398\n",
            "  Validation Loss: 4.2026\n",
            "  Validation Accuracy: 0.3156\n",
            "Epoch 130/400:\n",
            "  Training Loss: 0.2410\n",
            "  Validation Loss: 4.2668\n",
            "  Validation Accuracy: 0.3189\n",
            "Epoch 131/400:\n",
            "  Training Loss: 0.2432\n",
            "  Validation Loss: 4.3000\n",
            "  Validation Accuracy: 0.3156\n",
            "Epoch 132/400:\n",
            "  Training Loss: 0.2333\n",
            "  Validation Loss: 4.3283\n",
            "  Validation Accuracy: 0.3256\n",
            "Epoch 133/400:\n",
            "  Training Loss: 0.2440\n",
            "  Validation Loss: 4.3380\n",
            "  Validation Accuracy: 0.3272\n",
            "Epoch 134/400:\n",
            "  Training Loss: 0.2496\n",
            "  Validation Loss: 4.3281\n",
            "  Validation Accuracy: 0.3256\n",
            "Epoch 135/400:\n",
            "  Training Loss: 0.2389\n",
            "  Validation Loss: 4.2739\n",
            "  Validation Accuracy: 0.3306\n",
            "Epoch 136/400:\n",
            "  Training Loss: 0.2323\n",
            "  Validation Loss: 4.3262\n",
            "  Validation Accuracy: 0.3372\n",
            "Epoch 137/400:\n",
            "  Training Loss: 0.2319\n",
            "  Validation Loss: 4.3176\n",
            "  Validation Accuracy: 0.3339\n",
            "Epoch 138/400:\n",
            "  Training Loss: 0.2277\n",
            "  Validation Loss: 4.3018\n",
            "  Validation Accuracy: 0.3289\n",
            "Epoch 139/400:\n",
            "  Training Loss: 0.2350\n",
            "  Validation Loss: 4.3778\n",
            "  Validation Accuracy: 0.3256\n",
            "Epoch 140/400:\n",
            "  Training Loss: 0.2422\n",
            "  Validation Loss: 4.4140\n",
            "  Validation Accuracy: 0.3140\n",
            "Epoch 141/400:\n",
            "  Training Loss: 0.2436\n",
            "  Validation Loss: 4.4295\n",
            "  Validation Accuracy: 0.3239\n",
            "Epoch 142/400:\n",
            "  Training Loss: 0.2246\n",
            "  Validation Loss: 4.3964\n",
            "  Validation Accuracy: 0.3306\n",
            "Epoch 143/400:\n",
            "  Training Loss: 0.2348\n",
            "  Validation Loss: 4.4113\n",
            "  Validation Accuracy: 0.3355\n",
            "Epoch 144/400:\n",
            "  Training Loss: 0.2418\n",
            "  Validation Loss: 4.4826\n",
            "  Validation Accuracy: 0.3239\n",
            "Epoch 145/400:\n",
            "  Training Loss: 0.2323\n",
            "  Validation Loss: 4.4443\n",
            "  Validation Accuracy: 0.3405\n",
            "Epoch 146/400:\n",
            "  Training Loss: 0.2186\n",
            "  Validation Loss: 4.4687\n",
            "  Validation Accuracy: 0.3306\n",
            "Epoch 147/400:\n",
            "  Training Loss: 0.2228\n",
            "  Validation Loss: 4.4688\n",
            "  Validation Accuracy: 0.3355\n",
            "Epoch 148/400:\n",
            "  Training Loss: 0.2153\n",
            "  Validation Loss: 4.4557\n",
            "  Validation Accuracy: 0.3439\n",
            "Epoch 149/400:\n",
            "  Training Loss: 0.2180\n",
            "  Validation Loss: 4.4680\n",
            "  Validation Accuracy: 0.3339\n",
            "Epoch 150/400:\n",
            "  Training Loss: 0.2096\n",
            "  Validation Loss: 4.4296\n",
            "  Validation Accuracy: 0.3372\n",
            "Epoch 151/400:\n",
            "  Training Loss: 0.2166\n",
            "  Validation Loss: 4.3841\n",
            "  Validation Accuracy: 0.3306\n",
            "Epoch 152/400:\n",
            "  Training Loss: 0.2019\n",
            "  Validation Loss: 4.3828\n",
            "  Validation Accuracy: 0.3272\n",
            "Epoch 153/400:\n",
            "  Training Loss: 0.2043\n",
            "  Validation Loss: 4.3808\n",
            "  Validation Accuracy: 0.3289\n",
            "Epoch 154/400:\n",
            "  Training Loss: 0.2028\n",
            "  Validation Loss: 4.4572\n",
            "  Validation Accuracy: 0.3455\n",
            "Epoch 155/400:\n",
            "  Training Loss: 0.1915\n",
            "  Validation Loss: 4.4917\n",
            "  Validation Accuracy: 0.3355\n",
            "Epoch 156/400:\n",
            "  Training Loss: 0.1988\n",
            "  Validation Loss: 4.5103\n",
            "  Validation Accuracy: 0.3372\n",
            "Epoch 157/400:\n",
            "  Training Loss: 0.2038\n",
            "  Validation Loss: 4.4757\n",
            "  Validation Accuracy: 0.3522\n",
            "Epoch 158/400:\n",
            "  Training Loss: 0.2021\n",
            "  Validation Loss: 4.4374\n",
            "  Validation Accuracy: 0.3422\n",
            "Epoch 159/400:\n",
            "  Training Loss: 0.2043\n",
            "  Validation Loss: 4.5300\n",
            "  Validation Accuracy: 0.3306\n",
            "Epoch 160/400:\n",
            "  Training Loss: 0.1952\n",
            "  Validation Loss: 4.5733\n",
            "  Validation Accuracy: 0.3389\n",
            "Epoch 161/400:\n",
            "  Training Loss: 0.1911\n",
            "  Validation Loss: 4.5115\n",
            "  Validation Accuracy: 0.3389\n",
            "Epoch 162/400:\n",
            "  Training Loss: 0.1906\n",
            "  Validation Loss: 4.5124\n",
            "  Validation Accuracy: 0.3422\n",
            "Epoch 163/400:\n",
            "  Training Loss: 0.1907\n",
            "  Validation Loss: 4.5364\n",
            "  Validation Accuracy: 0.3355\n",
            "Epoch 164/400:\n",
            "  Training Loss: 0.2120\n",
            "  Validation Loss: 4.5999\n",
            "  Validation Accuracy: 0.3256\n",
            "Epoch 165/400:\n",
            "  Training Loss: 0.1977\n",
            "  Validation Loss: 4.6399\n",
            "  Validation Accuracy: 0.3322\n",
            "Epoch 166/400:\n",
            "  Training Loss: 0.2006\n",
            "  Validation Loss: 4.5927\n",
            "  Validation Accuracy: 0.3339\n",
            "Epoch 167/400:\n",
            "  Training Loss: 0.2019\n",
            "  Validation Loss: 4.5609\n",
            "  Validation Accuracy: 0.3405\n",
            "Epoch 168/400:\n",
            "  Training Loss: 0.2095\n",
            "  Validation Loss: 4.5873\n",
            "  Validation Accuracy: 0.3472\n",
            "Epoch 169/400:\n",
            "  Training Loss: 0.2078\n",
            "  Validation Loss: 4.6179\n",
            "  Validation Accuracy: 0.3422\n",
            "Epoch 170/400:\n",
            "  Training Loss: 0.2153\n",
            "  Validation Loss: 4.5916\n",
            "  Validation Accuracy: 0.3488\n",
            "Epoch 171/400:\n",
            "  Training Loss: 0.2115\n",
            "  Validation Loss: 4.6002\n",
            "  Validation Accuracy: 0.3306\n",
            "Epoch 172/400:\n",
            "  Training Loss: 0.2152\n",
            "  Validation Loss: 4.5942\n",
            "  Validation Accuracy: 0.3389\n",
            "Epoch 173/400:\n",
            "  Training Loss: 0.2016\n",
            "  Validation Loss: 4.5979\n",
            "  Validation Accuracy: 0.3389\n",
            "Epoch 174/400:\n",
            "  Training Loss: 0.2114\n",
            "  Validation Loss: 4.5558\n",
            "  Validation Accuracy: 0.3355\n",
            "Epoch 175/400:\n",
            "  Training Loss: 0.2080\n",
            "  Validation Loss: 4.5555\n",
            "  Validation Accuracy: 0.3405\n",
            "Epoch 176/400:\n",
            "  Training Loss: 0.2142\n",
            "  Validation Loss: 4.5810\n",
            "  Validation Accuracy: 0.3306\n",
            "Epoch 177/400:\n",
            "  Training Loss: 0.2234\n",
            "  Validation Loss: 4.6120\n",
            "  Validation Accuracy: 0.3239\n",
            "Epoch 178/400:\n",
            "  Training Loss: 0.2228\n",
            "  Validation Loss: 4.5584\n",
            "  Validation Accuracy: 0.3289\n",
            "Epoch 179/400:\n",
            "  Training Loss: 0.2348\n",
            "  Validation Loss: 4.5011\n",
            "  Validation Accuracy: 0.3405\n",
            "Epoch 180/400:\n",
            "  Training Loss: 0.2266\n",
            "  Validation Loss: 4.5475\n",
            "  Validation Accuracy: 0.3256\n",
            "Epoch 181/400:\n",
            "  Training Loss: 0.2188\n",
            "  Validation Loss: 4.5968\n",
            "  Validation Accuracy: 0.3189\n",
            "Epoch 182/400:\n",
            "  Training Loss: 0.2080\n",
            "  Validation Loss: 4.5388\n",
            "  Validation Accuracy: 0.3223\n",
            "Epoch 183/400:\n",
            "  Training Loss: 0.1947\n",
            "  Validation Loss: 4.5980\n",
            "  Validation Accuracy: 0.3156\n",
            "Epoch 184/400:\n",
            "  Training Loss: 0.2043\n",
            "  Validation Loss: 4.6481\n",
            "  Validation Accuracy: 0.3173\n",
            "Epoch 185/400:\n",
            "  Training Loss: 0.2023\n",
            "  Validation Loss: 4.6960\n",
            "  Validation Accuracy: 0.3256\n",
            "Epoch 186/400:\n",
            "  Training Loss: 0.1926\n",
            "  Validation Loss: 4.7540\n",
            "  Validation Accuracy: 0.3239\n",
            "Epoch 187/400:\n",
            "  Training Loss: 0.1974\n",
            "  Validation Loss: 4.7032\n",
            "  Validation Accuracy: 0.3272\n",
            "Epoch 188/400:\n",
            "  Training Loss: 0.1976\n",
            "  Validation Loss: 4.6407\n",
            "  Validation Accuracy: 0.3422\n",
            "Epoch 189/400:\n",
            "  Training Loss: 0.1934\n",
            "  Validation Loss: 4.6402\n",
            "  Validation Accuracy: 0.3272\n",
            "Epoch 190/400:\n",
            "  Training Loss: 0.1922\n",
            "  Validation Loss: 4.7416\n",
            "  Validation Accuracy: 0.3289\n",
            "Epoch 191/400:\n",
            "  Training Loss: 0.2069\n",
            "  Validation Loss: 4.7176\n",
            "  Validation Accuracy: 0.3389\n",
            "Epoch 192/400:\n",
            "  Training Loss: 0.2033\n",
            "  Validation Loss: 4.7371\n",
            "  Validation Accuracy: 0.3455\n",
            "Epoch 193/400:\n",
            "  Training Loss: 0.2131\n",
            "  Validation Loss: 4.7503\n",
            "  Validation Accuracy: 0.3272\n",
            "Epoch 194/400:\n",
            "  Training Loss: 0.2169\n",
            "  Validation Loss: 4.7426\n",
            "  Validation Accuracy: 0.3123\n",
            "Epoch 195/400:\n",
            "  Training Loss: 0.2038\n",
            "  Validation Loss: 4.6820\n",
            "  Validation Accuracy: 0.3306\n",
            "Epoch 196/400:\n",
            "  Training Loss: 0.2071\n",
            "  Validation Loss: 4.7003\n",
            "  Validation Accuracy: 0.3090\n",
            "Epoch 197/400:\n",
            "  Training Loss: 0.2068\n",
            "  Validation Loss: 4.6490\n",
            "  Validation Accuracy: 0.3123\n",
            "Epoch 198/400:\n",
            "  Training Loss: 0.2037\n",
            "  Validation Loss: 4.6531\n",
            "  Validation Accuracy: 0.3339\n",
            "Epoch 199/400:\n",
            "  Training Loss: 0.2011\n",
            "  Validation Loss: 4.6491\n",
            "  Validation Accuracy: 0.3173\n",
            "Epoch 200/400:\n",
            "  Training Loss: 0.2017\n",
            "  Validation Loss: 4.6873\n",
            "  Validation Accuracy: 0.3322\n",
            "Epoch 201/400:\n",
            "  Training Loss: 0.2000\n",
            "  Validation Loss: 4.7117\n",
            "  Validation Accuracy: 0.3355\n",
            "Epoch 202/400:\n",
            "  Training Loss: 0.1995\n",
            "  Validation Loss: 4.6705\n",
            "  Validation Accuracy: 0.3223\n",
            "Epoch 203/400:\n",
            "  Training Loss: 0.1918\n",
            "  Validation Loss: 4.5411\n",
            "  Validation Accuracy: 0.3339\n",
            "Epoch 204/400:\n",
            "  Training Loss: 0.1812\n",
            "  Validation Loss: 4.5391\n",
            "  Validation Accuracy: 0.3439\n",
            "Epoch 205/400:\n",
            "  Training Loss: 0.1836\n",
            "  Validation Loss: 4.5816\n",
            "  Validation Accuracy: 0.3339\n",
            "Epoch 206/400:\n",
            "  Training Loss: 0.1941\n",
            "  Validation Loss: 4.6171\n",
            "  Validation Accuracy: 0.3256\n",
            "Epoch 207/400:\n",
            "  Training Loss: 0.2036\n",
            "  Validation Loss: 4.5945\n",
            "  Validation Accuracy: 0.3239\n",
            "Epoch 208/400:\n",
            "  Training Loss: 0.1916\n",
            "  Validation Loss: 4.6103\n",
            "  Validation Accuracy: 0.3239\n",
            "Epoch 209/400:\n",
            "  Training Loss: 0.1950\n",
            "  Validation Loss: 4.5504\n",
            "  Validation Accuracy: 0.3355\n",
            "Epoch 210/400:\n",
            "  Training Loss: 0.1934\n",
            "  Validation Loss: 4.5004\n",
            "  Validation Accuracy: 0.3339\n",
            "Epoch 211/400:\n",
            "  Training Loss: 0.2002\n",
            "  Validation Loss: 4.5510\n",
            "  Validation Accuracy: 0.3306\n",
            "Epoch 212/400:\n",
            "  Training Loss: 0.2090\n",
            "  Validation Loss: 4.5625\n",
            "  Validation Accuracy: 0.3439\n",
            "Epoch 213/400:\n",
            "  Training Loss: 0.2002\n",
            "  Validation Loss: 4.5982\n",
            "  Validation Accuracy: 0.3355\n",
            "Epoch 214/400:\n",
            "  Training Loss: 0.1854\n",
            "  Validation Loss: 4.5733\n",
            "  Validation Accuracy: 0.3322\n",
            "Epoch 215/400:\n",
            "  Training Loss: 0.2089\n",
            "  Validation Loss: 4.6169\n",
            "  Validation Accuracy: 0.3056\n",
            "Epoch 216/400:\n",
            "  Training Loss: 0.1886\n",
            "  Validation Loss: 4.6223\n",
            "  Validation Accuracy: 0.3173\n",
            "Epoch 217/400:\n",
            "  Training Loss: 0.1942\n",
            "  Validation Loss: 4.5777\n",
            "  Validation Accuracy: 0.3405\n",
            "Epoch 218/400:\n",
            "  Training Loss: 0.1851\n",
            "  Validation Loss: 4.6219\n",
            "  Validation Accuracy: 0.3256\n",
            "Epoch 219/400:\n",
            "  Training Loss: 0.1776\n",
            "  Validation Loss: 4.6862\n",
            "  Validation Accuracy: 0.3272\n",
            "Epoch 220/400:\n",
            "  Training Loss: 0.1752\n",
            "  Validation Loss: 4.7547\n",
            "  Validation Accuracy: 0.3272\n",
            "Epoch 221/400:\n",
            "  Training Loss: 0.1759\n",
            "  Validation Loss: 4.7732\n",
            "  Validation Accuracy: 0.3339\n",
            "Epoch 222/400:\n",
            "  Training Loss: 0.1733\n",
            "  Validation Loss: 4.8420\n",
            "  Validation Accuracy: 0.3189\n",
            "Epoch 223/400:\n",
            "  Training Loss: 0.1646\n",
            "  Validation Loss: 4.8089\n",
            "  Validation Accuracy: 0.3189\n",
            "Epoch 224/400:\n",
            "  Training Loss: 0.1688\n",
            "  Validation Loss: 4.7980\n",
            "  Validation Accuracy: 0.3339\n",
            "Epoch 225/400:\n",
            "  Training Loss: 0.1630\n",
            "  Validation Loss: 4.7569\n",
            "  Validation Accuracy: 0.3256\n",
            "Epoch 226/400:\n",
            "  Training Loss: 0.1628\n",
            "  Validation Loss: 4.6993\n",
            "  Validation Accuracy: 0.3239\n",
            "Epoch 227/400:\n",
            "  Training Loss: 0.1697\n",
            "  Validation Loss: 4.6933\n",
            "  Validation Accuracy: 0.3439\n",
            "Epoch 228/400:\n",
            "  Training Loss: 0.1675\n",
            "  Validation Loss: 4.7767\n",
            "  Validation Accuracy: 0.3339\n",
            "Epoch 229/400:\n",
            "  Training Loss: 0.1901\n",
            "  Validation Loss: 4.8302\n",
            "  Validation Accuracy: 0.3322\n",
            "Epoch 230/400:\n",
            "  Training Loss: 0.1710\n",
            "  Validation Loss: 4.8079\n",
            "  Validation Accuracy: 0.3422\n",
            "Epoch 231/400:\n",
            "  Training Loss: 0.1600\n",
            "  Validation Loss: 4.8359\n",
            "  Validation Accuracy: 0.3223\n",
            "Epoch 232/400:\n",
            "  Training Loss: 0.1749\n",
            "  Validation Loss: 4.8720\n",
            "  Validation Accuracy: 0.3206\n",
            "Epoch 233/400:\n",
            "  Training Loss: 0.1616\n",
            "  Validation Loss: 4.8770\n",
            "  Validation Accuracy: 0.3173\n",
            "Epoch 234/400:\n",
            "  Training Loss: 0.1744\n",
            "  Validation Loss: 4.8532\n",
            "  Validation Accuracy: 0.3272\n",
            "Epoch 235/400:\n",
            "  Training Loss: 0.1734\n",
            "  Validation Loss: 4.8797\n",
            "  Validation Accuracy: 0.3206\n",
            "Epoch 236/400:\n",
            "  Training Loss: 0.1710\n",
            "  Validation Loss: 4.9550\n",
            "  Validation Accuracy: 0.3189\n",
            "Epoch 237/400:\n",
            "  Training Loss: 0.1612\n",
            "  Validation Loss: 4.9395\n",
            "  Validation Accuracy: 0.3223\n",
            "Epoch 238/400:\n",
            "  Training Loss: 0.1889\n",
            "  Validation Loss: 4.9022\n",
            "  Validation Accuracy: 0.3156\n",
            "Epoch 239/400:\n",
            "  Training Loss: 0.1801\n",
            "  Validation Loss: 4.9054\n",
            "  Validation Accuracy: 0.3023\n",
            "Epoch 240/400:\n",
            "  Training Loss: 0.1784\n",
            "  Validation Loss: 4.9096\n",
            "  Validation Accuracy: 0.3189\n",
            "Epoch 241/400:\n",
            "  Training Loss: 0.1715\n",
            "  Validation Loss: 4.9506\n",
            "  Validation Accuracy: 0.3173\n",
            "Epoch 242/400:\n",
            "  Training Loss: 0.1857\n",
            "  Validation Loss: 4.9910\n",
            "  Validation Accuracy: 0.3040\n",
            "Epoch 243/400:\n",
            "  Training Loss: 0.1613\n",
            "  Validation Loss: 4.9432\n",
            "  Validation Accuracy: 0.3206\n",
            "Epoch 244/400:\n",
            "  Training Loss: 0.1612\n",
            "  Validation Loss: 4.9777\n",
            "  Validation Accuracy: 0.3223\n",
            "Epoch 245/400:\n",
            "  Training Loss: 0.1557\n",
            "  Validation Loss: 4.9353\n",
            "  Validation Accuracy: 0.3123\n",
            "Epoch 246/400:\n",
            "  Training Loss: 0.1618\n",
            "  Validation Loss: 4.9226\n",
            "  Validation Accuracy: 0.3223\n",
            "Epoch 247/400:\n",
            "  Training Loss: 0.1580\n",
            "  Validation Loss: 4.9301\n",
            "  Validation Accuracy: 0.3223\n",
            "Epoch 248/400:\n",
            "  Training Loss: 0.1708\n",
            "  Validation Loss: 4.8431\n",
            "  Validation Accuracy: 0.3339\n",
            "Epoch 249/400:\n",
            "  Training Loss: 0.1601\n",
            "  Validation Loss: 4.8572\n",
            "  Validation Accuracy: 0.3355\n",
            "Epoch 250/400:\n",
            "  Training Loss: 0.1577\n",
            "  Validation Loss: 4.9731\n",
            "  Validation Accuracy: 0.3272\n",
            "Epoch 251/400:\n",
            "  Training Loss: 0.1604\n",
            "  Validation Loss: 4.9444\n",
            "  Validation Accuracy: 0.3272\n",
            "Epoch 252/400:\n",
            "  Training Loss: 0.1624\n",
            "  Validation Loss: 4.8528\n",
            "  Validation Accuracy: 0.3272\n",
            "Epoch 253/400:\n",
            "  Training Loss: 0.1517\n",
            "  Validation Loss: 4.9211\n",
            "  Validation Accuracy: 0.3239\n",
            "Epoch 254/400:\n",
            "  Training Loss: 0.1572\n",
            "  Validation Loss: 4.9080\n",
            "  Validation Accuracy: 0.3322\n",
            "Epoch 255/400:\n",
            "  Training Loss: 0.1484\n",
            "  Validation Loss: 4.8947\n",
            "  Validation Accuracy: 0.3306\n",
            "Epoch 256/400:\n",
            "  Training Loss: 0.1647\n",
            "  Validation Loss: 4.9470\n",
            "  Validation Accuracy: 0.3289\n",
            "Epoch 257/400:\n",
            "  Training Loss: 0.1533\n",
            "  Validation Loss: 5.0032\n",
            "  Validation Accuracy: 0.3090\n",
            "Epoch 258/400:\n",
            "  Training Loss: 0.1524\n",
            "  Validation Loss: 5.0340\n",
            "  Validation Accuracy: 0.3156\n",
            "Epoch 259/400:\n",
            "  Training Loss: 0.1571\n",
            "  Validation Loss: 5.0982\n",
            "  Validation Accuracy: 0.2924\n",
            "Epoch 260/400:\n",
            "  Training Loss: 0.1492\n",
            "  Validation Loss: 5.0385\n",
            "  Validation Accuracy: 0.3073\n",
            "Epoch 261/400:\n",
            "  Training Loss: 0.1558\n",
            "  Validation Loss: 4.9778\n",
            "  Validation Accuracy: 0.3189\n",
            "Epoch 262/400:\n",
            "  Training Loss: 0.1566\n",
            "  Validation Loss: 5.0385\n",
            "  Validation Accuracy: 0.3206\n",
            "Epoch 263/400:\n",
            "  Training Loss: 0.1706\n",
            "  Validation Loss: 5.0312\n",
            "  Validation Accuracy: 0.3206\n",
            "Epoch 264/400:\n",
            "  Training Loss: 0.1512\n",
            "  Validation Loss: 4.9683\n",
            "  Validation Accuracy: 0.3189\n",
            "Epoch 265/400:\n",
            "  Training Loss: 0.1720\n",
            "  Validation Loss: 4.9115\n",
            "  Validation Accuracy: 0.3156\n",
            "Epoch 266/400:\n",
            "  Training Loss: 0.1595\n",
            "  Validation Loss: 4.9662\n",
            "  Validation Accuracy: 0.3306\n",
            "Epoch 267/400:\n",
            "  Training Loss: 0.1678\n",
            "  Validation Loss: 4.9843\n",
            "  Validation Accuracy: 0.3389\n",
            "Epoch 268/400:\n",
            "  Training Loss: 0.1677\n",
            "  Validation Loss: 4.9756\n",
            "  Validation Accuracy: 0.3322\n",
            "Epoch 269/400:\n",
            "  Training Loss: 0.1576\n",
            "  Validation Loss: 4.9845\n",
            "  Validation Accuracy: 0.3355\n",
            "Epoch 270/400:\n",
            "  Training Loss: 0.1742\n",
            "  Validation Loss: 4.9335\n",
            "  Validation Accuracy: 0.3322\n",
            "Epoch 271/400:\n",
            "  Training Loss: 0.1542\n",
            "  Validation Loss: 4.8696\n",
            "  Validation Accuracy: 0.3339\n",
            "Epoch 272/400:\n",
            "  Training Loss: 0.1517\n",
            "  Validation Loss: 4.9649\n",
            "  Validation Accuracy: 0.3239\n",
            "Epoch 273/400:\n",
            "  Training Loss: 0.1573\n",
            "  Validation Loss: 5.0138\n",
            "  Validation Accuracy: 0.3306\n",
            "Epoch 274/400:\n",
            "  Training Loss: 0.1507\n",
            "  Validation Loss: 5.0155\n",
            "  Validation Accuracy: 0.3189\n",
            "Epoch 275/400:\n",
            "  Training Loss: 0.1513\n",
            "  Validation Loss: 4.9856\n",
            "  Validation Accuracy: 0.3339\n",
            "Epoch 276/400:\n",
            "  Training Loss: 0.1519\n",
            "  Validation Loss: 4.9476\n",
            "  Validation Accuracy: 0.3439\n",
            "Epoch 277/400:\n",
            "  Training Loss: 0.1463\n",
            "  Validation Loss: 4.9053\n",
            "  Validation Accuracy: 0.3422\n",
            "Epoch 278/400:\n",
            "  Training Loss: 0.1442\n",
            "  Validation Loss: 4.9506\n",
            "  Validation Accuracy: 0.3306\n",
            "Epoch 279/400:\n",
            "  Training Loss: 0.1401\n",
            "  Validation Loss: 4.9623\n",
            "  Validation Accuracy: 0.3339\n",
            "Epoch 280/400:\n",
            "  Training Loss: 0.1376\n",
            "  Validation Loss: 4.9909\n",
            "  Validation Accuracy: 0.3339\n",
            "Epoch 281/400:\n",
            "  Training Loss: 0.1321\n",
            "  Validation Loss: 4.9629\n",
            "  Validation Accuracy: 0.3289\n",
            "Epoch 282/400:\n",
            "  Training Loss: 0.1367\n",
            "  Validation Loss: 5.0477\n",
            "  Validation Accuracy: 0.3405\n",
            "Epoch 283/400:\n",
            "  Training Loss: 0.1417\n",
            "  Validation Loss: 5.1191\n",
            "  Validation Accuracy: 0.3339\n",
            "Epoch 284/400:\n",
            "  Training Loss: 0.1437\n",
            "  Validation Loss: 5.0552\n",
            "  Validation Accuracy: 0.3289\n",
            "Epoch 285/400:\n",
            "  Training Loss: 0.1389\n",
            "  Validation Loss: 5.0091\n",
            "  Validation Accuracy: 0.3439\n",
            "Epoch 286/400:\n",
            "  Training Loss: 0.1450\n",
            "  Validation Loss: 5.0685\n",
            "  Validation Accuracy: 0.3472\n",
            "Epoch 287/400:\n",
            "  Training Loss: 0.1392\n",
            "  Validation Loss: 5.0955\n",
            "  Validation Accuracy: 0.3339\n",
            "Epoch 288/400:\n",
            "  Training Loss: 0.1452\n",
            "  Validation Loss: 5.0808\n",
            "  Validation Accuracy: 0.3339\n",
            "Epoch 289/400:\n",
            "  Training Loss: 0.1538\n",
            "  Validation Loss: 5.0742\n",
            "  Validation Accuracy: 0.3322\n",
            "Epoch 290/400:\n",
            "  Training Loss: 0.1515\n",
            "  Validation Loss: 5.0985\n",
            "  Validation Accuracy: 0.3322\n",
            "Epoch 291/400:\n",
            "  Training Loss: 0.1599\n",
            "  Validation Loss: 5.1061\n",
            "  Validation Accuracy: 0.3322\n",
            "Epoch 292/400:\n",
            "  Training Loss: 0.1448\n",
            "  Validation Loss: 5.0528\n",
            "  Validation Accuracy: 0.3355\n",
            "Epoch 293/400:\n",
            "  Training Loss: 0.1492\n",
            "  Validation Loss: 4.9902\n",
            "  Validation Accuracy: 0.3439\n",
            "Epoch 294/400:\n",
            "  Training Loss: 0.1362\n",
            "  Validation Loss: 5.0347\n",
            "  Validation Accuracy: 0.3306\n",
            "Epoch 295/400:\n",
            "  Training Loss: 0.1329\n",
            "  Validation Loss: 5.0594\n",
            "  Validation Accuracy: 0.3322\n",
            "Epoch 296/400:\n",
            "  Training Loss: 0.1446\n",
            "  Validation Loss: 5.0931\n",
            "  Validation Accuracy: 0.3239\n",
            "Epoch 297/400:\n",
            "  Training Loss: 0.1407\n",
            "  Validation Loss: 5.1317\n",
            "  Validation Accuracy: 0.3289\n",
            "Epoch 298/400:\n",
            "  Training Loss: 0.1341\n",
            "  Validation Loss: 5.1330\n",
            "  Validation Accuracy: 0.3090\n",
            "Epoch 299/400:\n",
            "  Training Loss: 0.1539\n",
            "  Validation Loss: 5.1084\n",
            "  Validation Accuracy: 0.3040\n",
            "Epoch 300/400:\n",
            "  Training Loss: 0.1451\n",
            "  Validation Loss: 5.1180\n",
            "  Validation Accuracy: 0.3007\n",
            "Epoch 301/400:\n",
            "  Training Loss: 0.1373\n",
            "  Validation Loss: 5.1176\n",
            "  Validation Accuracy: 0.3156\n",
            "Epoch 302/400:\n",
            "  Training Loss: 0.1453\n",
            "  Validation Loss: 5.1269\n",
            "  Validation Accuracy: 0.3140\n",
            "Epoch 303/400:\n",
            "  Training Loss: 0.1485\n",
            "  Validation Loss: 5.2327\n",
            "  Validation Accuracy: 0.3223\n",
            "Epoch 304/400:\n",
            "  Training Loss: 0.1460\n",
            "  Validation Loss: 5.2382\n",
            "  Validation Accuracy: 0.3223\n",
            "Epoch 305/400:\n",
            "  Training Loss: 0.1586\n",
            "  Validation Loss: 5.1996\n",
            "  Validation Accuracy: 0.3223\n",
            "Epoch 306/400:\n",
            "  Training Loss: 0.1418\n",
            "  Validation Loss: 5.2000\n",
            "  Validation Accuracy: 0.3156\n",
            "Epoch 307/400:\n",
            "  Training Loss: 0.1453\n",
            "  Validation Loss: 5.2051\n",
            "  Validation Accuracy: 0.2973\n",
            "Epoch 308/400:\n",
            "  Training Loss: 0.1495\n",
            "  Validation Loss: 5.1959\n",
            "  Validation Accuracy: 0.3189\n",
            "Epoch 309/400:\n",
            "  Training Loss: 0.1378\n",
            "  Validation Loss: 5.2393\n",
            "  Validation Accuracy: 0.3140\n",
            "Epoch 310/400:\n",
            "  Training Loss: 0.1349\n",
            "  Validation Loss: 5.2611\n",
            "  Validation Accuracy: 0.3140\n",
            "Epoch 311/400:\n",
            "  Training Loss: 0.1319\n",
            "  Validation Loss: 5.3115\n",
            "  Validation Accuracy: 0.3189\n",
            "Epoch 312/400:\n",
            "  Training Loss: 0.1332\n",
            "  Validation Loss: 5.3969\n",
            "  Validation Accuracy: 0.3206\n",
            "Epoch 313/400:\n",
            "  Training Loss: 0.1288\n",
            "  Validation Loss: 5.4092\n",
            "  Validation Accuracy: 0.3223\n",
            "Epoch 314/400:\n",
            "  Training Loss: 0.1302\n",
            "  Validation Loss: 5.4278\n",
            "  Validation Accuracy: 0.3256\n",
            "Epoch 315/400:\n",
            "  Training Loss: 0.1176\n",
            "  Validation Loss: 5.4045\n",
            "  Validation Accuracy: 0.3173\n",
            "Epoch 316/400:\n",
            "  Training Loss: 0.1290\n",
            "  Validation Loss: 5.3376\n",
            "  Validation Accuracy: 0.3123\n",
            "Epoch 317/400:\n",
            "  Training Loss: 0.1232\n",
            "  Validation Loss: 5.3203\n",
            "  Validation Accuracy: 0.3106\n",
            "Epoch 318/400:\n",
            "  Training Loss: 0.1219\n",
            "  Validation Loss: 5.3461\n",
            "  Validation Accuracy: 0.3040\n",
            "Epoch 319/400:\n",
            "  Training Loss: 0.1220\n",
            "  Validation Loss: 5.3510\n",
            "  Validation Accuracy: 0.2990\n",
            "Epoch 320/400:\n",
            "  Training Loss: 0.1232\n",
            "  Validation Loss: 5.2865\n",
            "  Validation Accuracy: 0.3206\n",
            "Epoch 321/400:\n",
            "  Training Loss: 0.1304\n",
            "  Validation Loss: 5.3655\n",
            "  Validation Accuracy: 0.3156\n",
            "Epoch 322/400:\n",
            "  Training Loss: 0.1286\n",
            "  Validation Loss: 5.4057\n",
            "  Validation Accuracy: 0.3106\n",
            "Epoch 323/400:\n",
            "  Training Loss: 0.1331\n",
            "  Validation Loss: 5.4507\n",
            "  Validation Accuracy: 0.3040\n",
            "Epoch 324/400:\n",
            "  Training Loss: 0.1324\n",
            "  Validation Loss: 5.3846\n",
            "  Validation Accuracy: 0.3223\n",
            "Epoch 325/400:\n",
            "  Training Loss: 0.1273\n",
            "  Validation Loss: 5.3876\n",
            "  Validation Accuracy: 0.3206\n",
            "Epoch 326/400:\n",
            "  Training Loss: 0.1391\n",
            "  Validation Loss: 5.3786\n",
            "  Validation Accuracy: 0.3223\n",
            "Epoch 327/400:\n",
            "  Training Loss: 0.1331\n",
            "  Validation Loss: 5.3920\n",
            "  Validation Accuracy: 0.3140\n",
            "Epoch 328/400:\n",
            "  Training Loss: 0.1231\n",
            "  Validation Loss: 5.3892\n",
            "  Validation Accuracy: 0.3156\n",
            "Epoch 329/400:\n",
            "  Training Loss: 0.1400\n",
            "  Validation Loss: 5.4404\n",
            "  Validation Accuracy: 0.3156\n",
            "Epoch 330/400:\n",
            "  Training Loss: 0.1267\n",
            "  Validation Loss: 5.4988\n",
            "  Validation Accuracy: 0.3106\n",
            "Epoch 331/400:\n",
            "  Training Loss: 0.1313\n",
            "  Validation Loss: 5.5147\n",
            "  Validation Accuracy: 0.3040\n",
            "Epoch 332/400:\n",
            "  Training Loss: 0.1402\n",
            "  Validation Loss: 5.4934\n",
            "  Validation Accuracy: 0.3056\n",
            "Epoch 333/400:\n",
            "  Training Loss: 0.1319\n",
            "  Validation Loss: 5.4453\n",
            "  Validation Accuracy: 0.3173\n",
            "Epoch 334/400:\n",
            "  Training Loss: 0.1491\n",
            "  Validation Loss: 5.4711\n",
            "  Validation Accuracy: 0.3073\n",
            "Epoch 335/400:\n",
            "  Training Loss: 0.1449\n",
            "  Validation Loss: 5.4620\n",
            "  Validation Accuracy: 0.3123\n",
            "Epoch 336/400:\n",
            "  Training Loss: 0.1351\n",
            "  Validation Loss: 5.4113\n",
            "  Validation Accuracy: 0.3073\n",
            "Epoch 337/400:\n",
            "  Training Loss: 0.1568\n",
            "  Validation Loss: 5.4049\n",
            "  Validation Accuracy: 0.3073\n",
            "Epoch 338/400:\n",
            "  Training Loss: 0.1377\n",
            "  Validation Loss: 5.3149\n",
            "  Validation Accuracy: 0.3023\n",
            "Epoch 339/400:\n",
            "  Training Loss: 0.1281\n",
            "  Validation Loss: 5.2369\n",
            "  Validation Accuracy: 0.3106\n",
            "Epoch 340/400:\n",
            "  Training Loss: 0.1404\n",
            "  Validation Loss: 5.2472\n",
            "  Validation Accuracy: 0.3007\n",
            "Epoch 341/400:\n",
            "  Training Loss: 0.1384\n",
            "  Validation Loss: 5.2273\n",
            "  Validation Accuracy: 0.3106\n",
            "Epoch 342/400:\n",
            "  Training Loss: 0.1380\n",
            "  Validation Loss: 5.2359\n",
            "  Validation Accuracy: 0.3256\n",
            "Epoch 343/400:\n",
            "  Training Loss: 0.1373\n",
            "  Validation Loss: 5.2767\n",
            "  Validation Accuracy: 0.3056\n",
            "Epoch 344/400:\n",
            "  Training Loss: 0.1390\n",
            "  Validation Loss: 5.3073\n",
            "  Validation Accuracy: 0.3272\n",
            "Epoch 345/400:\n",
            "  Training Loss: 0.1491\n",
            "  Validation Loss: 5.3306\n",
            "  Validation Accuracy: 0.3306\n",
            "Epoch 346/400:\n",
            "  Training Loss: 0.1266\n",
            "  Validation Loss: 5.3055\n",
            "  Validation Accuracy: 0.3206\n",
            "Epoch 347/400:\n",
            "  Training Loss: 0.1389\n",
            "  Validation Loss: 5.3568\n",
            "  Validation Accuracy: 0.3239\n",
            "Epoch 348/400:\n",
            "  Training Loss: 0.1328\n",
            "  Validation Loss: 5.3302\n",
            "  Validation Accuracy: 0.3256\n",
            "Epoch 349/400:\n",
            "  Training Loss: 0.1382\n",
            "  Validation Loss: 5.3249\n",
            "  Validation Accuracy: 0.3123\n",
            "Epoch 350/400:\n",
            "  Training Loss: 0.1261\n",
            "  Validation Loss: 5.3338\n",
            "  Validation Accuracy: 0.3056\n",
            "Epoch 351/400:\n",
            "  Training Loss: 0.1299\n",
            "  Validation Loss: 5.2594\n",
            "  Validation Accuracy: 0.3140\n",
            "Epoch 352/400:\n",
            "  Training Loss: 0.1438\n",
            "  Validation Loss: 5.3425\n",
            "  Validation Accuracy: 0.3206\n",
            "Epoch 353/400:\n",
            "  Training Loss: 0.1328\n",
            "  Validation Loss: 5.3594\n",
            "  Validation Accuracy: 0.3056\n",
            "Epoch 354/400:\n",
            "  Training Loss: 0.1448\n",
            "  Validation Loss: 5.3239\n",
            "  Validation Accuracy: 0.3123\n",
            "Epoch 355/400:\n",
            "  Training Loss: 0.1553\n",
            "  Validation Loss: 5.2139\n",
            "  Validation Accuracy: 0.3272\n",
            "Epoch 356/400:\n",
            "  Training Loss: 0.1428\n",
            "  Validation Loss: 5.1848\n",
            "  Validation Accuracy: 0.3389\n",
            "Epoch 357/400:\n",
            "  Training Loss: 0.1354\n",
            "  Validation Loss: 5.2333\n",
            "  Validation Accuracy: 0.3339\n",
            "Epoch 358/400:\n",
            "  Training Loss: 0.1377\n",
            "  Validation Loss: 5.2122\n",
            "  Validation Accuracy: 0.3372\n",
            "Epoch 359/400:\n",
            "  Training Loss: 0.1314\n",
            "  Validation Loss: 5.1414\n",
            "  Validation Accuracy: 0.3339\n",
            "Epoch 360/400:\n",
            "  Training Loss: 0.1264\n",
            "  Validation Loss: 5.1192\n",
            "  Validation Accuracy: 0.3339\n",
            "Epoch 361/400:\n",
            "  Training Loss: 0.1628\n",
            "  Validation Loss: 5.1835\n",
            "  Validation Accuracy: 0.3355\n",
            "Epoch 362/400:\n",
            "  Training Loss: 0.1758\n",
            "  Validation Loss: 5.2346\n",
            "  Validation Accuracy: 0.3073\n",
            "Epoch 363/400:\n",
            "  Training Loss: 0.1643\n",
            "  Validation Loss: 5.2208\n",
            "  Validation Accuracy: 0.3256\n",
            "Epoch 364/400:\n",
            "  Training Loss: 0.1681\n",
            "  Validation Loss: 5.2666\n",
            "  Validation Accuracy: 0.3106\n",
            "Epoch 365/400:\n",
            "  Training Loss: 0.1905\n",
            "  Validation Loss: 5.3560\n",
            "  Validation Accuracy: 0.3023\n",
            "Epoch 366/400:\n",
            "  Training Loss: 0.1732\n",
            "  Validation Loss: 5.3042\n",
            "  Validation Accuracy: 0.3040\n",
            "Epoch 367/400:\n",
            "  Training Loss: 0.1969\n",
            "  Validation Loss: 5.2120\n",
            "  Validation Accuracy: 0.3040\n",
            "Epoch 368/400:\n",
            "  Training Loss: 0.2024\n",
            "  Validation Loss: 5.1907\n",
            "  Validation Accuracy: 0.3073\n",
            "Epoch 369/400:\n",
            "  Training Loss: 0.1771\n",
            "  Validation Loss: 5.2450\n",
            "  Validation Accuracy: 0.3173\n",
            "Epoch 370/400:\n",
            "  Training Loss: 0.1960\n",
            "  Validation Loss: 5.0330\n",
            "  Validation Accuracy: 0.3339\n",
            "Epoch 371/400:\n",
            "  Training Loss: 0.1698\n",
            "  Validation Loss: 5.0355\n",
            "  Validation Accuracy: 0.3339\n",
            "Epoch 372/400:\n",
            "  Training Loss: 0.1707\n",
            "  Validation Loss: 4.9380\n",
            "  Validation Accuracy: 0.3322\n",
            "Epoch 373/400:\n",
            "  Training Loss: 0.1904\n",
            "  Validation Loss: 4.9434\n",
            "  Validation Accuracy: 0.3522\n",
            "Epoch 374/400:\n",
            "  Training Loss: 0.1651\n",
            "  Validation Loss: 4.9228\n",
            "  Validation Accuracy: 0.3488\n",
            "Epoch 375/400:\n",
            "  Training Loss: 0.1662\n",
            "  Validation Loss: 4.9469\n",
            "  Validation Accuracy: 0.3555\n",
            "Epoch 376/400:\n",
            "  Training Loss: 0.1606\n",
            "  Validation Loss: 5.0986\n",
            "  Validation Accuracy: 0.3472\n",
            "Epoch 377/400:\n",
            "  Training Loss: 0.1669\n",
            "  Validation Loss: 5.1796\n",
            "  Validation Accuracy: 0.3272\n",
            "Epoch 378/400:\n",
            "  Training Loss: 0.1595\n",
            "  Validation Loss: 5.3377\n",
            "  Validation Accuracy: 0.3123\n",
            "Epoch 379/400:\n",
            "  Training Loss: 0.1601\n",
            "  Validation Loss: 5.2946\n",
            "  Validation Accuracy: 0.3256\n",
            "Epoch 380/400:\n",
            "  Training Loss: 0.1746\n",
            "  Validation Loss: 5.2359\n",
            "  Validation Accuracy: 0.3206\n",
            "Epoch 381/400:\n",
            "  Training Loss: 0.1949\n",
            "  Validation Loss: 5.1350\n",
            "  Validation Accuracy: 0.3256\n",
            "Epoch 382/400:\n",
            "  Training Loss: 0.2069\n",
            "  Validation Loss: 5.0222\n",
            "  Validation Accuracy: 0.3389\n",
            "Epoch 383/400:\n",
            "  Training Loss: 0.2010\n",
            "  Validation Loss: 4.9187\n",
            "  Validation Accuracy: 0.3306\n",
            "Epoch 384/400:\n",
            "  Training Loss: 0.1888\n",
            "  Validation Loss: 4.8943\n",
            "  Validation Accuracy: 0.3355\n",
            "Epoch 385/400:\n",
            "  Training Loss: 0.2061\n",
            "  Validation Loss: 5.1143\n",
            "  Validation Accuracy: 0.3239\n",
            "Epoch 386/400:\n",
            "  Training Loss: 0.1944\n",
            "  Validation Loss: 5.1425\n",
            "  Validation Accuracy: 0.3223\n",
            "Epoch 387/400:\n",
            "  Training Loss: 0.1984\n",
            "  Validation Loss: 5.1100\n",
            "  Validation Accuracy: 0.3322\n",
            "Epoch 388/400:\n",
            "  Training Loss: 0.2017\n",
            "  Validation Loss: 4.9841\n",
            "  Validation Accuracy: 0.3239\n",
            "Epoch 389/400:\n",
            "  Training Loss: 0.1986\n",
            "  Validation Loss: 5.1273\n",
            "  Validation Accuracy: 0.3256\n",
            "Epoch 390/400:\n",
            "  Training Loss: 0.2098\n",
            "  Validation Loss: 5.1882\n",
            "  Validation Accuracy: 0.3023\n",
            "Epoch 391/400:\n",
            "  Training Loss: 0.1907\n",
            "  Validation Loss: 4.9916\n",
            "  Validation Accuracy: 0.3073\n",
            "Epoch 392/400:\n",
            "  Training Loss: 0.1947\n",
            "  Validation Loss: 5.1000\n",
            "  Validation Accuracy: 0.3156\n",
            "Epoch 393/400:\n",
            "  Training Loss: 0.1884\n",
            "  Validation Loss: 5.1439\n",
            "  Validation Accuracy: 0.3306\n",
            "Epoch 394/400:\n",
            "  Training Loss: 0.1682\n",
            "  Validation Loss: 5.1221\n",
            "  Validation Accuracy: 0.3322\n",
            "Epoch 395/400:\n",
            "  Training Loss: 0.1951\n",
            "  Validation Loss: 5.0643\n",
            "  Validation Accuracy: 0.3189\n",
            "Epoch 396/400:\n",
            "  Training Loss: 0.2012\n",
            "  Validation Loss: 5.0939\n",
            "  Validation Accuracy: 0.3306\n",
            "Epoch 397/400:\n",
            "  Training Loss: 0.1863\n",
            "  Validation Loss: 5.0313\n",
            "  Validation Accuracy: 0.3306\n",
            "Epoch 398/400:\n",
            "  Training Loss: 0.1990\n",
            "  Validation Loss: 5.1104\n",
            "  Validation Accuracy: 0.3339\n",
            "Epoch 399/400:\n",
            "  Training Loss: 0.1899\n",
            "  Validation Loss: 5.1831\n",
            "  Validation Accuracy: 0.3355\n",
            "Epoch 400/400:\n",
            "  Training Loss: 0.2268\n",
            "  Validation Loss: 5.1060\n",
            "  Validation Accuracy: 0.3156\n",
            "\n",
            "Showing 5 translation examples:\n",
            "\n",
            "Example 1: Input: We visit our grandparents, Target: Nous rendons visite à nos grands-parents, Prediction: ous aegoons lal n sa lsuelueueeetiiemeeearismeeel\n",
            "\n",
            "Example 2: Input: We are friends, Target: Nous sommes amis, Prediction: ous aanoon llon  lllloooolloooiuueeeeuuioeooe\n",
            "\n",
            "Example 3: Input: We travel by train, Target: Nous voyageons en train, Prediction: ous pinuronns dssdouufsamfoooiiill\n",
            "\n",
            "Example 4: Input: She swims in the ocean, Target: Elle nage dans l'océan, Prediction: lle pouenuent seénecntecreellllooiiiieee eeeee\n",
            "\n",
            "Example 5: Input: He enjoys reading books, Target: Il aime lire des livres, Prediction: l é menlene ve  melee  aeeaaannaaaa  eeeennneennaee\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "import random\n",
        "import ast\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Install python-docx for reading .docx files\n",
        "!pip install python-docx\n",
        "\n",
        "# Path to the .docx file in Google Drive\n",
        "file_path = '/content/drive/My Drive/Dataset_English_to_French.docx'\n",
        "\n",
        "# Load the .docx file\n",
        "from docx import Document\n",
        "doc = Document(file_path)\n",
        "\n",
        "# Extract text\n",
        "text = []\n",
        "for paragraph in doc.paragraphs:\n",
        "    text.append(paragraph.text)\n",
        "\n",
        "# Combine into single string\n",
        "text = '\\n'.join(text)\n",
        "\n",
        "# Extract the list from the text\n",
        "start_index = text.find('[')  # Find the start of the list\n",
        "end_index = text.rfind(']') + 1  # Find the end of the list\n",
        "list_content = text[start_index:end_index]  # Extract the list content\n",
        "\n",
        "# Safely evaluate the list content\n",
        "dataset = ast.literal_eval(list_content)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Special tokens\n",
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "PAD_token = 2  # New padding token\n",
        "\n",
        "# Create character mappings\n",
        "all_chars = set(''.join([word for pair in dataset for word in pair]))\n",
        "char_to_index = {\"SOS\": SOS_token, \"EOS\": EOS_token, \"PAD\": PAD_token,\n",
        "                **{char: i+3 for i, char in enumerate(sorted(list(all_chars)))}}\n",
        "index_to_char = {i: char for char, i in char_to_index.items()}\n",
        "vocab_size = len(char_to_index)\n",
        "\n",
        "# Find maximum sequence length in the dataset\n",
        "max_length = max(len(word) for pair in dataset for word in pair) + 1  # +1 for EOS token\n",
        "\n",
        "# Dataset class with proper padding\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, dataset, char_to_index, max_length):\n",
        "        self.dataset = dataset\n",
        "        self.char_to_index = char_to_index\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_word, target_word = self.dataset[idx]\n",
        "\n",
        "        # Convert to indices and add EOS\n",
        "        input_indices = [self.char_to_index[char] for char in input_word] + [EOS_token]\n",
        "        target_indices = [self.char_to_index[char] for char in target_word] + [EOS_token]\n",
        "\n",
        "        # Pad sequences to max_length\n",
        "        input_padded = input_indices + [PAD_token] * (self.max_length - len(input_indices))\n",
        "        target_padded = target_indices + [PAD_token] * (self.max_length - len(target_indices))\n",
        "\n",
        "        return (\n",
        "            torch.tensor(input_padded[:self.max_length], dtype=torch.long),\n",
        "            torch.tensor(target_padded[:self.max_length], dtype=torch.long)\n",
        "        )\n",
        "\n",
        "# collate function\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = zip(*batch)\n",
        "    src_batch = torch.stack(src_batch)\n",
        "    tgt_batch = torch.stack(tgt_batch)\n",
        "    return src_batch, tgt_batch\n",
        "\n",
        "# Positional Encoding\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]\n",
        "\n",
        "# Transformer Model\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model=256, nhead=2, num_layers=3, dropout=0.01): # Number of Heads and Layers\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model, padding_idx=PAD_token)\n",
        "        self.pos_encoder = PositionalEncoding(d_model)\n",
        "\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            num_encoder_layers=num_layers,\n",
        "            num_decoder_layers=num_layers,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, src, tgt, src_mask=None, tgt_mask=None):\n",
        "        # Create source and target masks\n",
        "        src_key_padding_mask = (src == PAD_token)\n",
        "        tgt_key_padding_mask = (tgt == PAD_token)\n",
        "\n",
        "        # Embedding and positional encoding\n",
        "        src = self.embedding(src) * math.sqrt(self.d_model)\n",
        "        src = self.pos_encoder(src)\n",
        "\n",
        "        tgt = self.embedding(tgt) * math.sqrt(self.d_model)\n",
        "        tgt = self.pos_encoder(tgt)\n",
        "\n",
        "        # Create attention masks\n",
        "        if tgt_mask is None:\n",
        "            tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt.size(1)).to(device)\n",
        "\n",
        "        # Transformer\n",
        "        output = self.transformer(\n",
        "            src, tgt,\n",
        "            tgt_mask=tgt_mask,\n",
        "            src_key_padding_mask=src_key_padding_mask,\n",
        "            tgt_key_padding_mask=tgt_key_padding_mask\n",
        "        )\n",
        "        output = self.fc_out(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "def calculate_accuracy(model, dataloader):\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src, tgt in dataloader:\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "            tgt_input = tgt[:, :-1]\n",
        "            tgt_output = tgt[:, 1:]\n",
        "\n",
        "            output = model(src, tgt_input)\n",
        "            preds = output.argmax(dim=-1)\n",
        "\n",
        "            # Mask for non-padding tokens\n",
        "            mask = (tgt_output != PAD_token)\n",
        "            total += mask.sum().item()\n",
        "            correct += (preds == tgt_output)[mask].sum().item()\n",
        "\n",
        "    return correct / total if total > 0 else 0\n",
        "\n",
        "def evaluate(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_batches = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src, tgt in dataloader:\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "            tgt_input = tgt[:, :-1]\n",
        "            tgt_output = tgt[:, 1:]\n",
        "\n",
        "            output = model(src, tgt_input)\n",
        "            loss = criterion(output.reshape(-1, output.size(-1)), tgt_output.reshape(-1))\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_batches += 1\n",
        "\n",
        "    return total_loss / total_batches if total_batches > 0 else 0\n",
        "\n",
        "def train_model(model, train_dataloader, val_dataloader, n_epochs, learning_rate=0.001):\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=PAD_token)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        train_batches = 0\n",
        "\n",
        "        for src, tgt in train_dataloader:\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "\n",
        "            # Prepare input and output\n",
        "            tgt_input = tgt[:, :-1]\n",
        "            tgt_output = tgt[:, 1:]\n",
        "\n",
        "            # Forward pass\n",
        "            optimizer.zero_grad()\n",
        "            output = model(src, tgt_input)\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = criterion(output.reshape(-1, output.size(-1)), tgt_output.reshape(-1))\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            train_batches += 1\n",
        "\n",
        "        # Calculate metrics\n",
        "        avg_train_loss = train_loss / train_batches\n",
        "        avg_val_loss = evaluate(model, val_dataloader, criterion)\n",
        "        val_accuracy = calculate_accuracy(model, val_dataloader)\n",
        "\n",
        "        # Print progress\n",
        "        print(f'Epoch {epoch+1}/{n_epochs}:')\n",
        "        print(f'  Training Loss: {avg_train_loss:.4f}')\n",
        "        print(f'  Validation Loss: {avg_val_loss:.4f}')\n",
        "        print(f'  Validation Accuracy: {val_accuracy:.4f}')\n",
        "\n",
        "        # Save best model\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "            print('  (Model saved)')\n",
        "\n",
        "\n",
        "\n",
        "def show_examples(model, dataloader, index_to_char, n_examples):\n",
        "    model.eval()\n",
        "    example_count = 0\n",
        "\n",
        "    print(f\"\\nShowing {n_examples} translation examples:\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src, tgt in dataloader:\n",
        "            if example_count >= n_examples:\n",
        "                break\n",
        "\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "            tgt_input = tgt[:, :-1]\n",
        "            output = model(src, tgt_input)\n",
        "            preds = output.argmax(dim=-1)\n",
        "\n",
        "            # Convert indices to characters\n",
        "            def indices_to_str(indices):\n",
        "                return ''.join([index_to_char.get(idx.item(), '?')\n",
        "                              for idx in indices\n",
        "                              if idx not in (SOS_token, EOS_token, PAD_token)])\n",
        "\n",
        "            # Print all examples\n",
        "            for i in range(src.size(0)):\n",
        "                if example_count >= n_examples:\n",
        "                    break\n",
        "\n",
        "                print(f\"\\nExample {example_count + 1}: Input: {indices_to_str(src[i])}, Target: {indices_to_str(tgt[i])}, Prediction: {indices_to_str(preds[i])}\")\n",
        "\n",
        "                example_count += 1\n",
        "\n",
        "# Split dataset\n",
        "train_data, val_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create dataloaders with custom collate function\n",
        "train_dataset = TranslationDataset(train_data, char_to_index, max_length)\n",
        "val_dataset = TranslationDataset(val_data, char_to_index, max_length)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "# Initialize model\n",
        "model = TransformerModel(vocab_size).to(device)\n",
        "\n",
        "# Train the model\n",
        "print(\"Starting training...\")\n",
        "train_model(model, train_dataloader, val_dataloader, n_epochs=400) # Epochss\n",
        "\n",
        "# Show examples after training\n",
        "show_examples(model, val_dataloader, index_to_char, n_examples=5) # Examples"
      ]
    }
  ]
}